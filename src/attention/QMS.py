
# QMS.py
# High-rigor constant-time representation + S^2 visualization + MoE + LTM
# Author: generated by assistant
# License: MIT
#
# Highlights:
# - Type hints with numpy typing
# - Defensive checks & numerical guards
# - Equivariance test on S^2 for band-limited kernels
# - Integral normalization test for delta_L^t
# - CLI with subcommands: ascii, moe, moe_ltm, selftest
#
# Dependencies: numpy; optional matplotlib (PNG), optional Pillow (GIF)

from __future__ import annotations
import math, json, os, argparse, sys, time
from dataclasses import dataclass
from typing import Iterable, List, Tuple, Dict, Optional, Set

import numpy as np
from numpy.typing import NDArray

# ------------------------------
# Utility
# ------------------------------

def _as_unit(v: NDArray[np.float64]) -> NDArray[np.float64]:
    v = np.asarray(v, dtype=np.float64)
    n = float(np.linalg.norm(v))
    if not np.isfinite(n) or n == 0.0:
        raise ValueError("Zero/NaN/Inf norm in _as_unit")
    return v / n

def _check_prob_vec(p: NDArray[np.float64]):
    if p.ndim != 1 or p.size == 0:
        raise ValueError("prob vector must be 1D and non-empty")
    if np.any(p < -1e-12):
        raise ValueError("negative probabilities")
    s = float(np.sum(p))
    if not np.isfinite(s) or s <= 0.0:
        raise ValueError("sum(prob) must be positive/finite")

# ------------------------------
# SU(2) / QMS-256
# ------------------------------

def su2_from_quat(w: float, x: float, y: float, z: float) -> NDArray[np.complex64]:
    """
    Map unit quaternion q = w + x i + y j + z k to SU(2) matrix U in C^{2x2}:
      a = w + i z, b = x + i y
      U = [[a, b], [-conj(b), conj(a)]]
    Preconditions: (w,x,y,z) ~ unit length within ~1e-6.
    """
    a = complex(w, z)
    b = complex(x, y)
    U = np.array([[a, b], [-np.conjugate(b), np.conjugate(a)]], dtype=np.complex64)
    # det(U) = |a|^2 + |b|^2 = 1 for unit quaternion; numerical guard:
    det = U[0,0]*U[1,1] - U[0,1]*U[1,0]
    if not np.isfinite(det):
        raise FloatingPointError("non-finite SU(2) matrix")
    return U

def axis_angle_to_quat(axis: NDArray[np.float64], theta: float) -> Tuple[float,float,float,float]:
    axis = _as_unit(np.asarray(axis, dtype=np.float64))
    half = 0.5 * float(theta)
    s = math.sin(half)
    return (math.cos(half), axis[0]*s, axis[1]*s, axis[2]*s)

def build_qms256_lut() -> NDArray[np.complex64]:
    """
    Build 256-entry LUT: 4 axes x 64 angles.
    Byte b = 4*k + r with k in [0..63], r in {0,1,2,3}.
    Axis set = {x, y, z, (1,1,1)/sqrt(3)}.
    Returns: (256,2,2) complex64 array.
    """
    axes = np.array([[1.0, 0.0, 0.0],
                     [0.0, 1.0, 0.0],
                     [0.0, 0.0, 1.0],
                     [1.0, 1.0, 1.0]], dtype=np.float64)
    axes[3] /= np.linalg.norm(axes[3])
    mats: List[NDArray[np.complex64]] = []
    for b in range(256):
        k = b // 4
        r = b % 4
        theta = 2.0 * math.pi * (k / 64.0)
        mats.append(su2_from_quat(*axis_angle_to_quat(axes[r], theta)))
    return np.stack(mats, axis=0).astype(np.complex64, copy=False)

class QMS256:
    """
    Stateful QMS-256 stepper:
      - LUT of 256 SU(2) matrices
      - psi ∈ C^2, normalized each step
    Complexity: O(1) per step, fixed 2x2 complex matmul.
    """
    def __init__(self, lut: Optional[NDArray[np.complex64]]=None):
        self.lut = build_qms256_lut() if lut is None else lut.astype(np.complex64, copy=False)
        if self.lut.shape != (256,2,2):
            raise ValueError("lut must have shape (256,2,2)")
        self.psi: NDArray[np.complex64] = np.array([1+0j, 0+0j], dtype=np.complex64)

    @staticmethod
    def normalize_psi(psi: NDArray[np.complex64]) -> NDArray[np.complex64]:
        n = float(np.linalg.norm(psi))
        if not np.isfinite(n) or n == 0.0:
            return np.array([1+0j, 0+0j], dtype=np.complex64)
        return psi / n

    def reset(self, psi: Optional[NDArray[np.complex64]]=None) -> None:
        self.psi = self.normalize_psi(np.array([1+0j, 0+0j], dtype=np.complex64) if psi is None else psi)

    def step_byte(self, b: int) -> NDArray[np.complex64]:
        U = self.lut[int(b) & 0xFF]
        self.psi = self.normalize_psi(U @ self.psi)
        return self.psi.copy()

# ------------------------------
# Hopf map and S^2 grids
# ------------------------------

def hopf_to_unitvec(psi: NDArray[np.complex64]) -> NDArray[np.float64]:
    """
    psi = [u,v] ∈ C^2, ||psi||=1.
    n = (nx,ny,nz) with
      nx = 2 Re(u conj(v)), ny = 2 Im(u conj(v)), nz = |u|^2 - |v|^2
    Returns unit vector in R^3 (float64).
    """
    if psi.shape != (2,):
        raise ValueError("psi must be shape (2,) complex vector")
    u, v = psi[0], psi[1]
    uv = u * np.conjugate(v)
    nx = 2.0 * float(np.real(uv))
    ny = 2.0 * float(np.imag(uv))
    nz = float((np.abs(u)**2 - np.abs(v)**2).real)
    n = np.array([nx, ny, nz], dtype=np.float64)
    nrm = float(np.linalg.norm(n))
    if not np.isfinite(nrm) or nrm == 0.0:
        return np.array([0.0, 0.0, 1.0], dtype=np.float64)
    return n / nrm

def make_latlong_grid(n_theta: int, n_phi: int) -> Tuple[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:
    if n_theta <= 0 or n_phi <= 0:
        raise ValueError("n_theta and n_phi must be positive")
    theta = (np.arange(n_theta) + 0.5) * (math.pi / n_theta)
    phi = (np.arange(n_phi)) * (2.0 * math.pi / n_phi)
    T, P = np.meshgrid(theta, phi, indexing='ij')
    nx = np.sin(T) * np.cos(P)
    ny = np.sin(T) * np.sin(P)
    nz = np.cos(T)
    n_grid = np.stack([nx, ny, nz], axis=-1).astype(np.float64, copy=False)
    return T, P, n_grid

# ------------------------------
# Band-limited delta on S^2 (Legendre recursion) with optional heat kernel
# ------------------------------

def legendre_series_deltaL_heat(cos_gamma: NDArray[np.float64], L: int, t_heat: float=0.0) -> NDArray[np.float64]:
    """
    δ_L^t(n,n0) = Σ_{l=0..L} [(2l+1)/(4π)] * exp(-t l(l+1)) * P_l(cos γ)
    Vectorized in cos_gamma. Uses stable 3-term recurrence for P_l.
    Error: O(L * eps_float) for |cosγ|<=1, float64.
    """
    if L < 0:
        raise ValueError("L must be >= 0")
    x = np.asarray(cos_gamma, dtype=np.float64)
    if np.any(x < -1.0000001) or np.any(x > 1.0000001):
        raise ValueError("cos_gamma out of [-1,1]")
    x = np.clip(x, -1.0, 1.0)
    P_prev = np.ones_like(x)             # P0
    S = (1.0 / (4.0 * math.pi)) * math.exp(-t_heat*0) * P_prev
    if L == 0:
        return S
    P_curr = x.copy()                    # P1
    S += (1.0 / (4.0 * math.pi)) * 3.0 * math.exp(-t_heat*2) * P_curr
    for l in range(1, L):
        P_next = ((2*l + 1) * x * P_curr - l * P_prev) / (l + 1)
        coef = (2*(l+1) + 1)
        decay = math.exp(-t_heat * (l+1) * (l+2))
        S += (1.0 / (4.0 * math.pi)) * coef * decay * P_next
        P_prev, P_curr = P_curr, P_next
    return S

# ------------------------------
# Impulses (short-term ring)
# ------------------------------

@dataclass
class Impulse:
    n: NDArray[np.float64]   # (3,)
    amp: float

class ImpulseBuffer:
    def __init__(self, capacity: int=64, decay: float=0.95):
        if capacity <= 0:
            raise ValueError("capacity must be > 0")
        if not (0.0 < decay <= 1.0):
            raise ValueError("decay must be in (0,1]")
        self.capacity = int(capacity)
        self.decay = float(decay)
        self.items: List[Impulse] = []

    def step_decay(self):
        for it in self.items:
            it.amp *= self.decay
        self.items = [it for it in self.items if it.amp > 1e-9]

    def push(self, n: NDArray[np.float64], amp: float):
        n = _as_unit(np.asarray(n, dtype=np.float64))
        a = float(amp)
        if not np.isfinite(a) or a < 0.0:
            raise ValueError("amp must be finite and >= 0")
        if len(self.items) >= self.capacity:
            self.items = self.items[1:]
        self.items.append(Impulse(n=n, amp=a))

    def render_field(self, n_grid: NDArray[np.float64], L: int, t_heat: float=0.0) -> NDArray[np.float64]:
        f = np.zeros(n_grid.shape[:2], dtype=np.float64)
        if not self.items:
            return f
        for it in self.items:
            n0 = it.n
            cos_g = (n_grid[...,0]*n0[0] + n_grid[...,1]*n0[1] + n_grid[...,2]*n0[2])
            f += it.amp * legendre_series_deltaL_heat(cos_g, L, t_heat=t_heat)
        return f

# ------------------------------
# ASCII rendering helper
# ------------------------------

def render_ascii(field: NDArray[np.float64], chars: str=" .:-=+*#%@") -> str:
    if field.ndim != 2:
        raise ValueError("field must be 2D")
    S = field - float(np.min(field))
    mx = float(np.max(S))
    if mx > 0:
        S = S / mx
    H,W = S.shape
    lines = ["".join(chars[min(len(chars)-1, int(round(S[i,j]*(len(chars)-1))))] for j in range(W))
             for i in range(H)]
    return "\n".join(lines)

# ------------------------------
# MoE hashing and visualizers
# ------------------------------

def _splitmix64(x: int) -> int:
    x = (x + 0x9E3779B97F4A7C15) & 0xFFFFFFFFFFFFFFFF
    z = x
    z = (z ^ (z >> 30)) * 0xBF58476D1CE4E5B9 & 0xFFFFFFFFFFFFFFFF
    z = (z ^ (z >> 27)) * 0x94D049BB133111EB & 0xFFFFFFFFFFFFFFFF
    z = z ^ (z >> 31)
    return z

def _u32_to_unit(u: int) -> float:
    return (u & 0xFFFFFFFF) / 2**32

def expert_to_unitvec(expert_id: int, seed: int=0) -> Tuple[NDArray[np.float64], float, float]:
    x = (int(expert_id) & 0xFFFFFFFFFFFFFFFF) ^ (int(seed) & 0xFFFFFFFFFFFFFFFF)
    h1 = _splitmix64(x)
    h2 = _splitmix64(x ^ 0xD1B54A32D192ED03)
    u = _u32_to_unit(h1)
    v = _u32_to_unit(h2)
    cos_t = max(-1.0, min(1.0, 2.0*u - 1.0))
    theta = math.acos(cos_t)
    phi = 2.0*math.pi*v
    nx = math.sin(theta)*math.cos(phi)
    ny = math.sin(theta)*math.sin(phi)
    nz = math.cos(theta)
    return np.array([nx,ny,nz], dtype=np.float64), theta, phi

class MoEVisualizer:
    """
    S^2 field for MoE router:
      - Two bands L_low and L_high with heat smoothing
      - top-k events -> impulses (rank-1 updates)
      - KPIs: entropy H (EMA), load imbalance LI, collapse Z, churn (EMA)
    Complexity: O(1) per token for fixed k, L.
    """
    def __init__(self, L_low: int=8, L_high: int=16, t_heat: float=0.01, alpha_hi: float=0.6,
                 capacity: int=128, decay: float=0.94, n_theta: int=48, n_phi: int=96, seed: int=0):
        if L_low < 0 or L_high < 0:
            raise ValueError("L must be >=0")
        self.L_low, self.L_high = int(L_low), int(L_high)
        self.t_heat = float(t_heat)
        self.alpha_hi = float(alpha_hi)
        self.ring_low = ImpulseBuffer(capacity=capacity, decay=decay)
        self.ring_high = ImpulseBuffer(capacity=capacity, decay=decay)
        self.T, self.P, self.n_grid = make_latlong_grid(n_theta, n_phi)
        self.seed = int(seed)
        # KPIs
        self.entropy_ema = 0.0
        self.churn_ema = 0.0
        self.last_topk: Set[int] = set()
        self.usage: Dict[int, float] = {}
        self.ema_alpha = 0.1

    def update_token(self, topk_ids: Iterable[int], topk_probs: Iterable[float]):
        ids = list(map(int, topk_ids))
        probs = np.asarray(list(topk_probs), dtype=np.float64)
        _check_prob_vec(probs)
        probs = probs / (np.sum(probs) + 1e-12)

        self.ring_low.step_decay()
        self.ring_high.step_decay()

        for eid, p in zip(ids, probs):
            n, _, _ = expert_to_unitvec(eid, seed=self.seed)
            self.ring_low.push(n, amp=p)
            self.ring_high.push(n, amp=p)
            self.usage[eid] = self.usage.get(eid, 0.0) + float(p)

        # entropy EMA
        H = -float(np.sum(probs * np.log(np.clip(probs, 1e-12, 1.0))))
        a = self.ema_alpha
        self.entropy_ema = (1-a)*self.entropy_ema + a*H
        # churn EMA
        now = set(ids)
        jacc = (len(self.last_topk & now) / (len(self.last_topk | now) if (self.last_topk or now) else 1))
        churn = 1.0 - jacc
        self.churn_ema = (1-a)*self.churn_ema + a*churn
        self.last_topk = now

    def render_field(self) -> NDArray[np.float64]:
        f_low  = self.ring_low.render_field(self.n_grid, self.L_low,  t_heat=self.t_heat)
        f_high = self.ring_high.render_field(self.n_grid, self.L_high, t_heat=self.t_heat)
        return f_low + self.alpha_hi * f_high

    def metrics(self) -> Dict[str, float]:
        if not self.usage:
            return dict(H=self.entropy_ema, LI=0.0, Z=0.0, churn=self.churn_ema)
        counts = np.array(list(self.usage.values()), dtype=np.float64)
        LI = float(np.std(counts) / (np.mean(counts) + 1e-12))
        Z  = float(np.max(counts) / (np.mean(counts) + 1e-12))
        return dict(H=self.entropy_ema, LI=LI, Z=Z, churn=self.churn_ema)

    # Optional plotting (defaults only; no explicit colors/styles; one axes per fig)
    def render_ascii(self, chars: str=" .:-=+*#%@") -> str:
        return render_ascii(self.render_field(), chars=chars)

    def render_png(self, path_png: str, overlay_last: Optional[Iterable[int]]=None):
        try:
            import matplotlib.pyplot as plt
        except Exception as e:
            raise RuntimeError("matplotlib is required for PNG rendering") from e
        field = self.render_field()
        plt.figure(figsize=(7,3.2))
        plt.imshow(field, aspect='auto')
        plt.title(f"MoE S^2 field (L_low={self.L_low}, L_high={self.L_high}, t={self.t_heat})")
        plt.xlabel("phi bins"); plt.ylabel("theta bins"); plt.colorbar()
        if overlay_last:
            xs, ys = [], []
            for eid in overlay_last:
                _, th, ph = expert_to_unitvec(int(eid), seed=self.seed)
                j = int((ph / (2*np.pi)) * field.shape[1]) % field.shape[1]
                i = int((th / np.pi) * field.shape[0]) % field.shape[0]
                xs.append(j); ys.append(i)
            if xs:
                plt.scatter(xs, ys, s=28, marker='*')
        plt.tight_layout()
        plt.savefig(path_png, dpi=120)
        plt.close()

# ------------------------------
# Long-term memory on S^2 (fixed prototypes)
# ------------------------------

class LongTermMemory:
    """
    Fixed-size spherical prototype dictionary (online, O(1) per token).
    Updates: nearest-prototype EMA on S^2 + renormalization; exponential decay for strength.
    """
    def __init__(self, M: int=24, eta: float=0.06, decay: float=0.996, seed: int=0):
        if M <= 0: raise ValueError("M must be > 0")
        if not (0.0 < eta <= 1.0): raise ValueError("eta must be in (0,1]")
        if not (0.0 < decay <= 1.0): raise ValueError("decay must be in (0,1]")
        self.M = int(M); self.eta = float(eta); self.decay = float(decay)
        rng = np.random.default_rng(seed)
        u = rng.random(self.M); v = rng.random(self.M)
        cos_t = 2.0*u - 1.0
        theta = np.arccos(np.clip(cos_t, -1.0, 1.0))
        phi = 2.0*np.pi*v
        self.mu: NDArray[np.float64] = np.stack([np.sin(theta)*np.cos(phi),
                                                 np.sin(theta)*np.sin(phi),
                                                 np.cos(theta)], axis=1).astype(np.float64)  # (M,3)
        self.w  = np.zeros(self.M, dtype=np.float64)
        self.n_updates = np.zeros(self.M, dtype=np.int64)

    def step_decay(self) -> None:
        self.w *= self.decay

    def update(self, n_batch: NDArray[np.float64], amp_batch: NDArray[np.float64]) -> None:
        n_batch = np.asarray(n_batch, dtype=np.float64)
        amp_batch = np.asarray(amp_batch, dtype=np.float64)
        if n_batch.size == 0:
            return
        sims = n_batch @ self.mu.T            # (K,M)
        idx  = np.argmax(sims, axis=1)        # (K,)
        for n,a,j in zip(n_batch, amp_batch, idx):
            n = _as_unit(n)
            if self.w[j] < 1e-9 and self.n_updates[j] < 1:
                self.mu[j] = n; self.w[j] = float(a); self.n_updates[j] += 1; continue
            self.mu[j] = self.mu[j]*(1.0-self.eta) + n*self.eta
            self.mu[j] = self.mu[j] / (np.linalg.norm(self.mu[j]) + 1e-12)
            self.w[j] += float(a); self.n_updates[j] += 1

    def reconstruct_field(self, n_grid: NDArray[np.float64], L: int, t_heat: float=0.01) -> NDArray[np.float64]:
        H,W,_ = n_grid.shape
        if np.all(self.w <= 1e-9):
            return np.zeros((H,W), dtype=np.float64)
        w_disp = self.w / (np.max(self.w) + 1e-12)
        f = np.zeros((H,W), dtype=np.float64)
        for m in range(self.M):
            if w_disp[m] <= 1e-9:
                continue
            n0 = self.mu[m]
            cos_g = (n_grid[...,0]*n0[0] + n_grid[...,1]*n0[1] + n_grid[...,2]*n0[2])
            f += w_disp[m] * legendre_series_deltaL_heat(cos_g, L, t_heat=t_heat)
        return f

    def save(self, path: str) -> None:
        data = dict(M=self.M, eta=self.eta, decay=self.decay,
                    mu=self.mu.tolist(), w=self.w.tolist(), n_updates=self.n_updates.tolist())
        with open(path, "w") as f:
            json.dump(data, f, indent=2)

    @staticmethod
    def load(path: str) -> "LongTermMemory":
        with open(path, "r") as f:
            d = json.load(f)
        obj = LongTermMemory(M=d["M"], eta=d["eta"], decay=d["decay"], seed=0)
        obj.mu = np.array(d["mu"], dtype=np.float64)
        obj.w  = np.array(d["w"], dtype=np.float64)
        obj.n_updates = np.array(d["n_updates"], dtype=np.int64)
        return obj

class MoEVisualizerLTM(MoEVisualizer):
    def __init__(self, *args, M_mem: int=24, eta_mem: float=0.06, decay_mem: float=0.996, beta_mem: float=0.9, **kwargs):
        super().__init__(*args, **kwargs)
        self.mem = LongTermMemory(M=M_mem, eta=eta_mem, decay=decay_mem, seed=self.seed+1)
        self.beta_mem = float(beta_mem)

    def update_token(self, topk_ids: Iterable[int], topk_probs: Iterable[float]):
        super().update_token(topk_ids, topk_probs)
        ids = list(map(int, topk_ids))
        probs = np.asarray(list(topk_probs), dtype=np.float64)
        _check_prob_vec(probs)
        probs = probs / (np.sum(probs) + 1e-12)
        n_list = []; a_list = []
        for eid, p in zip(ids, probs):
            n,_,_ = expert_to_unitvec(eid, seed=self.seed)
            n_list.append(n); a_list.append(float(p))
        self.mem.step_decay()
        self.mem.update(np.array(n_list), np.array(a_list))

    def render_field_with_mem(self) -> Tuple[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:
        f_st  = self.render_field()  # low+high
        f_mem = self.mem.reconstruct_field(self.n_grid, self.L_low, t_heat=self.t_heat)
        return f_st + self.beta_mem * f_mem, f_st, f_mem

# ------------------------------
# Tests (quick, numeric)
# ------------------------------

def _rot_from_axis_angle(axis: NDArray[np.float64], theta: float) -> NDArray[np.float64]:
    a = _as_unit(axis)
    x,y,z = a
    c = math.cos(theta); s = math.sin(theta); C = 1.0 - c
    return np.array([[x*x*C + c,   x*y*C - z*s, x*z*C + y*s],
                     [y*x*C + z*s, y*y*C + c,   y*z*C - x*s],
                     [z*x*C - y*s, z*y*C + x*s, z*z*C + c  ]], dtype=np.float64)

def _rotate_grid(n_grid: NDArray[np.float64], R: NDArray[np.float64]) -> NDArray[np.float64]:
    H,W,_ = n_grid.shape
    m = n_grid.reshape(-1,3).T
    mr = (R @ m).T.reshape(H,W,3)
    return mr

def test_equivariance(L: int=8, t_heat: float=0.01, n_theta: int=40, n_phi: int=80, seed: int=0) -> float:
    """
    Tests δ_L^t equivariance:
      field(rotate impulses; fixed grid)  ~  field(fixed impulses; rotate grid^{-1})
    Returns relative L2 error E_eq.
    """
    rng = np.random.default_rng(seed)
    T,P,n_grid = make_latlong_grid(n_theta, n_phi)
    ring = ImpulseBuffer(capacity=8, decay=1.0)
    # 3 random impulses
    for _ in range(3):
        n = _as_unit(rng.normal(size=3))
        ring.push(n, amp=1.0)
    field = ring.render_field(n_grid, L=L, t_heat=t_heat)
    # random small rotation
    axis = _as_unit(rng.normal(size=3))
    theta = math.radians(15.0)
    R = _rot_from_axis_angle(axis, theta)
    # rotate impulses
    ringR = ImpulseBuffer(capacity=8, decay=1.0)
    for it in ring.items:
        ringR.push(R @ it.n, amp=it.amp)
    field_imp_rot = ringR.render_field(n_grid, L=L, t_heat=t_heat)
    # rotate grid (inverse)
    n_grid_inv = _rotate_grid(n_grid, R.T)
    field_grid_rot = ring.render_field(n_grid_inv, L=L, t_heat=t_heat)
    num = float(np.linalg.norm(field_imp_rot - field_grid_rot))
    den = float(np.linalg.norm(field_imp_rot) + 1e-12)
    return num / den

def test_delta_integral(L: int=8, t_heat: float=0.01, n_theta: int=90, n_phi: int=180) -> float:
    """
    Checks ∫ δ_L^t(n,n0) dΩ ≈ 1 numerically over lat-long grid with sinθ weights.
    Returns absolute error |I-1|.
    """
    T,P,n_grid = make_latlong_grid(n_theta, n_phi)
    n0 = np.array([0.0,0.0,1.0], dtype=np.float64)
    cos_g = n_grid[...,2]  # dot with north pole
    f = legendre_series_deltaL_heat(cos_g, L=L, t_heat=t_heat)
    # integral via sum f(θ,φ) sinθ dθ dφ
    dtheta = math.pi / n_theta
    dphi   = 2.0*math.pi / n_phi
    I = float(np.sum(f * np.sin(T)) * dtheta * dphi)
    return abs(I - 1.0)

# ------------------------------
# CLI
# ------------------------------

def _demo_qms_ascii():
    qms = QMS256()
    text = "Phenotype AI demo"
    T, P, n_grid = make_latlong_grid(40, 80)
    ring = ImpulseBuffer(capacity=64, decay=0.92)
    for b in text.encode("utf-8", "ignore"):
        psi = qms.step_byte(b)
        n0 = hopf_to_unitvec(psi)
        ring.step_decay()
        ring.push(n0, amp=1.0)
    field = ring.render_field(n_grid, L=8, t_heat=0.01)
    art = render_ascii(field)
    print(art)

def _demo_moe(outdir: str, frames: int=60, E: int=64, k: int=2, seed: int=2025):
    os.makedirs(outdir, exist_ok=True)
    viz = MoEVisualizer(L_low=8, L_high=16, t_heat=0.01, alpha_hi=0.6,
                        capacity=128, decay=0.94, n_theta=40, n_phi=80, seed=seed)
    rng = np.random.default_rng(11)
    base_logits = np.zeros(E, dtype=np.float64)
    last_topk = None
    for t in range(frames):
        if t % 20 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 1.0)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum() + 1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1e-9)))
        topk_idx = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p_topk = probs[topk_idx]; p_topk /= (p_topk.sum() + 1e-12)
        viz.update_token(topk_idx, p_topk)
        last_topk = topk_idx
    try:
        viz.render_png(os.path.join(outdir, "moe_last.png"), overlay_last=last_topk)
        with open(os.path.join(outdir, "moe_last.txt"), "w") as f:
            f.write(viz.render_ascii())
    except RuntimeError:
        pass

def _demo_moe_ltm(outdir: str, frames: int=72, E: int=96, k: int=2, seed: int=404):
    os.makedirs(outdir, exist_ok=True)
    viz = MoEVisualizerLTM(L_low=8, L_high=16, t_heat=0.012, alpha_hi=0.6,
                           capacity=128, decay=0.94, n_theta=40, n_phi=80, seed=seed,
                           M_mem=24, eta_mem=0.06, decay_mem=0.996, beta_mem=0.9)
    rng = np.random.default_rng(31)
    base_logits = np.zeros(E, dtype=np.float64)
    last_topk = None
    for t in range(frames):
        if t % 20 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum() + 1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1e-9)))
        topk_idx = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p_topk = probs[topk_idx]; p_topk /= (p_topk.sum() + 1e-12)
        viz.update_token(topk_idx, p_topk)
        last_topk = topk_idx
    try:
        field_all, field_st, field_mem = viz.render_field_with_mem()
        import matplotlib.pyplot as plt
        plt.figure(figsize=(6.4,3.0)); plt.imshow(field_all, aspect='auto')
        plt.title("MoE S^2 field with Long-term Memory"); plt.xlabel("phi"); plt.ylabel("theta"); plt.colorbar(); plt.tight_layout()
        plt.savefig(os.path.join(outdir, "moe_ltm_last.png"), dpi=120); plt.close()
        with open(os.path.join(outdir, "moe_ltm_last.txt"), "w") as f:
            f.write(render_ascii(field_all))
        viz.mem.save(os.path.join(outdir, "memory.json"))
    except RuntimeError:
        pass

def _cmd_selftest(args):
    # Equivariance
    e = test_equivariance(L=args.L, t_heat=args.t, n_theta=40, n_phi=80, seed=0)
    # Integral normalization
    err_int = test_delta_integral(L=args.L, t_heat=args.t, n_theta=80, n_phi=160)
    print(f"E_eq (relative): {e:.3e}")
    print(f"|∫δ_L^t − 1|:    {err_int:.3e}")
    # Quick sanity thresholds
    ok = (e < 5e-12) and (err_int < 5e-3)
    print("PASS" if ok else "FAIL")
    sys.exit(0 if ok else 1)

def main():
    parser = argparse.ArgumentParser(description="QMS_strict: O(1) S^2 visualization + MoE + LTM")
    sub = parser.add_subparsers()

    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run equivariance & integral tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()

# ==============================
# Filtered dgLA Čech backbone (constant-size)
# ==============================
from numpy.typing import NDArray

class GoodCover:
    """
    Finite good cover with P vertices (patches) and undirected edges for non-empty overlaps.
    Orientation: edge e=(i->j) with i<j. Incidence B (E×P): +1 at i, -1 at j. Sum selector S (E×P): 1 at i,j.
    """
    def __init__(self, P: int, edges_undirected: list[tuple[int,int]]):
        assert P >= 2, "P>=2 required"
        self.P = int(P)
        Eset = []
        for (i,j) in edges_undirected:
            i,j = int(i), int(j)
            if i==j: continue
            if i>j: i,j = j,i
            if (i,j) not in Eset: Eset.append((i,j))
        self.edges = Eset
        self.E = len(Eset)
        B = np.zeros((self.E, self.P), dtype=np.float64)
        S = np.zeros((self.E, self.P), dtype=np.float64)
        for r,(i,j) in enumerate(self.edges):
            B[r,i] = +1.0; B[r,j] = -1.0
            S[r,i] =  1.0; S[r,j] =  1.0
        self.B = B
        self.S = S

class Tot:
    """
    Total complex with truncated bidegrees (p,q)∈{0,1}×{0,1}:
      V0: (p=0,q=0)  shape (P,)
      V1: (p=1,q=0)  shape (P,)
      E0: (p=0,q=1)  shape (E,)
      E1: (p=1,q=1)  shape (E,)
    Stored as a single 1D vector with slices.
    """
    def __init__(self, cover: GoodCover):
        self.P = cover.P; self.E = cover.E; o = 0
        self.sl_V0 = slice(o, o+self.P); o += self.P
        self.sl_V1 = slice(o, o+self.P); o += self.P
        self.sl_E0 = slice(o, o+self.E); o += self.E
        self.sl_E1 = slice(o, o+self.E); o += self.E
        self.n = o
        self.cover = cover
    def zeros(self) -> NDArray[np.float64]:
        return np.zeros(self.n, dtype=np.float64)

def build_operators(cover: GoodCover, alpha: float=0.0, beta: float=0.0):
    """
    Build dense operators on Tot (n×n): d, iota, L, delta_tot, R, and D_R = (d+delta_tot)+R.
    - d acts on vertices and edges: V0→V1, E0→E1 (identity blocks) so d^2=0 by truncation.
    - iota acts V1→V0, E1→E0 (identity blocks).
    - L = d iota + iota d.
    - delta_tot: V0→E0 via +B, V1→E1 via -B.
    - R: filtered Robin; defaults to 0 to guarantee (D_R)^2=0. Nonzero R must be validated by enforcement.
    """
    P,E = cover.P, cover.E
    tot = Tot(cover); n = tot.n
    def put(dst: slice, src: slice, M: NDArray[np.float64], OUT: NDArray[np.float64]):
        OUT[dst, src] += M
    I_P = np.eye(P, dtype=np.float64); I_E = np.eye(E, dtype=np.float64)
    B = cover.B

    # d: V0→V1, E0→E1
    D = np.zeros((n,n), dtype=np.float64)
    put(tot.sl_V1, tot.sl_V0, I_P, D)
    put(tot.sl_E1, tot.sl_E0, I_E, D)

    # iota: V1→V0, E1→E0
    IOTA = np.zeros((n,n), dtype=np.float64)
    put(tot.sl_V0, tot.sl_V1, I_P, IOTA)
    put(tot.sl_E0, tot.sl_E1, I_E, IOTA)

    # L
    L = D @ IOTA + IOTA @ D

    # delta_tot
    DEL = np.zeros((n,n), dtype=np.float64)
    put(tot.sl_E0, tot.sl_V0, B,   DEL)
    put(tot.sl_E1, tot.sl_V1, -B,  DEL)

    Dtot = D + DEL

    # filtered R: default zero
    R = np.zeros((n,n), dtype=np.float64)
    if abs(alpha)>0 or abs(beta)>0:
        # provide a simple V0→E0 path proportional to B as a placeholder; enforcement may disable later
        put(tot.sl_E0, tot.sl_V0, alpha * B, R)

    D_R = Dtot + R
    return tot, D, IOTA, L, DEL, R, D_R

def build_contraction(cover: GoodCover):
    """
    Contraction (iota, pi, h) on the (V0,E0) sector using pseudoinverse of B for h.
    """
    P,E = cover.P, cover.E
    tot = Tot(cover); n = tot.n
    J = np.ones((P,1), dtype=np.float64); avg = (1.0/P)*J@J.T
    PI = np.zeros((n,n), dtype=np.float64); PI[tot.sl_V0, tot.sl_V0] = avg
    I_incl = np.zeros((n,n), dtype=np.float64); I_incl[tot.sl_V0, tot.sl_V0] = np.eye(P, dtype=np.float64)
    B = cover.B; B_pinv = np.linalg.pinv(B)  # (P×E)
    H = np.zeros((n,n), dtype=np.float64); H[tot.sl_V0, tot.sl_E0] = B_pinv
    return I_incl, PI, H

def h_neumann(R: NDArray[np.float64], H: NDArray[np.float64], tol: float=1e-7, max_m: int=64) -> NDArray[np.float64]:
    """
    h_R = H * Σ_{m≥0} (−R H)^m (Neumann). Truncate by operator-norm tail.
    """
    RH = R @ H
    S = np.eye(RH.shape[0], dtype=np.float64)
    term = np.eye(RH.shape[0], dtype=np.float64)
    for _ in range(max_m):
        term = - RH @ term
        S_next = S + term
        if np.linalg.norm(term, 2) <= tol * max(1.0, np.linalg.norm(S_next, 2)):
            S = S_next; break
        S = S_next
    return H @ S

class Backbone:
    """
    Filtered dgLA Čech backbone with fixed small matrices（恒等式優先）.
    enforce_square_zero=True なら、(D_R)^2 のノルムが閾値を超えた場合 R を無効化して恒等式を保つ。
    """
    def __init__(self, cover: GoodCover, alpha: float=0.0, beta: float=0.0, enforce_square_zero: bool=True, tol: float=1e-12):
        self.cover = cover
        self._alpha, self._beta = alpha, beta
        self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=alpha, beta=beta)
        if enforce_square_zero:
            sq = np.linalg.norm(self.D_R @ self.D_R, 2)
            if sq > tol:
                self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=0.0, beta=0.0)
        self.I_incl, self.PI, self.H = build_contraction(cover)
        self.H_R = h_neumann(self.R, self.H, tol=1e-7, max_m=64)

    def apply(self, A: NDArray[np.float64], x: NDArray[np.float64]) -> NDArray[np.float64]:
        return A @ x

    def jvp(self, x: NDArray[np.float64], dx: NDArray[np.float64], ops: list[str]) -> NDArray[np.float64]:
        A = np.eye(self.tot.n, dtype=np.float64)
        for op in ops:
            if op == 'D_R': A = self.D_R @ A
            elif op == 'D': A = (self.D + self.DEL) @ A
            elif op == 'IOTA': A = self.IOTA @ A
            elif op == 'L': A = self.L @ A
            else: raise ValueError(f"unknown op {op}")
        return A @ dx

    def vjp(self, x: NDArray[np.float64], v: NDArray[np.float64], ops: list[str]) -> NDArray[np.float64]:
        A = np.eye(self.tot.n, dtype=np.float64)
        for op in ops:
            if op == 'D_R': A = self.D_R @ A
            elif op == 'D': A = (self.D + self.DEL) @ A
            elif op == 'IOTA': A = self.IOTA @ A
            elif op == 'L': A = self.L @ A
            else: raise ValueError(f"unknown op {op}")
        return (A.T) @ v

    def check_square_zero(self) -> float:
        return float(np.linalg.norm(self.D_R @ self.D_R, 2))
    def check_cartan(self) -> float:
        C = self.D_R @ self.IOTA - self.IOTA @ self.D_R - self.L
        return float(np.linalg.norm(C, 2))
    def bound_gamma(self) -> float:
        return float(np.linalg.norm(self.H,2) * np.linalg.norm(self.R,2))

def qms_to_v0_vector(qms: "QMS256", text: str, P: int) -> NDArray[np.float64]:
    """
    QMS-256 のホップ写像による方向を φ で P 分割して V0 に投影（確率化）
    """
    counts = np.zeros(P, dtype=np.float64)
    for b in text.encode("utf-8","ignore"):
        psi = qms.step_byte(b)
        n = hopf_to_unitvec(psi)
        phi = float(np.arctan2(n[1], n[0]) % (2*np.pi))
        j = int(P * (phi / (2*np.pi))) % P
        counts[j] += 1.0
    s = float(counts.sum())
    return counts / s if s > 0 else counts

# ---- CLI hook: dgla_selftest ----
def _cli_dgla_selftest():
    P = 6
    cov = GoodCover(P, [(i,(i+1)%P) for i in range(P)])
    bb  = Backbone(cov, alpha=0.0, beta=0.0, enforce_square_zero=True)
    print("||D_R^2|| =", bb.check_square_zero())
    print("||[D_R,ι]-L|| =", bb.check_cartan())
    # quick JVP/VJP
    import numpy as _np
    x = _np.random.randn(bb.tot.n); dx = _np.random.randn(bb.tot.n); v = _np.random.randn(bb.tot.n)
    ops = ['D_R','L','D_R']
    j = bb.jvp(x, dx, ops); r = bb.vjp(x, v, ops)
    print("||JVP|| =", float(_np.linalg.norm(j)))
    print("||VJP|| =", float(_np.linalg.norm(r)))


# augment CLI for dgla_selftest
def main():
    import argparse
    parser = argparse.ArgumentParser(description="QMS: strict S^2 visualization + MoE + LTM + dgLA backbone")
    sub = parser.add_subparsers()

    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run S^2 kernel tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    p_dgla = sub.add_parser("dgla_selftest", help="Run dgLA Čech backbone self-test")
    p_dgla.set_defaults(func=lambda a: _cli_dgla_selftest())

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()


# ===== dgLA Čech backbone integration (appended) =====
# (If duplicate names exist, please remove older definitions; here we assume first import order wins.)

try:
    GoodCover
except NameError:
    from numpy.typing import NDArray
    class GoodCover:
        def __init__(self, P: int, edges_undirected: list[tuple[int,int]]):
            assert P>=2
            self.P=int(P); Eset=[]
            for (i,j) in edges_undirected:
                i,j=int(i),int(j)
                if i==j: continue
                if i>j: i,j=j,i
                if (i,j) not in Eset: Eset.append((i,j))
            self.edges=Eset; self.E=len(Eset)
            B=np.zeros((self.E,self.P),dtype=np.float64)
            S=np.zeros((self.E,self.P),dtype=np.float64)
            for r,(i,j) in enumerate(self.edges):
                B[r,i]=+1.0; B[r,j]=-1.0; S[r,i]=1.0; S[r,j]=1.0
            self.B=B; self.S=S
    class Tot:
        def __init__(self, cover: GoodCover):
            self.P=cover.P; self.E=cover.E; o=0
            self.sl_V0=slice(o,o+self.P); o+=self.P
            self.sl_V1=slice(o,o+self.P); o+=self.P
            self.sl_E0=slice(o,o+self.E); o+=self.E
            self.sl_E1=slice(o,o+self.E); o+=self.E
            self.n=o; self.cover=cover
        def zeros(self): return np.zeros(self.n,dtype=np.float64)
    def build_operators(cover: GoodCover, alpha: float=0.0, beta: float=0.0):
        P,E=cover.P,cover.E; tot=Tot(cover); n=tot.n
        def put(dst,src,M,OUT): OUT[dst,src]+=M
        I_P=np.eye(P); I_E=np.eye(E); B=cover.B
        D=np.zeros((n,n)); put(tot.sl_V1,tot.sl_V0,I_P,D); put(tot.sl_E1,tot.sl_E0,I_E,D)
        IOTA=np.zeros((n,n)); put(tot.sl_V0,tot.sl_V1,I_P,IOTA); put(tot.sl_E0,tot.sl_E1,I_E,IOTA)
        L=D@IOTA+IOTA@D
        DEL=np.zeros((n,n)); put(tot.sl_E0,tot.sl_V0,B,DEL); put(tot.sl_E1,tot.sl_V1,-B,DEL)
        Dtot=D+DEL
        R=np.zeros((n,n))
        if abs(alpha)>0 or abs(beta)>0: put(tot.sl_E0,tot.sl_V0,alpha*B,R)
        D_R=Dtot+R
        return tot,D,IOTA,L,DEL,R,D_R
    def build_contraction(cover: GoodCover):
        P,E=cover.P,cover.E; tot=Tot(cover); n=tot.n
        J=np.ones((P,1)); avg=(1.0/P)*J@J.T
        PI=np.zeros((n,n)); PI[tot.sl_V0,tot.sl_V0]=avg
        I_incl=np.zeros((n,n)); I_incl[tot.sl_V0,tot.sl_V0]=np.eye(P)
        B=cover.B; B_pinv=np.linalg.pinv(B)
        H=np.zeros((n,n)); H[tot.sl_V0,tot.sl_E0]=B_pinv
        return I_incl,PI,H
    def h_neumann(R,H,tol:float=1e-7,max_m:int=64):
        RH=R@H; S=np.eye(RH.shape[0]); term=np.eye(RH.shape[0])
        for _ in range(max_m):
            term= - RH @ term
            S_next=S+term
            if np.linalg.norm(term,2)<=tol*max(1.0,np.linalg.norm(S_next,2)):
                S=S_next; break
            S=S_next
        return H@S
    class Backbone:
        def __init__(self, cover: GoodCover, alpha: float=0.0, beta: float=0.0, enforce_square_zero: bool=True, tol: float=1e-12):
            self.cover=cover
            self.tot,self.D,self.IOTA,self.L,self.DEL,self.R,self.D_R=build_operators(cover,alpha=alpha,beta=beta)
            if enforce_square_zero:
                sq=np.linalg.norm(self.D_R@self.D_R,2)
                if sq>tol:
                    self.tot,self.D,self.IOTA,self.L,self.DEL,self.R,self.D_R=build_operators(cover,alpha=0.0,beta=0.0)
            self.I_incl,self.PI,self.H=build_contraction(cover)
            self.H_R=h_neumann(self.R,self.H,tol=1e-7,max_m=64)
        def apply(self,A,x): return A@x
        def jvp(self,x,dx,ops):
            A=np.eye(self.tot.n)
            for op in ops:
                if op=='D_R': A=self.D_R@A
                elif op=='D': A=(self.D+self.DEL)@A
                elif op=='IOTA': A=self.IOTA@A
                elif op=='L': A=self.L@A
                else: raise ValueError(op)
            return A@dx
        def vjp(self,x,v,ops):
            A=np.eye(self.tot.n)
            for op in ops:
                if op=='D_R': A=self.D_R@A
                elif op=='D': A=(self.D+self.DEL)@A
                elif op=='IOTA': A=self.IOTA@A
                elif op=='L': A=self.L@A
                else: raise ValueError(op)
            return (A.T)@v
        def check_square_zero(self): return float(np.linalg.norm(self.D_R@self.D_R,2))
        def check_cartan(self):
            C=self.D_R@self.IOTA - self.IOTA@self.D_R - self.L
            return float(np.linalg.norm(C,2))
        def bound_gamma(self): return float(np.linalg.norm(self.H,2)*np.linalg.norm(self.R,2))
    def qms_to_v0_vector(qms, text:str, P:int):
        counts=np.zeros(P,dtype=np.float64)
        for b in text.encode("utf-8","ignore"):
            psi=qms.step_byte(b); n=hopf_to_unitvec(psi)
            phi=float(np.arctan2(n[1],n[0])%(2*np.pi)); j=int(P*(phi/(2*np.pi)))%P
            counts[j]+=1.0
        s=float(counts.sum()); return counts/s if s>0 else counts
    def _cli_dgla_selftest():
        P=6; cov=GoodCover(P,[(i,(i+1)%P) for i in range(P)])
        bb=Backbone(cov,alpha=0.0,beta=0.0,enforce_square_zero=True)
        print("||D_R^2|| =", bb.check_square_zero())
        print("||[D_R,ι]-L|| =", bb.check_cartan())
        import numpy as _np
        x=_np.random.randn(bb.tot.n); dx=_np.random.randn(bb.tot.n); v=_np.random.randn(bb.tot.n)
        j=bb.jvp(x,dx,['D_R','L','D_R']); r=bb.vjp(x,v,['D_R','L','D_R'])
        print("||JVP|| =", float(_np.linalg.norm(j))); print("||VJP|| =", float(_np.linalg.norm(r)))
except Exception as _e:
    # If already defined, ignore.
    pass


# ==============================
# SH coefficient backend (constant-size updates, cached render basis)
# ==============================

def _lm_index(l: int, m: int) -> int:
    return l*l + l + m  # 0..(L+1)^2-1 with ordering by l then m=-l..l

def _real_sh_Y_vec(theta: float, phi: float, L: int) -> np.ndarray:
    """
    Real spherical harmonics vector Y (length (L+1)^2) at angles (theta,phi).
    Convention: Y_{l0} = N P_l(cosθ);
                m>0: sqrt(2) N P_l^m(cosθ) cos(mφ);
                m<0: sqrt(2) N P_l^{|m|}(cosθ) sin(|m|φ).
    Normalization N = sqrt((2l+1)/(4π) * (l-m)!/(l+m)!).
    """
    ct = float(np.cos(theta)); st = float(np.sin(theta))
    Y = np.zeros((L+1)*(L+1), dtype=np.float64)

    # Associated Legendre P_l^m via stable recursion:
    # P_m^m(x) = (-1)^m (2m-1)!! (1-x^2)^{m/2}
    # P_{m+1}^m(x) = x (2m+1) P_m^m(x)
    # P_l^m(x) = ((2l-1)x P_{l-1}^m - (l-1+m) P_{l-2}^m)/(l-m)
    Pmm_prev = 1.0
    x = ct
    fact = 1.0
    for m in range(1, L+1):
        Pmm_prev *= - fact * st
        fact += 2.0
    # We'll compute for each m separately
    for m in range(0, L+1):
        # compute P_l^m for l=m..L
        if m == 0:
            Pm_m = 1.0
        else:
            # recompute P_m^m
            Pm_m = 1.0
            fact = 1.0
            for k in range(1, m+1):
                Pm_m *= - fact * st
                fact += 2.0
        if m == L:
            Plm_vals = [Pm_m]
        else:
            Pm1_m = x * (2*m + 1) * Pm_m
            Plm_vals = [Pm_m, Pm1_m]
            for l in range(m+2, L+1):
                Pl = ((2*l - 1)*x*Plm_vals[-1] - (l-1+m)*Plm_vals[-2])/(l-m)
                Plm_vals.append(Pl)
        # write Y for m>=0 and m<0
        for idx, Plm in enumerate(Plm_vals):
            l = m + idx
            # normalization
            # N_{l,m}
            from math import factorial, sqrt, pi
            N = sqrt((2*l+1)/(4.0*pi) * factorial(l-m)/factorial(l+m))
            if m == 0:
                Y[_lm_index(l, 0)] = N * Plm
            else:
                c = sqrt(2.0) * N * Plm
                Y[_lm_index(l, +m)] = c * np.cos(m*phi)
                Y[_lm_index(l, -m)] = c * np.sin(m*phi)
    return Y

def _angles_from_unit(n: np.ndarray) -> tuple[float,float]:
    n = np.asarray(n, dtype=np.float64)
    n = n / (np.linalg.norm(n)+1e-12)
    theta = float(np.arccos(np.clip(n[2], -1.0, 1.0)))  # [0,π]
    phi = float(np.arctan2(n[1], n[0]) % (2*np.pi))     # [0,2π)
    return theta, phi

def _precompute_sh_basis(n_theta: int, n_phi: int, L: int, cache_dir: str="/mnt/data") -> dict:
    os.makedirs(cache_dir, exist_ok=True)
    key = f"shcache_{n_theta}x{n_phi}_L{L}.npz"
    path = os.path.join(cache_dir, key)
    if os.path.exists(path):
        data = np.load(path, allow_pickle=True)
        return {"B": data["B"], "theta": data["theta"], "phi": data["phi"], "L": int(data["L"])}
    T, P, n_grid = make_latlong_grid(n_theta, n_phi)
    H, W = n_theta, n_phi
    ncoef = (L+1)*(L+1)
    B = np.zeros((H*W, ncoef), dtype=np.float64)
    for i in range(H):
        for j in range(W):
            th = float(T[i,j]); ph = float(P[i,j])
            B[i*W+j,:] = _real_sh_Y_vec(th, ph, L)
    np.savez(path, B=B, theta=T, phi=P, L=L)
    return {"B": B, "theta": T, "phi": P, "L": L}

class SHField:
    """
    Real SH coefficient field up to band L.
      - c_st, c_mem ∈ R^{(L+1)^2}
      - g_l = exp(-t l(l+1)) radial heat
      - update_from_topk: O(k · L^2) constant (L small)
      - render: field = reshape(B @ (c_st + beta_mem c_mem), (H,W))
    """
    def __init__(self, L: int=16, t_heat: float=0.01, beta_mem: float=0.9, cache_dir: str="/mnt/data",
                 n_theta: int=40, n_phi: int=80):
        self.L = int(L); self.t_heat = float(t_heat); self.beta_mem = float(beta_mem)
        self.ncoef = (self.L+1)*(self.L+1)
        self.c_st  = np.zeros(self.ncoef, dtype=np.float64)
        self.c_mem = np.zeros(self.ncoef, dtype=np.float64)
        self.cache = _precompute_sh_basis(n_theta, n_phi, self.L, cache_dir=cache_dir)
        self.B = self.cache["B"]; self.theta = self.cache["theta"]; self.phi = self.cache["phi"]
        # precompute per-coefficient radial weights g_l
        self.g = np.zeros(self.ncoef, dtype=np.float64)
        for l in range(self.L+1):
            g_l = float(np.exp(- self.t_heat * l * (l+1)))
            for m in range(-l, l+1):
                self.g[_lm_index(l, m)] = g_l
        # KPI drift (for LTM-like mem); keep previous coefficients
        self.prev_mem = self.c_mem.copy()
        self.drift_ema = 0.0; self.ema_alpha = 0.1

    def _dir_to_Y(self, n: np.ndarray) -> np.ndarray:
        th, ph = _angles_from_unit(n)
        return _real_sh_Y_vec(th, ph, self.L)

    def update_from_topk(self, dirs: list[np.ndarray], amps: list[float], to_memory: bool=True):
        if not dirs: return
        contrib = np.zeros(self.ncoef, dtype=np.float64)
        for n,a in zip(dirs, amps):
            Y = self._dir_to_Y(n)
            contrib += float(a) * (self.g * Y)
        self.c_st *= 0.0  # short-term in SH demo: focus on immediate imprint (render history elsewhere if needed)
        self.c_st += contrib
        if to_memory:
            self.c_mem = 0.996 * self.c_mem + contrib  # decay + accumulate
            # drift metric: cosine between previous and current memory
            num = float(np.dot(self.prev_mem, self.c_mem))
            den = float(np.linalg.norm(self.prev_mem)*np.linalg.norm(self.c_mem) + 1e-12)
            s = num/den if den>0 else 1.0
            self.drift_ema = (1-self.ema_alpha)*self.drift_ema + self.ema_alpha * s
            self.prev_mem = self.c_mem.copy()

    def render(self, equal_area_correction: bool=False, percentile_norm: bool=True) -> np.ndarray:
        v = self.c_st + self.beta_mem * self.c_mem
        img = (self.B @ v).reshape(self.theta.shape)
        F = img.astype(np.float64, copy=False)
        if equal_area_correction:
            F = F / (np.sin(self.theta) + 1e-9)
        if percentile_norm:
            q01 = float(np.quantile(F, 0.01)); q99 = float(np.quantile(F, 0.99))
            if q99 - q01 > 1e-12:
                F = (F - q01) / (q99 - q01)
        else:
            mn = float(F.min()); mx = float(F.max())
            if mx - mn > 1e-12: F = (F - mn) / (mx - mn)
        return F

# ==============================
# KPI extensions for MoEVisualizer
# ==============================

def _gini_from_counts(x: np.ndarray) -> float:
    x = np.asarray(x, dtype=np.float64)
    if x.size == 0: return 0.0
    if np.all(x == 0): return 0.0
    x = np.sort(x)
    n = x.size
    cum = np.cumsum(x)
    g = (n + 1 - 2*np.sum(cum)/cum[-1]) / n
    return float(g)

# Patch metrics() if present
try:
    _old_metrics = MoEVisualizer.metrics
    def _metrics_ext(self) -> dict:
        base = _old_metrics(self)
        if self.usage:
            counts = np.array(list(self.usage.values()), dtype=np.float64)
            hhi = float(np.sum((counts/ (np.sum(counts)+1e-12))**2))
            n_eff = float(np.exp(self.entropy_ema))
            gini = _gini_from_counts(counts)
            base.update(dict(HHI=hhi, N_eff=n_eff, Gini=gini))
        return base
    MoEVisualizer.metrics = _metrics_ext
except Exception:
    pass

# ==============================
# Log ingestion (CSV-like lines)
# ==============================

def _parse_log_line(line: str) -> tuple[list[int], list[float]]:
    """
    Accept 'topk_ids=1,2,3 probs=0.4,0.35,0.25' or CSV '1,2,3;0.4,0.35,0.25'.
    Returns (ids, probs). Invalid lines -> empty.
    """
    s = line.strip()
    if not s: return [], []
    try:
        if ";" in s and "=" not in s:
            ids_s, probs_s = s.split(";")
            ids = [int(x) for x in ids_s.split(",") if x]
            probs = [float(x) for x in probs_s.split(",") if x]
            return ids, probs
        if "topk_ids=" in s and "probs=" in s:
            part = {kv.split("=")[0]: kv.split("=")[1] for kv in s.replace(",", " ").split() if "=" in kv}
            ids = [int(x) for x in part["topk_ids"].split()]
            probs = [float(x) for x in part["probs"].split()]
            return ids, probs
    except Exception:
        return [], []
    return [], []

def _cli_ingest_log(path_in: str, out_dir: str):
    os.makedirs(out_dir, exist_ok=True)
    viz = MoEVisualizerLTM(L_low=8, L_high=16, t_heat=0.01, alpha_hi=0.6,
                           capacity=128, decay=0.94, n_theta=40, n_phi=80, seed=123,
                           M_mem=24, eta_mem=0.06, decay_mem=0.996, beta_mem=0.9)
    last_topk = None
    with open(path_in, "r", encoding="utf-8") as f:
        for line in f:
            ids, probs = _parse_log_line(line)
            if not ids: continue
            p = np.array(probs, dtype=np.float64); p = p / (p.sum()+1e-12)
            viz.update_token(ids, p)
            last_topk = ids
    try:
        viz.render_png(os.path.join(out_dir, "ingest_last.png"), overlay_last=last_topk)
        with open(os.path.join(out_dir, "ingest_metrics.json"), "w") as wf:
            json.dump(viz.metrics(), wf, indent=2)
    except RuntimeError:
        pass

# ==============================
# CLI: SH demo & precompute
# ==============================

def _cli_sh_precompute(L: int=16, n_theta: int=40, n_phi: int=80, cache_dir: str="/mnt/data"):
    _ = _precompute_sh_basis(n_theta, n_phi, L, cache_dir=cache_dir)
    print("SH basis cached:", os.path.join(cache_dir, f"shcache_{n_theta}x{n_phi}_L{L}.npz"))

def _cli_sh_demo(out_dir: str, L: int=16, n_theta: int=40, n_phi: int=80,
                 frames: int=48, E: int=64, k: int=2, seed: int=11,
                 equal_area: bool=False, pct: bool=True):
    os.makedirs(out_dir, exist_ok=True)
    sh = SHField(L=L, t_heat=0.01, beta_mem=0.9, cache_dir="/mnt/data", n_theta=n_theta, n_phi=n_phi)
    rng = np.random.default_rng(seed)
    base_logits = np.zeros(E, dtype=np.float64)
    for t in range(frames):
        if t % 16 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum()+1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1e-9)))
        topk_idx = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p_topk = probs[topk_idx]; p_topk /= (p_topk.sum()+1e-12)
        # map ids to directions
        dirs = [expert_to_unitvec(int(eid))[0] for eid in topk_idx]
        sh.update_from_topk(dirs, list(p_topk), to_memory=True)
    # render and save
    img = sh.render(equal_area_correction=equal_area, percentile_norm=pct)
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(6.4,3.0)); plt.imshow(img, aspect='auto'); plt.title(f"SH demo L={L}")
        plt.xlabel("phi bins"); plt.ylabel("theta bins"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, f"sh_demo_L{L}.png"), dpi=130); plt.close()
    except Exception:
        pass
    # dump drift
    with open(os.path.join(out_dir, "sh_demo_metrics.json"), "w") as wf:
        json.dump({"drift_ema": sh.drift_ema}, wf, indent=2)

# ============ Override main() to add new subcommands (last definition wins) ============

def main():
    import argparse
    parser = argparse.ArgumentParser(description="QMS: strict S^2 visualization + MoE + LTM + dgLA + SH")
    sub = parser.add_subparsers()

    # existing demos (defined earlier in file)
    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run S^2 kernel tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    # Čech backbone
    p_dgla = sub.add_parser("dgla_selftest", help="Run dgLA Čech backbone self-test")
    p_dgla.set_defaults(func=lambda a: _cli_dgla_selftest())

    # SH backend
    p_shp = sub.add_parser("sh_precompute", help="Precompute & cache SH basis")
    p_shp.add_argument("--L", default=16, type=int)
    p_shp.add_argument("--n_theta", default=40, type=int)
    p_shp.add_argument("--n_phi", default=80, type=int)
    p_shp.add_argument("--cache_dir", default="/mnt/data", type=str)
    p_shp.set_defaults(func=lambda a: _cli_sh_precompute(a.L, a.n_theta, a.n_phi, a.cache_dir))

    p_shd = sub.add_parser("sh_demo", help="Run SH coefficient demo and save PNG+metrics")
    p_shd.add_argument("--out", default="./out_sh", type=str)
    p_shd.add_argument("--L", default=16, type=int)
    p_shd.add_argument("--n_theta", default=40, type=int)
    p_shd.add_argument("--n_phi", default=80, type=int)
    p_shd.add_argument("--frames", default=48, type=int)
    p_shd.add_argument("--E", default=64, type=int)
    p_shd.add_argument("--k", default=2, type=int)
    p_shd.add_argument("--seed", default=11, type=int)
    p_shd.add_argument("--equal_area", action="store_true")
    p_shd.add_argument("--no_pct", action="store_true")
    p_shd.set_defaults(func=lambda a: _cli_sh_demo(a.out, a.L, a.n_theta, a.n_phi, a.frames, a.E, a.k, a.seed, a.equal_area, not a.no_pct))

    # Log ingestion
    p_ing = sub.add_parser("ingest_log", help="Ingest CSV-like log and render final state")
    p_ing.add_argument("--in", dest="path_in", required=True, type=str)
    p_ing.add_argument("--out", dest="out_dir", default="./out_ingest", type=str)
    p_ing.set_defaults(func=lambda a: _cli_ingest_log(a.path_in, a.out_dir))

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()


# ==============================
# Curvature projection for Robin: solve [D, R+Δ] + (R+Δ)^2 = 0 in least squares
# ==============================

def _vec(M: np.ndarray) -> np.ndarray:
    return M.reshape(-1, order='F')  # Fortran vec for Kronecker identities

def _unvec(v: np.ndarray, n: int) -> np.ndarray:
    return v.reshape((n, n), order='F')

def project_robin_square_zero(D: np.ndarray, R: np.ndarray, mask: np.ndarray=None, tol: float=1e-10, max_iter: int=5) -> tuple[np.ndarray, float]:
    """
    Given D (square-zero) and initial R, iteratively find Δ to reduce curvature C = [D,R] + R^2.
    Solve linearized equation: [D,Δ] + RΔ + ΔR = -C for Δ in least squares (Kronecker form).
    Optionally restrict Δ to 'mask' support (bool matrix); else use support of R.
    Returns (R_proj, final_norm).
    """
    n = D.shape[0]
    Rk = R.copy()
    if mask is None:
        mask = (np.abs(R) > 0)

    I = np.eye(n)
    KD = np.kron(I, D) - np.kron(D.T, I)          # vec([D,Δ])
    def K(Rcur):
        return KD + np.kron(I, Rcur) + np.kron(Rcur.T, I)

    for _ in range(max_iter):
        C = (D @ Rk - Rk @ D) + (Rk @ Rk)
        normC = float(np.linalg.norm(C, 2))
        if normC <= tol:
            return Rk, normC
        A = K(Rk)
        b = - _vec(C)
        # restrict to mask: select columns where mask==True
        mask_vec = mask.reshape(-1, order='F')
        cols = np.where(mask_vec.ravel())[0]
        if cols.size == 0:
            # nothing adjustable; abort
            return Rk, normC
        Ared = A[:, cols]
        # least squares
        sol, *_ = np.linalg.lstsq(Ared, b, rcond=None)
        dR_vec = np.zeros(n*n, dtype=np.float64); dR_vec[cols] = sol
        dR = _unvec(dR_vec, n)
        Rk = Rk + dR
    C = (D @ Rk - Rk @ D) + (Rk @ Rk)
    return Rk, float(np.linalg.norm(C, 2))

# Hook Backbone to use the projector if beta/alpha requested
try:
    _Backbone_old_init = Backbone.__init__
    def _Backbone_new_init(self, cover, alpha: float=0.0, beta: float=0.0, enforce_square_zero: bool=True, tol: float=1e-12):
        self.cover = cover
        self._alpha, self._beta = alpha, beta
        self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=alpha, beta=beta)
        # If R nonzero, try to project to curvature-zero before enforcement
        if (np.abs(self.R).sum() > 0) and enforce_square_zero:
            mask = (np.abs(self.R) > 0)
            Rproj, cn = project_robin_square_zero(self.D + self.DEL, self.R, mask=mask, tol=1e-10, max_iter=6)
            self.R = Rproj
            self.D_R = (self.D + self.DEL) + self.R
            # If still large curvature, fallback to disabling R
            if cn > tol:
                self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=0.0, beta=0.0)
        # contraction/homotopy
        self.I_incl, self.PI, self.H = build_contraction(cover)
        self.H_R = h_neumann(self.R, self.H, tol=1e-7, max_m=64)
    Backbone.__init__ = _Backbone_new_init
except Exception:
    pass

# CLI helper
def _cli_dgla_project(P: int=6, beta: float=0.2):
    cov = GoodCover(P, [(i,(i+1)%P) for i in range(P)])
    tot, D, IOTA, L, DEL, R, D_R = build_operators(cov, alpha=0.0, beta=beta)
    mask = (np.abs(R) > 0)
    Rproj, cn = project_robin_square_zero(D+DEL, R, mask=mask, tol=1e-10, max_iter=8)
    D_Rp = (D+DEL) + Rproj
    print("Pre  ||(D_R)^2||:", float(np.linalg.norm((D_R @ D_R),2)))
    print("Post ||(D_R)^2||:", float(np.linalg.norm((D_Rp @ D_Rp),2)))
    print("Curvature residual:", cn)

# ==============================
# SH φ-rotation equivariance test
# ==============================

def _cli_sh_equivariance(L: int=12, n_theta: int=40, n_phi: int=80, shift_cols: int=5, trials: int=5, seed: int=7):
    rng = np.random.default_rng(seed)
    sh = SHField(L=L, t_heat=0.01, beta_mem=0.0, n_theta=n_theta, n_phi=n_phi)
    # Build a few random directions and amplitudes
    H, W = n_theta, n_phi
    dphi = 2*np.pi * (shift_cols / W)
    errs = []
    for _ in range(trials):
        sh.c_st[:] = 0; sh.c_mem[:] = 0
        K = 4
        dirs = []
        amps = []
        for k in range(K):
            th = np.arccos(2*rng.random()-1.0)  # uniform on sphere via cosθ
            ph = 2*np.pi * rng.random()
            dirs.append(np.array([np.cos(ph)*np.sin(th), np.sin(ph)*np.sin(th), np.cos(th)], dtype=np.float64))
            amps.append(rng.uniform(0.5, 1.0))
        sh.update_from_topk(dirs, amps, to_memory=False)
        img1 = sh.render(equal_area_correction=False, percentile_norm=False)

        # rotate directions by +dphi around z-axis
        dirs_rot = []
        for n in dirs:
            th, ph = float(np.arccos(np.clip(n[2],-1,1))), float(np.arctan2(n[1],n[0])%(2*np.pi))
            ph2 = (ph + dphi) % (2*np.pi)
            n2 = np.array([np.cos(ph2)*np.sin(th), np.sin(ph2)*np.sin(th), np.cos(th)], dtype=np.float64)
            dirs_rot.append(n2)
        sh.c_st[:] = 0; sh.c_mem[:] = 0
        sh.update_from_topk(dirs_rot, amps, to_memory=False)
        img2 = sh.render(equal_area_correction=False, percentile_norm=False)

        # compare with column roll
        img1r = np.roll(img1, shift_cols, axis=1)
        num = float(np.linalg.norm(img2 - img1r))
        den = float(np.linalg.norm(img1r) + 1e-12)
        errs.append(num/den)
    print("phi-rotation equivariance rel. error (mean,std):", float(np.mean(errs)), float(np.std(errs)))
    return float(np.mean(errs))

# Extend main()
def main():
    import argparse
    parser = argparse.ArgumentParser(description="QMS: strict S^2 visualization + MoE + LTM + dgLA + SH (+projection)")
    sub = parser.add_subparsers()

    # existing
    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run S^2 kernel tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    p_dgla = sub.add_parser("dgla_selftest", help="Run dgLA Čech backbone self-test")
    p_dgla.set_defaults(func=lambda a: _cli_dgla_selftest())

    # projection
    p_proj = sub.add_parser("dgla_project", help="Project Robin to curvature-zero")
    p_proj.add_argument("--P", default=6, type=int)
    p_proj.add_argument("--beta", default=0.2, type=float)
    p_proj.set_defaults(func=lambda a: _cli_dgla_project(a.P, a.beta))

    # SH
    p_shp = sub.add_parser("sh_precompute", help="Precompute & cache SH basis")
    p_shp.add_argument("--L", default=16, type=int)
    p_shp.add_argument("--n_theta", default=40, type=int)
    p_shp.add_argument("--n_phi", default=80, type=int)
    p_shp.add_argument("--cache_dir", default="/mnt/data", type=str)
    p_shp.set_defaults(func=lambda a: _cli_sh_precompute(a.L, a.n_theta, a.n_phi, a.cache_dir))

    p_shd = sub.add_parser("sh_demo", help="Run SH coefficient demo and save PNG+metrics")
    p_shd.add_argument("--out", default="./out_sh", type=str)
    p_shd.add_argument("--L", default=16, type=int)
    p_shd.add_argument("--n_theta", default=40, type=int)
    p_shd.add_argument("--n_phi", default=80, type=int)
    p_shd.add_argument("--frames", default=48, type=int)
    p_shd.add_argument("--E", default=64, type=int)
    p_shd.add_argument("--k", default=2, type=int)
    p_shd.add_argument("--seed", default=11, type=int)
    p_shd.add_argument("--equal_area", action="store_true")
    p_shd.add_argument("--no_pct", action="store_true")
    p_shd.set_defaults(func=lambda a: _cli_sh_demo(a.out, a.L, a.n_theta, a.n_phi, a.frames, a.E, a.k, a.seed, a.equal_area, not a.no_pct))

    p_sheq = sub.add_parser("sh_equivariance", help="Test phi-rotation equivariance for SH backend")
    p_sheq.add_argument("--L", default=12, type=int)
    p_sheq.add_argument("--n_theta", default=40, type=int)
    p_sheq.add_argument("--n_phi", default=80, type=int)
    p_sheq.add_argument("--shift_cols", default=5, type=int)
    p_sheq.add_argument("--trials", default=5, type=int)
    p_sheq.add_argument("--seed", default=7, type=int)
    p_sheq.set_defaults(func=lambda a: _cli_sh_equivariance(a.L, a.n_theta, a.n_phi, a.shift_cols, a.trials, a.seed))

    # ingest
    p_ing = sub.add_parser("ingest_log", help="Ingest CSV-like log and render final state")
    p_ing.add_argument("--in", dest="path_in", required=True, type=str)
    p_ing.add_argument("--out", dest="out_dir", default="./out_ingest", type=str)
    p_ing.set_defaults(func=lambda a: _cli_ingest_log(a.path_in, a.out_dir))

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()


# ==============================
# Equal-area cubemap grid + SH rendering
# ==============================

class CubeMapGrid:
    """
    6-face cubemap with N×N per face. Provides mapping to unit vectors.
    Layout for stitching (3×2 faces):
        [ +X | +Y | +Z ]
        [ -X | -Y | -Z ]
    """
    def __init__(self, N: int=32):
        assert N >= 2
        self.N = int(N)
        self.faces = ["+X","+Y","+Z","-X","-Y","-Z"]

    def face_uv_to_dir(self, face: str, u: float, v: float) -> np.ndarray:
        # u,v in [-1,1]
        if face == "+X":
            x, y, z =  1.0, -v, -u
        elif face == "-X":
            x, y, z = -1.0, -v,  u
        elif face == "+Y":
            x, y, z =  u,  1.0,  v
        elif face == "-Y":
            x, y, z =  u, -1.0, -v
        elif face == "+Z":
            x, y, z =  u, -v,  1.0
        elif face == "-Z":
            x, y, z = -u, -v, -1.0
        else:
            raise ValueError(face)
        v3 = np.array([x,y,z], dtype=np.float64)
        return v3 / (np.linalg.norm(v3)+1e-12)

    def sample_dirs(self) -> np.ndarray:
        N = self.N
        # pixel centers in [-1,1]
        ss = (np.arange(N)+0.5)/N * 2.0 - 1.0
        out = []
        for f in self.faces:
            for i in range(N):
                for j in range(N):
                    u = ss[j]; v = ss[i]
                    out.append(self.face_uv_to_dir(f, u, v))
        return np.stack(out, axis=0)  # (6*N*N, 3)

    def stitch(self, fields: dict) -> np.ndarray:
        """
        fields: dict{face: N×N array}
        returns stitched 2N×3N image
        """
        N = self.N
        row1 = np.concatenate([fields["+X"], fields["+Y"], fields["+Z"]], axis=1)
        row2 = np.concatenate([fields["-X"], fields["-Y"], fields["-Z"]], axis=1)
        return np.concatenate([row1, row2], axis=0)

def sh_render_cubemap(sh: "SHField", N: int=32, percentile_norm: bool=True) -> np.ndarray:
    """
    Evaluate SH coefficients on a cubemap grid. No equal-area correction needed.
    """
    cg = CubeMapGrid(N=N)
    ss = (np.arange(N)+0.5)/N * 2.0 - 1.0
    faces = {}
    v = sh.c_st + sh.beta_mem * sh.c_mem
    for face in cg.faces:
        img = np.zeros((N,N), dtype=np.float64)
        for i in range(N):
            for j in range(N):
                n = cg.face_uv_to_dir(face, ss[j], ss[i])
                th, ph = _angles_from_unit(n)
                Y = _real_sh_Y_vec(th, ph, sh.L)
                img[i,j] = float(Y @ v)
        F = img
        if percentile_norm:
            q01 = float(np.quantile(F, 0.01)); q99 = float(np.quantile(F, 0.99))
            if q99 - q01 > 1e-12: F = (F - q01) / (q99 - q01)
        else:
            mn = float(F.min()); mx = float(F.max())
            if mx - mn > 1e-12: F = (F - mn) / (mx - mn)
        faces[face] = F
    return cg.stitch(faces)

def _cli_cubemap_demo(out_dir: str, L: int=16, N: int=32, frames: int=48, E: int=64, k: int=2, seed: int=13):
    os.makedirs(out_dir, exist_ok=True)
    sh = SHField(L=L, t_heat=0.01, beta_mem=0.9, cache_dir="/mnt/data", n_theta=40, n_phi=80)
    rng = np.random.default_rng(seed)
    base_logits = np.zeros(E, dtype=np.float64)
    for t in range(frames):
        if t % 16 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum()+1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1e-9)))
        topk = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p = probs[topk]; p /= (p.sum()+1e-12)
        dirs = [expert_to_unitvec(int(eid))[0] for eid in topk]
        sh.update_from_topk(dirs, list(p), to_memory=True)
    img = sh_render_cubemap(sh, N=N, percentile_norm=True)
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(7.2,4.8)); plt.imshow(img, aspect='auto'); plt.title(f"Cubemap SH demo (L={L}, N={N})")
        plt.xlabel("faces (3N)"); plt.ylabel("faces (2N)"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, f"cubemap_L{L}_N{N}.png"), dpi=130); plt.close()
    except Exception:
        pass

# ==============================
# LongTermMemory: re-seed / split / merge
# ==============================

try:
    LTMcls = LongTermMemory
    def _ltm_optimize(self, reseed_thresh: float=1e-3, merge_cos: float=0.98, split_weight: float=0.2):
        """
        - reseed: slots with weight<reseed_thresh and zero updates
        - merge: cosine(n_i, n_j)>merge_cos -> merge j into i
        - split: if weight>split_weight and accumulated within-slot variance is high (proxy: recent drift low & strong), split into two nearby antipodal jitter
        """
        M = self.M
        # reseed
        for i in range(M):
            if self.w[i] < reseed_thresh:
                # random re-seed on sphere using expert_to_unitvec heuristic
                eid = int((i*1315423911) % 65536)
                n,_th,_ph = expert_to_unitvec(eid)
                self.mu[i,:] = n
                self.w[i] = reseed_thresh
# merge
        alive = [i for i in range(M) if self.w[i] > 0]
        merged = set()
        for i in alive:
            if i in merged: continue
            for j in alive:
                if j<=i or j in merged: continue
                c = float(np.dot(self.mu[i], self.mu[j]))
                if c > merge_cos:
                    wi, wj = self.w[i], self.w[j]
                    if wi+wj > 0:
                        self.mu[i,:] = (wi*self.mu[i] + wj*self.mu[j]) / (wi+wj)
                        self.mu[i,:] /= (np.linalg.norm(self.mu[i])+1e-12)
                        self.w[i] = wi+wj
                        self.w[j] = 0.0; merged.add(j)

        # split (heuristic): pick heavy slot and split near-orthogonally
        idx = int(np.argmax(self.w))
        if self.w[idx] > split_weight:
            n = self.mu[idx].copy()
            # jitter orthogonal direction
            a = np.array([1.0,0.0,0.0]); 
            if abs(np.dot(a,n))>0.9: a = np.array([0.0,1.0,0.0])
            v = a - np.dot(a,n)*n; v /= (np.linalg.norm(v)+1e-12)
            n2 = (n + 0.1*v); n2 /= (np.linalg.norm(n2)+1e-12)
            # find empty slot
            empty = np.where(self.w < reseed_thresh)[0]
            if empty.size>0:
                j = int(empty[0])
                self.mu[j,:] = n2
                self.w[j] = self.w[idx]*0.3
                self.w[idx] *= 0.7

    LTMcls.optimize = _ltm_optimize
except Exception:
    pass

def _cli_ltm_opt(out_dir: str="./out_ltm_opt"):
    os.makedirs(out_dir, exist_ok=True)
    viz = MoEVisualizerLTM(L_low=8, L_high=16, t_heat=0.01, alpha_hi=0.6,
                           capacity=128, decay=0.94, n_theta=40, n_phi=80, seed=404,
                           M_mem=24, eta_mem=0.06, decay_mem=0.996, beta_mem=0.9)
    # run short simulation
    rng = np.random.default_rng(17)
    E, k, T = 64, 2, 60
    base_logits = np.zeros(E, dtype=np.float64)
    for t in range(T):
        if t % 18 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum()+1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1.0e-9)))
        topk = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p = probs[topk]; p /= (p.sum()+1e-12)
        viz.update_token(topk, p)
    # before
    m0 = viz.metrics()
    viz.mem.optimize()
    m1 = viz.metrics()
    with open(os.path.join(out_dir, "ltm_opt_metrics.json"), "w") as wf:
        json.dump({"before": m0, "after": m1}, wf, indent=2)

# ==============================
# Micro-benchmarks
# ==============================

def _cli_bench(out_dir: str="./out_bench"):
    os.makedirs(out_dir, exist_ok=True)
    # JVP/VJP bench
    from time import perf_counter
    cov = GoodCover(6, [(i,(i+1)%6) for i in range(6)])
    bb = Backbone(cov, alpha=0.0, beta=0.0)
    x = np.random.randn(bb.tot.n); dx = np.random.randn(bb.tot.n); v = np.random.randn(bb.tot.n)
    ops = ['D_R','L','D_R']*8  # longer chain (still constant matrices)
    t0 = perf_counter(); 
    for _ in range(1000): _ = bb.jvp(x, dx, ops)
    t1 = perf_counter(); 
    for _ in range(1000): _ = bb.vjp(x, v, ops)
    t2 = perf_counter()
    jvp_khz = 1000.0 / (t1 - t0 + 1e-12) / 1e3
    vjp_khz = 1000.0 / (t2 - t1 + 1e-12) / 1e3
    # SH render bench
    sh = SHField(L=16, t_heat=0.01, beta_mem=0.9, n_theta=40, n_phi=80)
    dirs = [np.array([1,0,0],dtype=np.float64), np.array([0,1,0],dtype=np.float64)]
    amps = [0.6,0.4]; sh.update_from_topk(dirs, amps)
    t3 = perf_counter(); 
    for _ in range(10): _ = sh.render(equal_area_correction=False, percentile_norm=True)
    t4 = perf_counter()
    fps = 10.0 / (t4 - t3 + 1e-12)
    with open(os.path.join(out_dir, "bench.json"), "w") as wf:
        json.dump({"jvp_khz": jvp_khz, "vjp_khz": vjp_khz, "sh_fps": fps}, wf, indent=2)

# ==============================
# CLI augment
# ==============================

def main():
    import argparse
    parser = argparse.ArgumentParser(description="QMS: strict S^2 visualization + MoE + LTM + dgLA + SH (+projection,+cubemap,+bench)")
    sub = parser.add_subparsers()

    # existing shortcuts from earlier
    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run S^2 kernel tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    # dgLA
    p_dgla = sub.add_parser("dgla_selftest", help="Run dgLA Čech backbone self-test")
    p_dgla.set_defaults(func=lambda a: _cli_dgla_selftest())

    p_proj = sub.add_parser("dgla_project", help="Project Robin to curvature-zero")
    p_proj.add_argument("--P", default=6, type=int)
    p_proj.add_argument("--beta", default=0.2, type=float)
    p_proj.set_defaults(func=lambda a: _cli_dgla_project(a.P, a.beta))

    # SH
    p_shp = sub.add_parser("sh_precompute", help="Precompute & cache SH basis")
    p_shp.add_argument("--L", default=16, type=int)
    p_shp.add_argument("--n_theta", default=40, type=int)
    p_shp.add_argument("--n_phi", default=80, type=int)
    p_shp.add_argument("--cache_dir", default="/mnt/data", type=str)
    p_shp.set_defaults(func=lambda a: _cli_sh_precompute(a.L, a.n_theta, a.n_phi, a.cache_dir))

    p_shd = sub.add_parser("sh_demo", help="Run SH coefficient demo and save PNG+metrics")
    p_shd.add_argument("--out", default="./out_sh", type=str)
    p_shd.add_argument("--L", default=16, type=int)
    p_shd.add_argument("--n_theta", default=40, type=int)
    p_shd.add_argument("--n_phi", default=80, type=int)
    p_shd.add_argument("--frames", default=48, type=int)
    p_shd.add_argument("--E", default=64, type=int)
    p_shd.add_argument("--k", default=2, type=int)
    p_shd.add_argument("--seed", default=11, type=int)
    p_shd.add_argument("--equal_area", action="store_true")
    p_shd.add_argument("--no_pct", action="store_true")
    p_shd.set_defaults(func=lambda a: _cli_sh_demo(a.out, a.L, a.n_theta, a.n_phi, a.frames, a.E, a.k, a.seed, a.equal_area, not a.no_pct))

    p_sheq = sub.add_parser("sh_equivariance", help="Test phi-rotation equivariance for SH backend")
    p_sheq.add_argument("--L", default=12, type=int)
    p_sheq.add_argument("--n_theta", default=40, type=int)
    p_sheq.add_argument("--n_phi", default=80, type=int)
    p_sheq.add_argument("--shift_cols", default=5, type=int)
    p_sheq.add_argument("--trials", default=5, type=int)
    p_sheq.add_argument("--seed", default=7, type=int)
    p_sheq.set_defaults(func=lambda a: _cli_sh_equivariance(a.L, a.n_theta, a.n_phi, a.shift_cols, a.trials, a.seed))

    # cubemap demo
    p_cube = sub.add_parser("cubemap_demo", help="Render SH field on equal-area cubemap")
    p_cube.add_argument("--out", default="./out_cube", type=str)
    p_cube.add_argument("--L", default=16, type=int)
    p_cube.add_argument("--N", default=32, type=int)
    p_cube.add_argument("--frames", default=48, type=int)
    p_cube.add_argument("--E", default=64, type=int)
    p_cube.add_argument("--k", default=2, type=int)
    p_cube.add_argument("--seed", default=13, type=int)
    p_cube.set_defaults(func=lambda a: _cli_cubemap_demo(a.out, a.L, a.N, a.frames, a.E, a.k, a.seed))

    # LTM optimize
    p_ltm = sub.add_parser("ltm_opt", help="Optimize LTM (reseed/merge/split) after a short run")
    p_ltm.add_argument("--out", default="./out_ltm_opt", type=str)
    p_ltm.set_defaults(func=lambda a: _cli_ltm_opt(a.out))

    # benchmark
    p_bench = sub.add_parser("bench", help="Run micro-benchmarks (JVP/VJP and SH render)")
    p_bench.add_argument("--out", default="./out_bench", type=str)
    p_bench.set_defaults(func=lambda a: _cli_bench(a.out))

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()


# ==============================
# Cartan-compatible Robin projection: minimize ||[D,R]+R^2|| s.t. [R, IOTA]=0
# ==============================

def _vecF(M: np.ndarray) -> np.ndarray:
    return M.reshape(-1, order="F")
def _unvecF(v: np.ndarray, n: int) -> np.ndarray:
    return v.reshape((n,n), order="F")

def project_robin_cartan(Dtot: np.ndarray, IOTA: np.ndarray, R: np.ndarray, mask: np.ndarray=None,
                         tol: float=1e-10, max_iter: int=6) -> tuple[np.ndarray, float, float]:
    """
    Constrained least squares (KKT):
      minimize || [D, Δ] + RΔ + ΔR + C ||_F  subject to  [Δ, IOTA] = -[R, IOTA]
    where C = [D,R] + R^2 and D = Dtot.
    mask (bool) restricts Δ support; default: support of R.
    Returns (R_proj, curvature_norm, cartan_residual_norm).
    """
    n = Dtot.shape[0]
    I = np.eye(n)
    KD = np.kron(np.eye(n), Dtot) - np.kron(Dtot.T, np.eye(n))  # vec([D,Δ])
    KIo = np.kron(np.eye(n), IOTA) - np.kron(IOTA.T, np.eye(n)) # vec([Δ, IOTA])

    Rk = R.copy()
    if mask is None:
        mask = (np.abs(Rk) > 0)
    mask_vec = mask.reshape(-1, order="F")
    cols = np.where(mask_vec)[0]
    if cols.size == 0:
        C = (Dtot @ Rk - Rk @ Dtot) + (Rk @ Rk)
        Cart = Rk @ IOTA - IOTA @ Rk
        return Rk, float(np.linalg.norm(C,2)), float(np.linalg.norm(Cart,2))

    for _ in range(max_iter):
        C = (Dtot @ Rk - Rk @ Dtot) + (Rk @ Rk)
        Cart = Rk @ IOTA - IOTA @ Rk
        nc = float(np.linalg.norm(C, 2))
        ncart = float(np.linalg.norm(Cart, 2))
        if nc <= tol and ncart <= tol:
            return Rk, nc, ncart

        A_ls = KD + np.kron(np.eye(n), Rk) + np.kron(Rk.T, np.eye(n))  # vec([D,Δ] + RΔ + ΔR)
        b_ls = - _vecF(C)

        A_eq = KIo
        b_eq = - _vecF(Cart)

        # restrict columns by mask
        A_ls_red = A_ls[:, cols]
        A_eq_red = A_eq[:, cols]

        # KKT: [2 A^T A  Aeq^T; Aeq 0] [x; λ] = [2 A^T b; b_eq]
        ATA = A_ls_red.T @ A_ls_red
        ATb = A_ls_red.T @ b_ls
        zero = np.zeros((A_eq_red.shape[0], A_eq_red.shape[0]), dtype=np.float64)
        KKT = np.block([[2*ATA, A_eq_red.T],
                        [A_eq_red, zero]])
        rhs = np.concatenate([2*ATb, b_eq], axis=0)
        try:
            sol = np.linalg.lstsq(KKT, rhs, rcond=None)[0]
            d_red = sol[:A_ls_red.shape[1]]
        except Exception:
            # fall back to penalized LS
            lam = 1e4
            M = np.vstack([A_ls_red, math.sqrt(lam)*A_eq_red])
            y = np.concatenate([b_ls, math.sqrt(lam)*b_eq], axis=0)
            d_red = np.linalg.lstsq(M, y, rcond=None)[0]

        d_full = np.zeros(n*n, dtype=np.float64); d_full[cols] = d_red
        dR = _unvecF(d_full, n)
        Rk = Rk + dR

    C = (Dtot @ Rk - Rk @ Dtot) + (Rk @ Rk)
    Cart = Rk @ IOTA - IOTA @ Rk
    return Rk, float(np.linalg.norm(C, 2)), float(np.linalg.norm(Cart,2))

# Backbone hook to use Cartan-compatible projector
try:
    _Backbone_old_init2 = Backbone.__init__
    def _Backbone_new_init2(self, cover, alpha: float=0.0, beta: float=0.0, enforce_square_zero: bool=True, tol: float=1e-12):
        self.cover = cover
        self._alpha, self._beta = alpha, beta
        self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=alpha, beta=beta)
        if (np.abs(self.R).sum() > 0) and enforce_square_zero:
            mask = (np.abs(self.R) > 0)
            Rproj, cn, cart = project_robin_cartan(self.D + self.DEL, self.IOTA, self.R, mask=mask, tol=1e-10, max_iter=8)
            self.R = Rproj
            self.D_R = (self.D + self.DEL) + self.R
            if cn > tol or cart > tol:
                self.tot, self.D, self.IOTA, self.L, self.DEL, self.R, self.D_R = build_operators(cover, alpha=0.0, beta=0.0)
        self.I_incl, self.PI, self.H = build_contraction(cover)
        self.H_R = h_neumann(self.R, self.H, tol=1e-7, max_m=64)
    Backbone.__init__ = _Backbone_new_init2
except Exception:
    pass

def _cli_dgla_project_cartan(P: int=6, beta: float=0.2):
    cov = GoodCover(P, [(i,(i+1)%P) for i in range(P)])
    tot, D, IOTA, L, DEL, R, D_R = build_operators(cov, alpha=0.0, beta=beta)
    mask = (np.abs(R) > 0)
    Rp, cn, cart = project_robin_cartan(D+DEL, IOTA, R, mask=mask, tol=1e-10, max_iter=8)
    print("Cartan-projected: curvature norm =", cn, " Cartan residual =", cart)

# ==============================
# Wigner-D based rotation on SH coefficients (complex) with real<->complex conversion
# ==============================

def _wigner_d_l(l: int, beta: float) -> np.ndarray:
    """Return complex small-d^l(β) matrix of size (2l+1, 2l+1)."""
    from math import factorial, cos, sin
    c = cos(beta/2.0); s = sin(beta/2.0)
    size = 2*l + 1
    d = np.zeros((size, size), dtype=np.complex128)
    # m', m in [-l..l]
    fact = np.vectorize(factorial)
    for mp in range(-l, l+1):
        for m in range(-l, l+1):
            sum_val = 0.0+0.0j
            k_min = max(0, m-mp)
            k_max = min(l+ m, l- mp)
            for k in range(k_min, k_max+1):
                num = ((-1.0)**(k-m+mp)) * math.sqrt(
                    (math.factorial(l+m) * math.factorial(l-m) * math.factorial(l+mp) * math.factorial(l-mp))
                )
                denom = (math.factorial(l+m-k) * math.factorial(k) * math.factorial(k-m+mp) * math.factorial(l-mp-k))
                term = num/denom * (c**(2*l + mp - m - 2*k)) * (s**(2*k + m - mp))
                sum_val += term
            d[mp+l, m+l] = sum_val
    return d

def _complex_D_l(l: int, alpha: float, beta: float, gamma: float) -> np.ndarray:
    """Complex Wigner D^l(α,β,γ) = e^{-i m' α} d^l(β) e^{-i m γ}"""
    m = np.arange(-l, l+1, dtype=np.int64)
    exp_a = np.exp(-1j * m * alpha)
    exp_g = np.exp(-1j * m * gamma)
    d = _wigner_d_l(l, beta)
    return np.outer(exp_a, np.ones_like(exp_a)) * d * np.outer(np.ones_like(exp_g), exp_g)

def _real_complex_maps(L: int) -> tuple[np.ndarray, np.ndarray]:
    """
    Return (M_rc, M_cr) that map real basis -> complex basis and back for all l up to L.
    Real basis ordering matches _lm_index with +m=cos, -m=sin channels.
    Complex basis ordering is m=-l..l per l block.
    """
    blocks_rc = []; blocks_cr = []
    for l in range(0, L+1):
        size = 2*l+1
        Mrc = np.zeros((size, size), dtype=np.complex128)
        Mcr = np.zeros((size, size), dtype=np.complex128)
        base = _lm_index(l, -l)
        # m=0
        Mrc[l, _lm_index(l,0)-base] = 1.0+0.0j
        Mcr[_lm_index(l,0)-base, l] = 1.0+0.0j
        # m>0
        for m in range(1, l+1):
            idx_cos = _lm_index(l, +m) - base
            idx_sin = _lm_index(l, -m) - base
            ic_m  = m + l
            ic_mn = (-m) + l
            sgn = 1.0 if (m % 2 == 0) else -1.0
            # real -> complex
            Mrc[ic_m,   idx_cos] += 1.0/np.sqrt(2.0)
            Mrc[ic_mn,  idx_cos] += sgn/np.sqrt(2.0)
            Mrc[ic_m,   idx_sin] +=  1j/np.sqrt(2.0)
            Mrc[ic_mn,  idx_sin] += -1j*sgn/np.sqrt(2.0)
            # complex -> real (inverse)
            Mcr[idx_cos, ic_m]  += 1.0/np.sqrt(2.0)
            Mcr[idx_sin, ic_m]  += -1j/np.sqrt(2.0)
            Mcr[idx_cos, ic_mn] += sgn/np.sqrt(2.0)
            Mcr[idx_sin, ic_mn] += 1j*sgn/np.sqrt(2.0)
        blocks_rc.append(Mrc); blocks_cr.append(Mcr)
    def _blkdiag(mats):
        n = sum(A.shape[0] for A in mats)
        out = np.zeros((n,n), dtype=np.complex128)
        o = 0
        for A in mats:
            s = A.shape[0]
            out[o:o+s, o:o+s] = A
            o += s
        return out
    M_rc = _blkdiag(blocks_rc)
    M_cr = _blkdiag(blocks_cr)
    return M_rc, M_cr

def rotate_sh_real(c_real: np.ndarray, L: int, alpha: float, beta: float, gamma: float) -> np.ndarray:
    """
    Rotate real SH coefficients by Euler angles (z-y-z convention). Returns real coefficients.
    """
    M_rc, M_cr = _real_complex_maps(L)
    c_comp = M_rc @ c_real.reshape(-1,1)
    # assemble block-diagonal D
    total = sum(2*l+1 for l in range(0, L+1))
    Dblk = np.zeros((total, total), dtype=np.complex128)
    o = 0
    for l in range(0, L+1):
        Dl = _complex_D_l(l, alpha, beta, gamma)
        s_l = 2*l+1
        Dblk[o:o+s_l, o:o+s_l] = Dl
        o += s_l
    c_rot = M_cr @ (Dblk @ c_comp)
    return np.real(c_rot).ravel()

def _cli_sh_rotate_demo(out_dir: str="./out_shrot", L: int=8, n_theta: int=40, n_phi: int=80):
    os.makedirs(out_dir, exist_ok=True)
    sh = SHField(L=L, t_heat=0.01, beta_mem=0.0, n_theta=n_theta, n_phi=n_phi)
    # seed with a couple of impulses
    dirs = [np.array([1,0,0],dtype=np.float64), np.array([0,1,0],dtype=np.float64)]
    amps = [0.7, 0.3]
    sh.update_from_topk(dirs, amps, to_memory=False)
    img0 = sh.render(equal_area_correction=False, percentile_norm=False)
    # rotate coefficients by Euler angles and render again
    a,b,g = 0.3, 0.5, 0.2
    v = sh.c_st.copy()
    v_rot = rotate_sh_real(v, L, a,b,g)
    # temp swap into SHField and render
    old_st = sh.c_st.copy()
    sh.c_st[:] = v_rot; img1 = sh.render(equal_area_correction=False, percentile_norm=False); sh.c_st[:] = old_st
    try:
        import matplotlib.pyplot as plt
        # save side-by-side
        plt.figure(figsize=(6.4,3.0)); plt.imshow(img0, aspect='auto'); plt.title("before"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "before.png"), dpi=130); plt.close()
        plt.figure(figsize=(6.4,3.0)); plt.imshow(img1, aspect='auto'); plt.title("after rotate"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "after.png"), dpi=130); plt.close()
    except Exception:
        pass

# ==============================
# LTM auto-threshold adaptation
# ==============================

def ltm_auto_optimize(viz: "MoEVisualizerLTM") -> dict:
    """
    Adapt thresholds from current KPI, then call viz.mem.optimize().
    Heuristics:
      - if Gini or HHI high -> split_weight down (encourage splits)
      - if N_eff low -> reseed_thresh up
      - drift_ema low -> merge_cos up (more merging)
    """
    m = viz.metrics()
    gini = float(m.get("Gini", 0.0))
    hhi  = float(m.get("HHI", 0.0))
    n_eff = float(m.get("N_eff", 0.0))
    # defaults
    reseed = 1e-3; merge_cos = 0.98; split_weight = 0.2
    # tune
    if gini>0.5 or hhi>0.1:   # concentrated
        split_weight = max(0.1, 0.2 - 0.05)
    if n_eff<2.0:
        reseed = 2e-3
    if gini<0.2:
        merge_cos = 0.985
    # apply
    try:
        viz.mem.optimize(reseed_thresh=reseed, merge_cos=merge_cos, split_weight=split_weight)
    except Exception:
        pass
    return {"reseed_thresh": reseed, "merge_cos": merge_cos, "split_weight": split_weight, "metrics_before": m, "metrics_after": viz.metrics()}

def _cli_ltm_auto(out_dir: str="./out_ltm_auto"):
    os.makedirs(out_dir, exist_ok=True)
    viz = MoEVisualizerLTM(L_low=8, L_high=16, t_heat=0.01, alpha_hi=0.6,
                           capacity=128, decay=0.94, n_theta=40, n_phi=80, seed=404,
                           M_mem=24, eta_mem=0.06, decay_mem=0.996, beta_mem=0.9)
    # short run
    rng = np.random.default_rng(23)
    E,k,T=64,2,60
    base_logits = np.zeros(E, dtype=np.float64)
    for t in range(T):
        if t % 17 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum()+1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1.0e-9)))
        topk = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p = probs[topk]; p /= (p.sum()+1e-12)
        viz.update_token(topk, p)
    cfg = ltm_auto_optimize(viz)
    with open(os.path.join(out_dir, "ltm_auto.json"), "w") as wf:
        json.dump(cfg, wf, indent=2)

# ==============================
# Experimental visualizations
# ==============================

def _cli_beta_sweep(out_dir: str="./out_beta_sweep"):
    """
    Sweep beta for Robin, apply Cartan projection, and plot pre/post curvature norms.
    """
    os.makedirs(out_dir, exist_ok=True)
    betas = np.linspace(0.0, 0.5, 11)
    pre = []; post = []
    cov = GoodCover(6, [(i,(i+1)%6) for i in range(6)])
    for beta in betas:
        tot, D, IOTA, L, DEL, R, D_R = build_operators(cov, alpha=0.0, beta=float(beta))
        pre.append(float(np.linalg.norm(D_R@D_R,2)))
        Rp, cn, cart = project_robin_cartan(D+DEL, IOTA, R, mask=(np.abs(R)>0), tol=1e-10, max_iter=8)
        D_Rp = (D+DEL) + Rp
        post.append(float(np.linalg.norm(D_Rp@D_Rp,2)))
    try:
        import matplotlib.pyplot as plt
        plt.figure()
        plt.plot(betas, pre, label="pre")
        plt.plot(betas, post, label="post")
        plt.xlabel("beta"); plt.ylabel("|| (D_R)^2 ||_2"); plt.title("Curvature norms (pre/post)")
        plt.legend()
        plt.tight_layout(); plt.savefig(os.path.join(out_dir, "beta_sweep.png"), dpi=130); plt.close()
    except Exception:
        pass

def _cli_latlong_vs_cubemap(out_dir: str="./out_ll_vs_cube", L: int=12, N: int=24, frames: int=48):
    os.makedirs(out_dir, exist_ok=True)
    sh = SHField(L=L, t_heat=0.01, beta_mem=0.9, cache_dir="/mnt/data", n_theta=40, n_phi=80)
    rng = np.random.default_rng(31)
    E,k = 64,2
    base_logits = np.zeros(E, dtype=np.float64)
    for t in range(frames):
        if t % 16 == 0:
            j = rng.integers(E); base_logits[j] += rng.uniform(0.2, 0.8)
        probs = np.exp(base_logits - np.max(base_logits)); probs /= (probs.sum()+1e-12)
        g = -np.log(-np.log(np.clip(rng.random(E), 1e-9, 1.0-1.0e-9)))
        topk = np.argsort(-(np.log(probs+1e-20) + g))[:k]
        p = probs[topk]; p /= (p.sum()+1e-12)
        dirs = [expert_to_unitvec(int(eid))[0] for eid in topk]
        sh.update_from_topk(dirs, list(p), to_memory=True)
    img_ll = sh.render(equal_area_correction=True, percentile_norm=True)
    img_cb = sh_render_cubemap(sh, N=N, percentile_norm=True)
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(6.4,3.0)); plt.imshow(img_ll, aspect='auto'); plt.title("latlong (equal-area corrected)"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "latlong.png"), dpi=130); plt.close()
        plt.figure(figsize=(7.2,4.8)); plt.imshow(img_cb, aspect='auto'); plt.title("cubemap (equal-area)"); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "cubemap.png"), dpi=130); plt.close()
    except Exception:
        pass

# ==============================
# CLI augment (final)
# ==============================

def main():
    import argparse
    parser = argparse.ArgumentParser(description="QMS: unified (QMS-256 + S^2 + dgLA + SH + projection + cubemap + auto-LTM + viz)")
    sub = parser.add_subparsers()

    p_ascii = sub.add_parser("ascii", help="ASCII demo of QMS→S^2 impulses")
    p_ascii.set_defaults(func=lambda a: _demo_qms_ascii())

    p_moe = sub.add_parser("moe", help="MoE short-term demo (PNG+ASCII)")
    p_moe.add_argument("--out", default="./out_strict", type=str)
    p_moe.add_argument("--frames", default=60, type=int)
    p_moe.set_defaults(func=lambda a: _demo_moe(a.out, frames=a.frames))

    p_moe_ltm = sub.add_parser("moe_ltm", help="MoE + LTM demo (PNG+ASCII+JSON)")
    p_moe_ltm.add_argument("--out", default="./out_strict", type=str)
    p_moe_ltm.add_argument("--frames", default=72, type=int)
    p_moe_ltm.set_defaults(func=lambda a: _demo_moe_ltm(a.out, frames=a.frames))

    p_test = sub.add_parser("selftest", help="Run S^2 kernel tests")
    p_test.add_argument("--L", default=8, type=int)
    p_test.add_argument("--t", default=0.01, type=float)
    p_test.set_defaults(func=_cmd_selftest)

    p_dgla = sub.add_parser("dgla_selftest", help="Run dgLA Čech backbone self-test")
    p_dgla.set_defaults(func=lambda a: _cli_dgla_selftest())

    p_proj = sub.add_parser("dgla_project", help="Project Robin to curvature-zero")
    p_proj.add_argument("--P", default=6, type=int)
    p_proj.add_argument("--beta", default=0.2, type=float)
    p_proj.set_defaults(func=lambda a: _cli_dgla_project(a.P, a.beta))

    p_proj2 = sub.add_parser("dgla_project_cartan", help="Cartan-compatible projection of Robin")
    p_proj2.add_argument("--P", default=6, type=int)
    p_proj2.add_argument("--beta", default=0.2, type=float)
    p_proj2.set_defaults(func=lambda a: _cli_dgla_project_cartan(a.P, a.beta))

    p_shp = sub.add_parser("sh_precompute", help="Precompute & cache SH basis")
    p_shp.add_argument("--L", default=16, type=int)
    p_shp.add_argument("--n_theta", default=40, type=int)
    p_shp.add_argument("--n_phi", default=80, type=int)
    p_shp.add_argument("--cache_dir", default="/mnt/data", type=str)
    p_shp.set_defaults(func=lambda a: _cli_sh_precompute(a.L, a.n_theta, a.n_phi, a.cache_dir))

    p_shd = sub.add_parser("sh_demo", help="Run SH coefficient demo and save PNG+metrics")
    p_shd.add_argument("--out", default="./out_sh", type=str)
    p_shd.add_argument("--L", default=16, type=int)
    p_shd.add_argument("--n_theta", default=40, type=int)
    p_shd.add_argument("--n_phi", default=80, type=int)
    p_shd.add_argument("--frames", default=48, type=int)
    p_shd.add_argument("--E", default=64, type=int)
    p_shd.add_argument("--k", default=2, type=int)
    p_shd.add_argument("--seed", default=11, type=int)
    p_shd.add_argument("--equal_area", action="store_true")
    p_shd.add_argument("--no_pct", action="store_true")
    p_shd.set_defaults(func=lambda a: _cli_sh_demo(a.out, a.L, a.n_theta, a.n_phi, a.frames, a.E, a.k, a.seed, a.equal_area, not a.no_pct))

    p_sheq = sub.add_parser("sh_equivariance", help="Test phi-rotation equivariance for SH backend")
    p_sheq.add_argument("--L", default=12, type=int)
    p_sheq.add_argument("--n_theta", default=40, type=int)
    p_sheq.add_argument("--n_phi", default=80, type=int)
    p_sheq.add_argument("--shift_cols", default=5, type=int)
    p_sheq.add_argument("--trials", default=5, type=int)
    p_sheq.add_argument("--seed", default=7, type=int)
    p_sheq.set_defaults(func=lambda a: _cli_sh_equivariance(a.L, a.n_theta, a.n_phi, a.shift_cols, a.trials, a.seed))

    p_shrot = sub.add_parser("sh_rotate_demo", help="Rotate SH coefficients using Wigner-D and render")
    p_shrot.add_argument("--out", default="./out_shrot", type=str)
    p_shrot.add_argument("--L", default=8, type=int)
    p_shrot.add_argument("--n_theta", default=40, type=int)
    p_shrot.add_argument("--n_phi", default=80, type=int)
    p_shrot.set_defaults(func=lambda a: _cli_sh_rotate_demo(a.out, a.L, a.n_theta, a.n_phi))

    p_cube = sub.add_parser("cubemap_demo", help="Render SH field on equal-area cubemap")
    p_cube.add_argument("--out", default="./out_cube", type=str)
    p_cube.add_argument("--L", default=16, type=int)
    p_cube.add_argument("--N", default=32, type=int)
    p_cube.add_argument("--frames", default=48, type=int)
    p_cube.add_argument("--E", default=64, type=int)
    p_cube.add_argument("--k", default=2, type=int)
    p_cube.add_argument("--seed", default=13, type=int)
    p_cube.set_defaults(func=lambda a: _cli_cubemap_demo(a.out, a.L, a.N, a.frames, a.E, a.k, a.seed))

    p_ltm = sub.add_parser("ltm_opt", help="Optimize LTM (reseed/merge/split) after a short run")
    p_ltm.add_argument("--out", default="./out_ltm_opt", type=str)
    p_ltm.set_defaults(func=lambda a: _cli_ltm_opt(a.out))

    p_ltm2 = sub.add_parser("ltm_auto", help="Auto-adapt LTM thresholds from KPI")
    p_ltm2.add_argument("--out", default="./out_ltm_auto", type=str)
    p_ltm2.set_defaults(func=lambda a: _cli_ltm_auto(a.out))

    p_bench = sub.add_parser("bench", help="Run micro-benchmarks (JVP/VJP and SH render)")
    p_bench.add_argument("--out", default="./out_bench", type=str)
    p_bench.set_defaults(func=lambda a: _cli_bench(a.out))

    p_beta = sub.add_parser("beta_sweep", help="Plot curvature norms pre/post Cartan projection vs beta")
    p_beta.add_argument("--out", default="./out_beta_sweep", type=str)
    p_beta.set_defaults(func=lambda a: _cli_beta_sweep(a.out))

    p_llc = sub.add_parser("ll_vs_cube", help="Compare latlong vs cubemap renderings")
    p_llc.add_argument("--out", default="./out_ll_vs_cube", type=str)
    p_llc.add_argument("--L", default=12, type=int)
    p_llc.add_argument("--N", default=24, type=int)
    p_llc.add_argument("--frames", default=48, type=int)
    p_llc.set_defaults(func=lambda a: _cli_latlong_vs_cubemap(a.out, a.L, a.N, a.frames))

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args) if callable(args.func) else args.func
    else:
        parser.print_help()

if __name__ == "__main__":
    main()


# ===== HQ Numerics: Stable Wigner-D rotation (lgamma) and rotate_sh_real =====
import math as _math

def _wigner_d_l_lgamma(l: int, beta: float) -> np.ndarray:
    """Numerically stable small-d^l(β) using lgamma (complex128)."""
    from math import cos, sin, lgamma, exp
    c = cos(beta/2.0); s = sin(beta/2.0)
    size = 2*l + 1
    d = np.zeros((size, size), dtype=np.complex128)
    for mp in range(-l, l+1):
        for m in range(-l, l+1):
            k_min = max(0, m-mp)
            k_max = min(l+m, l-mp)
            acc = 0.0+0.0j
            for k in range(k_min, k_max+1):
                log_num = 0.5*( lgamma(l+m+1)+lgamma(l-m+1)+lgamma(l+mp+1)+lgamma(l-mp+1) )
                log_den = lgamma(l+m-k+1)+lgamma(k+1)+lgamma(k-m+mp+1)+lgamma(l-mp-k+1)
                phase = (-1.0)**(k-m+mp)
                pow_c = (2*l + mp - m - 2*k)
                pow_s = (2*k + m - mp)
                coeff = phase * _math.exp(log_num - log_den) * (c**pow_c) * (s**pow_s)
                acc += coeff
            d[mp+l, m+l] = acc
    return d

def _complex_D_l_lgamma(l: int, alpha: float, beta: float, gamma: float) -> np.ndarray:
    m = np.arange(-l, l+1, dtype=np.int64)
    exp_a = np.exp(-1j * m * alpha)
    exp_g = np.exp(-1j * m * gamma)
    d = _wigner_d_l_lgamma(l, beta)
    return np.outer(exp_a, np.ones_like(exp_a)) * d * np.outer(np.ones_like(exp_g), exp_g)

def rotate_sh_real(c_real: np.ndarray, L: int, alpha: float, beta: float, gamma: float) -> np.ndarray:
    """
    Rotate real SH coefficients by Euler angles (z-y-z). Uses internal real<->complex maps.
    Falls back to identity if maps are unavailable.
    """
    try:
        M_rc, M_cr = _real_complex_maps(L)  # provided earlier in QMS.py
    except Exception:
        return c_real.copy()
    c_comp = M_rc @ c_real.reshape(-1,1)
    total = sum(2*l+1 for l in range(0, L+1))
    Dblk = np.zeros((total, total), dtype=np.complex128)
    o = 0
    for l in range(0, L+1):
        Dl = _complex_D_l_lgamma(l, alpha, beta, gamma)
        s_l = 2*l+1
        Dblk[o:o+s_l, o:o+s_l] = Dl
        o += s_l
    c_rot = M_cr @ (Dblk @ c_comp)
    return np.real(c_rot).ravel()


# ===== QA Harness (Cartan/Curvature, phi-equivar, Wigner-D stability) =====
from dataclasses import dataclass, asdict
from typing import Dict, Any

@dataclass
class QAConfig:
    L: int = 8
    n_theta: int = 20
    n_phi: int = 40
    rng_seed: int = 7
    beta: float = 0.2
    cartan_tol: float = 1e-10
    curvature_tol: float = 1e-10
    equiv_tol: float = 1e-9

def run_qa(cfg: QAConfig) -> Dict[str, Any]:
    res: Dict[str, Any] = {"config": asdict(cfg)}
    ok = True
    # 1) Cartan-compatible Robin projection
    try:
        if 'GoodCover' in globals() and 'build_operators' in globals() and 'project_robin_cartan' in globals():
            cov = GoodCover(6, [(i,(i+1)%6) for i in range(6)])
            tot, D, IOTA, Lx, DEL, R, D_R = build_operators(cov, alpha=0.0, beta=cfg.beta)
            Rp, cn, cart = project_robin_cartan(D+DEL, IOTA, R, mask=(np.abs(R)>0), tol=cfg.cartan_tol, max_iter=8)
            res["cartan"] = {"curvature_norm": float(cn), "cartan_resid": float(cart)}
            if not (cn <= cfg.curvature_tol and cart <= cfg.cartan_tol): ok = False
        else:
            res["cartan"] = "skipped"
    except Exception as e:
        res["cartan"] = f"error: {e}"; ok = False

    # 2) phi-rotation equivariance test
    try:
        if '_cli_sh_equivariance' in globals():
            err = _cli_sh_equivariance(L=cfg.L, n_theta=cfg.n_theta, n_phi=cfg.n_phi, shift_cols=3, trials=3, seed=cfg.rng_seed)
            res["equivariance_phi_relerr"] = float(err)
            if err > cfg.equiv_tol: ok = False
        else:
            res["equivariance_phi_relerr"] = "skipped"
    except Exception as e:
        res["equivariance_phi_relerr"] = f"error: {e}"; ok = False

    # 3) Wigner-D stability: compare to self-rotation if available (else just compute once)
    try:
        if 'SHField' in globals():
            sh = SHField(L=cfg.L, t_heat=0.01, beta_mem=0.0, n_theta=cfg.n_theta, n_phi=cfg.n_phi)
            dirs = [np.array([1,0,0],dtype=np.float64), np.array([0,1,0],dtype=np.float64)]
            amps = [0.6, 0.4]
            sh.update_from_topk(dirs, amps, to_memory=False)
            v = sh.c_st.copy()
            a,b,g = 0.31, 0.52, 0.27
            v_st = rotate_sh_real(v, cfg.L, a,b,g)
            # if a legacy rotate was defined elsewhere, we can't easily fetch; report norm as sanity
            res["wigner_rot_norm"] = float(np.linalg.norm(v_st))
        else:
            res["wigner_rot_norm"] = "skipped"
    except Exception as e:
        res["wigner_rot_norm"] = f"error: {e}"; ok = False

    res["ok"] = ok
    return res


# ===== Minimal CLI for HQ features =====
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="QMS (with HQ numerics/QA)")
    sub = parser.add_subparsers()

    pqa = sub.add_parser("qa", help="Run QA suite and print JSON")
    pqa.add_argument("--L", type=int, default=8)
    pqa.add_argument("--n_theta", type=int, default=20)
    pqa.add_argument("--n_phi", type=int, default=40)
    pqa.add_argument("--beta", type=float, default=0.2)
    pqa.add_argument("--equiv_tol", type=float, default=1e-9)
    pqa.set_defaults(func=lambda a: print(json.dumps(run_qa(QAConfig(L=a.L, n_theta=a.n_theta, n_phi=a.n_phi, beta=a.beta, equiv_tol=a.equiv_tol)), indent=2)))

    prot = sub.add_parser("rotate_demo", help="Rotate one SH impulse using stable Wigner-D")
    prot.add_argument("--L", type=int, default=8)
    prot.add_argument("--alpha", type=float, default=0.3)
    prot.add_argument("--beta", type=float, default=0.5)
    prot.add_argument("--gamma", type=float, default=0.2)
    def _run_rot(a):
        if 'SHField' not in globals():
            print("SHField unavailable"); return
        sh = SHField(L=a.L, t_heat=0.01, beta_mem=0.0, n_theta=20, n_phi=40)
        dirs = [np.array([1,0,0],dtype=np.float64)]
        sh.update_from_topk(dirs, [1.0], to_memory=False)
        v = sh.c_st.copy()
        v2 = rotate_sh_real(v, a.L, a.alpha, a.beta, a.gamma)
        print("norms:", float(np.linalg.norm(v)), float(np.linalg.norm(v2)))
    prot.set_defaults(func=_run_rot)

    args = parser.parse_args()
    if hasattr(args, "func"):
        args.func(args)
    else:
        parser.print_help()
