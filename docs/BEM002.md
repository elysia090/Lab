BEM v0.0.1 – Boolean Expert Machine
Hardware-Oriented Core, ISA, and Algorithms
(Integrated English ASCII Draft, no separators)
	0.	Scope and Goals

0.1 Purpose

This document defines the Boolean Expert Machine (BEM) v0.0.1 as a hardware-oriented, finite-state abstract machine with:
	1.	A single integer control core plus a fixed set of co-processors.
	2.	A fast path that uses only integer arithmetic and bitwise operations, with bounded per-step cost independent of episode length and total steps.
	3.	A family of Boolean experts acting as local state transformers over bit-sliced state.
	4.	Online learning via bandit-style expert selection and log-domain weight updates plus a GRPO-like mid-path update.
	5.	Structural updates (expert split/merge, macro extraction, circuit rewrites) subject to formal verification.
	6.	Interfaces for self-play, synthetic experiments, and counterexample-guided refinement.
	7.	A minimal RISC ISA and explicit algorithms for routing, learning, scheduling, and patch verification.

0.2 Non-goals

BEM v0.0.1 does not define:
	1.	Concrete binary encodings or micro-architectural details.
	2.	Concrete performance targets or power envelopes.
	3.	Any host programming language, ABI, or OS integration.
	4.	Floating-point primitives or neural networks on the fast path.

Neural or floating-point components may exist outside the core (for example in ANN, PROVER, or task generators) as untrusted proposal or oracle modules. All proposals must be validated through the verification kernel before affecting the trusted configuration.

0.3 Notation and Complexity

Bits are elements of {0,1}. Bitvectors of length n are elements of {0,1}^n. Integers are elements of Z with fixed-width representations.

Per-step complexity refers to control-core cycles and co-processor invocations triggered by one logical step (event or token). Fast-path cost must be bounded by a constant independent of:
	•	Episode length.
	•	Total number of past steps.

Parameters:
	•	N: number of global state bits.
	•	K: number of shared memory bits (K >= N).
	•	P: number of fixed-point parameters.
	•	W: SIMD width (lanes).
	•	S: maximum number of experts (slots in EXPERT table).
	•	d: dimension of feature bits for routing (for example 64 to 256).
	•	k_large: ANN candidate size (for example 16 to 64).
	•	k_small: final routing candidate size (for example 1 to 4).
	•	D_max: maximum graph search depth inside ANN.
	•	M_max: maximum neighbor degree in ANN.
	•	G: GRPO-lite group size (for example 4 or 8).
	•	d_ctx: context feature dimension for scheduler (for example 8 or 16).

All are fixed at design or configuration time.
	1.	Machine State and Identifiers

1.1 Logical State

The logical state at time t is:

X_t = (s_t, M_t, Theta_t)

where:
	•	s_t in {0,1}^N: global state bits (bit-sliced over W lanes physically).
	•	M_t in {0,1}^K: shared memory bits.
	•	Theta_t in Z^P: fixed-point parameters.

Fast path reads and writes s_t and M_t and may read Theta_t. Structural update and verification may modify Theta_t and structural tables.

1.2 Configuration

Structural configuration C includes:
	•	EXPERT table (experts, stats, routing metadata).
	•	CFG (instruction array and CFG metadata).
	•	ANN index and routing metadata.
	•	INVAR and PROOF configuration.
	•	WORK configuration (PoX weights and scheduler parameters).
	•	LAYOUT and ID maps.

Fast path may read C but must not modify it directly. All structural changes proceed via patches.

1.3 Identifier Space

Domain U = {0, 1, …, 2^32 - 1}. Each identifier u in U is structured:

u = [class(6) | ecc(6) | shard(6) | local(14)]

where:
	•	class in {0..63}: object class (expert, cfg_node, variable, template, hypothesis, etc).
	•	ecc in {0..63}: parity or ECC bits for shard and local.
	•	shard in {0..63}: logical shard index.
	•	local in {0..16383}: shard-local index.

Gray encoding:

g(u) = u xor (u >> 1)

Hamming distance d_H(a, b) is number of differing bits. A simple similarity:

sim(u, v) = 32 - d_H(g(u), g(v))

1.4 Slot Mapping

Objects with tabular storage (experts, macros) use a slot function:

slot: U -> {0..S-1} union {bottom}

For allocated expert identifier u:
	•	i = slot(u) in {0..S-1}.
	•	EXPERT[i] is descriptor for u.

Requirements:
	1.	slot(u) != bottom for any allocated expert u.
	2.	If u != v and both are allocated experts, then slot(u) != slot(v).
	3.	slot mapping and its inverse are stored in SHARED.
	4.	Rebalancing may change slot(u), but must preserve:
	•	Object content.
	•	Semantics of references that use identifiers u.

1.5 Task and Context Identifiers

Per-step metadata:
	•	task_id_t in Z_small: integer distinguishing task families.
	•	context_hash_t in Z_32 or Z_64: rolling hash summarizing recent observations, rewards, and actions.

These reside in STATE or SHARED and are computed by deterministic functions:

task_id_t = T_id(s_t, M_t, external_task_config)
context_hash_t = H_ctx(context_hash_{t-1}, obs_{t-1}, r_{t-1}, a_{t-1})

H_ctx uses integer arithmetic and bitwise operations only.
	2.	Memory Segments

2.1 Logical Segments
	1.	STATE
	•	Holds bit-sliced representation of s_t over W lanes.
	•	STATE[k] in {0,1}^W for k in {0..N-1}.
	2.	SHARED
	•	Holds M_t, Theta_t, configuration, routing metadata, bandit and GRPO stats, scheduler statistics, counters, ANN descriptors, etc.
	3.	EXPERT
	•	Entries EXPERT[0..S-1] with expert descriptors, circuits, stats.
	4.	CFG
	•	Instruction array C[0..L-1], CFG node metadata, macro descriptors.
	5.	TRACE
	•	Step-level traces, episode summaries, patch metadata, PoX entries.
	6.	PROOF
	•	CNF formulas, solver contexts, proof objects, unsat cores, CEGIS data.
	7.	WORK
	•	PoX configuration, difficulty, moving averages, scheduler matrices and vectors.

Segments are logically disjoint. Physical mapping is implementation-specific but must preserve semantic isolation.

2.2 STATE Segment Representation

For each bit index k in [0, N):
	•	S_pl[k] in {0,1}^W holds bit k for all lanes.

Lane l view of s_t:

s_t^(l)[k] = bit l of S_pl[k]

Shared memory M_t and parameters Theta_t are not bit-sliced.

2.3 EXPERT Entry Format

For each slot i:

EXPERT[i] = (id_i, R_spec_i, W_spec_i, C_rep_i, stats_i, params_i, routing_meta_i)

where:
	•	id_i in U: expert identifier.
	•	R_spec_i: input selection specification.
	•	W_spec_i: write-back specification.
	•	C_rep_i: Boolean circuit representation.
	•	stats_i includes:
	•	wins_total_i, visits_total_i.
	•	Per-task arrays:
	•	wins_i_tau, visits_i_tau, last_update_step_i.
	•	params_i includes:
	•	z_i: log-weight (fixed-point).
	•	L_i_tau, S_i_tau: cumulative loss and squared loss for adaptive eta.
	•	routing_meta_i:
	•	priority tags, macro tags, version, index metadata.

2.4 CFG Segment
	•	C[pc] is an abstract instruction executed by BEM-CORE.
	•	CFG nodes v in U (class cfg_node) include:
	•	pc_start[v], pc_end[v].
	•	Succ(v): successor node ids.
	•	Optional local invariants P_v (CNF in PROOF).

Macros:
	•	Represent common expert sequences or hot CFG fragments.
	•	Macro nodes reference subprograms or expert sequences.

	3.	Hardware Modules

3.1 BEM-CORE

BEM-CORE executes the ISA:
	•	Integer arithmetic and bitwise operations.
	•	Control flow.
	•	Scalar loads and stores.
	•	Co-processor commands.

It is responsible for:
	•	Fast-path loop control.
	•	Mid-path learning and scheduler updates.
	•	Scheduling of slow-path tasks (verification, structural updates).

3.2 BIT-ALU

BIT-ALU operates on W-bit bitvectors:
	•	AND, OR, XOR, NOT.
	•	Shifts and rotates.
	•	POPCOUNT and parity.
	•	Mask-based blends.

Latency of BIT-ALU operations must be bounded by a small constant.

3.3 ANN Unit

Interface:

ANN_QUERY(desc_ptr) -> candidate_list_ptr

Descriptor in SHARED:
	•	q: 32-bit key.
	•	f: feature bitvector of length d.
	•	k: desired number of candidates (<= k_large).
	•	config: routing configuration for task.

Output list:
	•	count (<= k).
	•	Sequence of slot indices or identifiers.

Internal constraints:
	•	Search depth <= D_max.
	•	Per-node degree <= M_max.
	•	Worst-case query cost bounded by constant given D_max and M_max.

3.4 SAT and CEGIS Unit (PROVER)

Interfaces:
	•	SAT_CHECK(cnf_id, options) -> SAT, UNSAT, UNKNOWN, with optional unsat_core_id.
	•	PROOF_CHECK(cnf_id, proof_id) -> ACCEPT or REJECT.
	•	HOARE_CHECK(cfg_id, annotations_id) -> ACCEPT or REJECT.
	•	CEGIS(phi_id, hyp_class_id, options) -> candidate_id or NONE, counterexample_id or NONE.

Supports:
	•	Incremental CNF with base contexts.
	•	Unsat core extraction.
	•	Multiple solver profiles and circuit-aware heuristics chosen by BEM-CORE.

3.5 HASH and ECC Unit

Responsibilities:
	•	ECC encode and decode for identifiers and memory blocks.
	•	Hash computation Hash: {0,1}* -> {0,1}^h (for example h = 256).
	•	Merkle tree updates.
	•	Hash chains: H_{k+1} = Hash(H_k || entry_k).

3.6 LOG Unit

Responsibilities:
	•	Append structured entries to TRACE.
	•	Maintain hash chain H_k in protected state.
	•	Maintain counters and moving averages for PoX and drift metrics.

	4.	Observation and Routing Inputs

4.1 Observation Function

Observation is a deterministic function:

obs_t = O(s_t, M_t) = (task_id_t, context_hash_t, local_bits_t, feature_bits_t)

Components:
	•	task_id_t:
	•	Stable for the duration of a benchmark task family.
	•	Derived from configuration and environment.
	•	context_hash_t:
	•	32- or 64-bit rolling hash:
context_hash_t = H_ctx(context_hash_{t-1}, small summary of obs_{t-1}, r_{t-1}, a_{t-1}).
	•	Implemented via integer multiply-add and xor.
	•	local_bits_t:
	•	Fixed subset of bits from s_t and M_t, configured per task.
	•	feature_bits_t in {0,1}^d:
	•	Derived from F_feat(s_t, M_t, context_hash_t).
	•	For example via random projections and thresholds or sketches.

4.2 Query Key

From obs_t:

q_t = F_id(task_id_t, context_hash_t)

Example:
	•	q_t = low32(Hash256(task_id_t || context_hash_t))

F_id must distribute contexts across shards using integer and bit operations only.

4.3 Shards and Buckets

ANN Unit derives:
	•	shard_id = high bits or Gray-coded prefix of q_t.
	•	bucket_id = selected bits of q_t.

Index structure:

index[shard_id][bucket_id] = small set of candidate experts plus local graph or cache.
	5.	Expert Semantics and Circuits

5.1 Expert as Local Transformer

Given global state (s, M), expert i defines:

x = R_i(s, M) in {0,1}^{n_i}
y = C_i(x) in {0,1}^{m_i}
(s’, M’) = W_i(s, M, y)

where:
	•	R_i is determined by R_spec_i:
	•	Bit indices into s and M.
	•	Simple address expressions.
	•	C_i is given by C_rep_i:
	•	Either ANF or ROBDD-like form.
	•	W_i is determined by W_spec_i:
	•	Write-back to specific bits or contiguous regions.
	•	Optional lane masks derived from y.

5.2 Circuit Representation

ANF form:
	•	Each output y_j is xor of monomials, each monomial being an AND of subset of inputs.

ROBDD form:
	•	DAG with nodes representing tests on specific input bits.
	•	Canonical variable ordering.
	•	Reduced graph.

Common requirements:
	•	Circuits must support bit-sliced evaluation:
	•	Inputs x for all lanes are packed in W-bit words.
	•	All intermediate values are W-bit.
	•	Operations use BIT-ALU primitives.

5.3 Fast-Path Evaluation Bound

Design-time bounds:
	•	n_i <= N_in_max.
	•	m_i <= N_out_max.
	•	Monomial count per output <= M_mono_max.

Total cost per expert evaluation is bounded:

Cost_expert(i) <= C_expert_max

C_expert_max depends on N_in_max, N_out_max, M_mono_max but not on episode length.
	6.	Fast-Path Control and Routing

6.1 Two-Stage Routing Algorithm

At each step t:
	1.	Observation: obs_t = O(s_t, M_t).
	2.	Query: (q_t, f_t) = (F_id(task_id_t, context_hash_t), feature_bits_t).
	3.	ANN candidate retrieval: C_large = ANN_QUERY(q_t, f_t, k_large, config(task_id_t)).
	4.	Bandit-based filtering:
	•	For task tau = task_id_t and each i in C_large:
	•	Compute exploitation mean and exploration bonus based on visits and wins.
	•	Combine with log-weight z_i.
	•	Select a subset C_t of size k_small, or sample expert i_t.
	5.	Expert batch evaluation:
	•	BEM_EXPERT_BATCH(i_t or C_t, STATE, SHARED).
	6.	Minimal stats updates (Algorithm B).

Fast path must not call SAT, heavy CEGIS, or structural updates.

6.2 Lane-Level Assignment

Assignment strategies:
	•	Single expert for all lanes: i_t applied to each lane independently.
	•	Grouped lanes: lanes partitioned into groups, one expert per group.
	•	Per-lane expert: allowed but must remain bit-sliced and masked.

BEM_EXPERT_BATCH applies R_spec, C_rep, W_spec consistently across lanes.

6.3 Fast-Path Complexity

Per step t, fast-path cost must satisfy:

Cost_step <= C_obs + C_ANN + C_route + C_expert_batch + C_stats

All C_* depend only on configuration constants and not on episode length.
	7.	Learning and Bandits

7.1 Per-Step Reward and Loss

Per step t:
	•	Reward r_t is bounded: r_t in [R_min, R_max].
	•	BAD_t in {0,1} denotes safety violation indicator.
	•	Cost proxy cost_t >= 0 approximates per-step fast-path cycles.

Instantaneous payoff:

u_t = r_t - lambda_bad * BAD_t - lambda_cost * cost_t

Primary per-step bandit loss:

For expert i at task tau:

loss_t(i) = -r_t if i = i_t, and 0 otherwise.

7.2 Per-Step Bandit Statistics

For each expert i, task tau:
	•	visits_i_tau, wins_i_tau.
	•	visits_total_i, wins_total_i.
	•	N_tau: total visits for task tau.

Update per step with Algorithm B.

7.3 Log-Domain Update and GRPO-Lite

Mid-path weight update consists of:
	•	Bandit-style log-domain updates using cumulative loss L_i_tau and squared loss S_i_tau.
	•	GRPO-lite group-relative updates based on episode returns.

Log-domain update:
	•	hat_l = L_i_tau / max(1, visits_i_tau).
	•	hat_l_clipped = clamp(hat_l, -L_max, L_max).
	•	eta_i_tau = c_eta / sqrt(S_i_tau + epsilon_eta).
	•	delta_z = eta_i_tau * hat_l_clipped, clipped to Delta_z_max.
	•	z_i’ = z_i - delta_z.

GRPO-lite update:
	•	Group episodes by key, compute group-standardized advantages A_j.
	•	Accumulate per expert and task, then update z_i with eta_grpo * A_bar.

Both updates are integer fixed-point and executed mid-path.
	8.	Structural Updates and Templates

8.1 Logging

TRACE stores:
	•	Per-step entries: (time, task_id, context_hash, i_t, r_t, BAD_t, minimal obs_t).
	•	Per-episode summaries: returns, length, regret estimates.
	•	Candidate patches and their metadata.
	•	Accepted patches with VC ids and PoX scores.

Each entry participates in a hash chain.

8.2 Error Localization

Given episodes or batches with low return or high regret, choose candidate step indices:

G(tau) subset of {0..T-1}.

Examples:
	•	Last L steps of low-return episodes.
	•	Steps where TD error or regret surrogate exceeds threshold.

These steps guide where splits, merges, or macros might help.

8.3 Expert Split

Given i* used at t* in G(tau):
	1.	Choose gating bit index b from expert inputs or context bits.
	2.	Allocate new ids u0, u1 and slots i0, i1.
	3.	Define new experts i0, i1 with same R_spec and W_spec as i* and initial C_rep copies.
	4.	Gate:
	•	i0 active when bit b = 0.
	•	i1 active when bit b = 1.
	5.	Adjust routing:
	•	Deprecate i* or lower z_i*.
	•	Initialize z_i0, z_i1 near z_i*.
	•	Insert i0, i1 into ANN index.
	6.	Create patch Delta_split describing changes.

8.4 Expert Merge

For candidate merge cluster C_merge = {i_1,..,i_k}:
	1.	Evaluate similarity based on inputs, outputs, and stats.
	2.	If similar, define merged expert m:
	•	R_spec_m as intersection or union of R_spec_i_j.
	•	W_spec_m as compatible subset of W_spec_i_j.
	•	C_rep_m approximating aggregated behavior via search or CEGIS.
	3.	Update routing:
	•	Create new id u_m and slot i_m.
	•	Route most traffic to i_m; possibly keep residual experts.
	4.	Create patch Delta_merge.

8.5 Macro and Template Extraction

From logs L, extraction procedure T_extract(L) yields templates T_k:
	•	Represent CFG fragments or expert sequences that occur frequently.
	•	Characterized by:
	•	Sequence of nodes or experts.
	•	Parameter slots.
	•	Optional reward pattern.

Templates can be:
	•	Compiled into macro nodes.
	•	Used for synthetic episodes.
	•	Targeted by superoptimization.

8.6 Superoptimization

For selected hot experts or macros:
	1.	Derive intermediate representation IR from C_rep and logs.
	2.	Define equivalence domain D.
	3.	Search for cheaper circuit C_rep’ equivalent to C_rep on D.
	4.	Construct VC_equiv(Delta) asserting equivalence.
	5.	Call SAT_CHECK on VC_equiv(Delta).
	6.	If UNSAT, accept patch Delta_superopt replacing C_rep with C_rep’.
	7.	Verification Kernel

9.1 CNF Representation

Variables var_j indexed by integers or subset of U. Clause c:
	•	Represented as pair (pos, neg), where pos_j = 1 if var_j appears positively, neg_j = 1 if var_j appears negatively.

CNF formula Phi is a finite set of clauses.

9.2 Hoare Logic Annotations

For each CFG node v:
	•	P_v is CNF formula for invariant at entry of v.

For edge (u, v) with instructions instr(u->v):
	•	WP_instr(u->v): mapping from CNF to CNF (weakest precondition).

Hoare consistency:

P_u = WP_instr(u->v)(P_v) for all edges (u, v).

9.3 VC Construction and Incremental Solving

For patch Delta:
	•	VC(Delta) is CNF capturing:
	•	Safety: BAD not reachable.
	•	Equivalence on domain D.
	•	Hoare consistency for updated CFG.

Solver:
	•	baseCNF_id: baseline CNF.
	•	deltaCNF_id: clauses for Delta.

SAT_CHECK(base + delta) returns SAT, UNSAT, or UNKNOWN, with optional unsat_core_id.

9.4 CEGIS Integration

CEGIS(phi_id, hyp_class_id):
	•	Yields candidate satisfying phi or counterexample.

Counterexample can be mapped back to initial state and environment traces for further training.

CEGIS is used to synthesize:
	•	Experts from specifications.
	•	Invariants.
	•	Merged experts consistent with observed behavior.

	10.	PoX Objectives and Scheduling

10.1 PoX Score

For verified patch Delta, estimate:
	•	Delta_R: regret reduction across benchmark tasks.
	•	Delta_S: safety improvement.
	•	Delta_C: cost reduction.
	•	Delta_I: information gain.

PoX score:

score(Delta) = w_R * Delta_R + w_S * Delta_S + w_C * Delta_C + w_I * Delta_I

Weights w_* are stored in WORK.

10.2 PoX State and Difficulty

WORK segment stores:
	•	w_R, w_S, w_C, w_I.
	•	Difficulty D (acceptance threshold).
	•	Moving averages for score and yield.
	•	Saturation metrics (for example last_high_score_step).

10.3 Scheduler Policy

Scheduler chooses allocation fractions:

alpha_act, alpha_synth, alpha_verify in [0,1], sum to 1.

Heuristics:
	•	Increase alpha_synth when uncertainty is high.
	•	Increase alpha_verify when many high-priority patches wait.
	•	Reduce alpha_verify when backlog is low and yield is low.
	•	Respect external requirements on alpha_act.

Concrete scheduler algorithm is given in Algorithm D.
	11.	Execution Model and Time Scales

11.1 Fast Path (Level 1)

Per-step loop:
	1.	STEP_FAST (Algorithm A).
	2.	BANDIT_UPDATE_STEP (Algorithm B) once reward is known.

No structural changes or heavy verification.

11.2 Mid Path

Executed periodically:
	•	GRPO_LITE_UPDATE (Algorithm C).
	•	Log aggregation and template extraction.
	•	Drift metrics.

11.3 Slow Path (Level 2 and 3)

Executed asynchronously:
	•	Structural patch generation.
	•	PROVER calls and patch verification.
	•	PoX scoring.
	•	Scheduler meta-steps (Algorithm D).
	•	Snapshot and rollback.

	12.	Integrity and Audit

12.1 Log Chain

TRACE entries e_k form hash chain:

H_0 = fixed constant
H_{k+1} = Hash(H_k || e_k)

H_k is stored or exported, allowing tamper detection.

12.2 Merkle Trees

Merkle trees may cover:
	•	EXPERT segment.
	•	CFG.
	•	WORK configuration.

Update procedures recompute hashes from modified leaves upward. Root hashes are stored or exported.

12.3 Patch Acceptance

Patch Delta is applied only if:
	1.	VC(Delta) is verified: SAT_CHECK returns UNSAT.
	2.	PoX condition holds: score(Delta) >= D (if PoX enabled).

Accepted patches are logged with descriptors, VC identifiers, PoX scores, and parent hash.
	13.	Game-Theoretic Interpretation (Informative)

13.1 Stage Game

Players:
	•	Player 1: BEM controller (fast path).
	•	Player 2: environment.

At time t:
	1.	Internal state X_t and observation obs_t.
	2.	BEM chooses expert i_t from available experts.
	3.	State transitions via expert semantics to X_{t+1}.
	4.	Environment returns reward r_t and affects future observations.

Instantaneous payoff:

u_t = r_t - lambda_bad * BAD_t - lambda_cost * cost_t.

13.2 Regret and Policies

For fixed task tau and action set A_tau:
	•	Policies map (obs, tau) to distributions over A_tau.
	•	Regret_T measures difference between cumulative payoff of BEM policy and best reference policy in a reference class, subject to safety constraints.

Design intent:
	•	Expected regret is sublinear in T under standard assumptions.

13.3 Safety

Safety enforced by:
	•	BAD_t indicator.
	•	Verification constraints VC(Delta).

Strategy space restricted to safe configurations S_safe for which BAD remains rare or unreachable.

13.4 Meta-Actions

Structural patches Delta act as meta-actions transforming configuration C to C’ subject to:
	•	VC(Delta) being UNSAT.
	•	PoX threshold.

Meta-game payoff approximated by score(Delta) minus cost of verification.

13.5 Two-Time-Scale Learning

Fast time scale:
	•	Contextual bandit with safety constraints (fast path).

Slow time scale:
	•	Patch selection and verification as meta-game.
	•	Scheduler controlling compute allocation.

	14.	Self-Evolving Training Pipeline v0.0.1

14.1 Components
	•	B_main: main BEM with full verification and PoX.
	•	B_d: specialist BEMs per domain (math, code, reasoning, agentic, safety, etc).
	•	S_domain: domain scheduler controlling domain-level allocations.
	•	G_d,k: task generators per domain and difficulty.
	•	V_d, E_d: domain-specific verifiers and evaluators.
	•	S_patch: patch scheduler managing Q_patch.

14.2 Phases

Phase 0: Initialization
	•	Initialize specialists with minimal expert sets and simple tasks.
	•	Initialize B_main with slightly richer expert capacity.

Phase 1: Specialist self-play
	•	Run act and synth modes in each domain.
	•	Use BEM learning rules to improve B_d.
	•	Log episodes and metrics.

Phase 2: Distillation into main BEM
	•	Construct distillation dataset from high-quality episodes from specialists.
	•	Train B_main to match expert choices and outputs.
	•	Install macros and templates via verified patches.

Phase 3: Mixed-domain RL on main BEM
	•	Use S_domain to choose domain and mode (act, synth, verify).
	•	Run episodes, structural proposals, and verification.
	•	Use off-policy masking for unstable episodes.
	•	Use PoX and Algorithm D to select verification jobs.

Phase 4: Long-run self-evolution
	•	Maintain specialists for new domains or capabilities.
	•	Periodically distill into B_main.
	•	Continuously run mixed-domain RL and structural updates.

14.3 Curriculum and Difficulty

Per domain d and difficulty k, maintain:
	•	Pass rate.
	•	Regret statistics.

Curriculum C_d adjusts sampling so that tasks remain challenging but not impossible, gradually increasing complexity.
	15.	Image Snapshot Model v0.0.1

15.1 Base Image

Define a stable base container image:
	•	Name: registry.example.com/bem-core:0.0.1
	•	Contents:
	•	BEM engine and CLI.
	•	SAT, ANN, and other libraries.
	•	Default configuration templates.

15.2 Long-lived Runtime Container

Run long-lived container:
	•	Name: bem-runner
	•	Derived from bem-core:0.0.1
	•	Command launches BEM scheduler and subsystems.

Inside container:
	•	/var/lib/bem: evolving engine state.
	•	/var/log/bem: logs.
	•	/etc/bem: configurations.

15.3 Snapshot as Image

Snapshot concept:
	•	Docker image created from filesystem of running bem-runner container.

Tag format examples:
	•	registry.example.com/bem-brain:YYYYMMDD-HHMM
	•	Possibly extended with metrics.

Snapshot includes:
	•	All layers from base image.
	•	Top layer containing runtime state and configs.

Command sequence conceptually:
	•	Compute SNAP_TAG.
	•	docker commit bem-runner registry.example.com/bem-brain:SNAP_TAG
	•	docker push registry.example.com/bem-brain:SNAP_TAG

Attach labels describing version and metrics.

15.4 Snapshot Scheduling and Gating

Scheduling:
	•	Snapshot agent triggers at fixed cadence (for example every 6 hours) or event-based.

Gating conditions:
	•	Read summary metrics from /var/lib/bem/metrics.
	•	Require:
	•	Zero safety violations in recent window.
	•	Verification backlog under threshold.
	•	Acceptable performance trends.

If gating fails, skip snapshot for this interval.

15.5 Restore and Promotion

Restore on another machine:
	•	docker pull bem-brain:TAG
	•	docker run –name bem-runner bem-brain:TAG bem-engine –resume

Promote snapshot to stable tag by re-tagging and pushing.

15.6 Migration to New Core

When base image version changes:
	•	Launch old snapshot container, archive /var/lib/bem.
	•	Launch new core container, import archive and run migration tool.
	•	Commit migrated container as new snapshot.

15.7 Retention and Security

Retention policy:
	•	Keep last N daily snapshots and M weekly snapshots and all stable tags.
	•	Clean up older non-stable snapshots.

Security:
	•	Use private registry.
	•	Restrict push and pull.
	•	Segregate external inputs via volumes where possible.

	16.	Core ISA v0.0.1

16.1 Registers

Scalar registers:
	•	x0..x31: 64-bit general purpose (x0 is zero).
	•	pc: program counter.
	•	sr: status register.
	•	seed: PRNG state.

Bitvector registers:
	•	b0..b31: W-bit vector registers.

Optional predicate registers:
	•	p0..p15: predicate flags.

Segment base registers (conceptual):
	•	sb_state, sb_shared, sb_expert, sb_cfg, sb_trace, sb_proof, sb_work.

16.2 Instruction Classes

Integer ALU:
	•	ADD rd, rs1, rs2
	•	SUB rd, rs1, rs2
	•	MULLO rd, rs1, rs2
	•	AND rd, rs1, rs2
	•	OR rd, rs1, rs2
	•	XOR rd, rs1, rs2
	•	SHL rd, rs1, imm
	•	SHR rd, rs1, imm
	•	SAR rd, rs1, imm
	•	NOT rd, rs1

Loads and stores:
	•	LD rd, [base + offset]
	•	ST rs, [base + offset]

Bitvector operations:
	•	BLD bd, [base + offset]
	•	BST bs, [base + offset]
	•	B_AND bd, bs1, bs2
	•	B_OR bd, bs1, bs2
	•	B_XOR bd, bs1, bs2
	•	B_NOT bd, bs1
	•	B_SHL bd, bs, imm
	•	B_SHR bd, bs, imm
	•	B_ROL bd, bs, imm
	•	B_ROR bd, bs, imm
	•	B_BLEND bd, mask, a, b
	•	B_POPCNT rd, bs
	•	B_PARITY rd, bs

Control flow:
	•	BEQ rs1, rs2, label
	•	BNE rs1, rs2, label
	•	BLT rs1, rs2, label
	•	BGE rs1, rs2, label
	•	JMP label
	•	JAL rd, label
	•	RET rd

Co-processor calls:
	•	COP op_id, rs_arg, rd_res

where op_id selects ANN, PROVER, HASH, LOG, PROPOSER, etc.

PRNG:
	•	RAND rd

updates seed and returns pseudo-random bits.

16.3 Co-Processor ABIs

ANN_QUERY:
	•	Input: pointer to descriptor with q, f pointer, k, config.
	•	Output: pointer to candidate list with count and slot indices.

PROVER_CALL:
	•	SAT_CHECK: cnf_id and options, returns result code and optional unsat_core_id.
	•	HOARE_CHECK, PROOF_CHECK, CEGIS similarly.

HASH_CALL:
	•	Input pointer and length, returns hash pointer.

LOG_CALL:
	•	Append log entry and update hash chain.

	17.	Algorithm Layer v0.0.2 (Under v0.0.1 Semantics)

17.1 Algorithm A: STEP_FAST

Implements per-step fast path, using:
	•	Observation O and F_feat.
	•	ANN_QUERY.
	•	Bandit routing with UCB-like score and optional softmax.
	•	Expert evaluation via BEM_EXPERT_BATCH.
	•	Minimal logging.

17.2 Algorithm B: BANDIT_UPDATE_STEP

Per-step bandit stats update:
	•	Increment visits, wins, and N_tau.
	•	Pure integer arithmetic.

17.3 Algorithm C: GRPO_LITE_UPDATE

Mid-path GRPO-like update:
	•	Group episodes by (task_id, context_bucket(initial_context_hash)).
	•	Compute group returns and standardized advantages.
	•	Accumulate per expert and task.
	•	Update log-weights z_i with bounded delta_z.

17.4 Algorithm D: Contextual Scheduler META_STEP

Three arms (act, synth, verify) modeled as contextual linear bandits:
	•	Context x_m derived from global state (backlogs, PoX yield, safety, drift).
	•	For each arm a:
	•	Maintain A_a and b_a for linear regression.
	•	Approximate theta_a = A_a^{-1} b_a via fixed-iteration solver.
	•	Compute UCB-like score s_a.
	•	Choose arm a_star via greedy or softmax.
	•	Execute one workload unit from that arm.
	•	Update A_a_star, b_a_star, reward estimates, and weights w_a.
	•	Apply safety overrides if safety_violation_rate exceeds threshold.

17.5 Algorithm E: PROVER Profile Selection

For VC(Delta):
	•	Extract simple features (size, clause lengths, horn structure, circuit flags, depth estimate).
	•	Apply table-based decision to select solver profile id.
	•	Pass profile id to PROVER_CALL.

17.6 Drift and Rollback

Monitor performance_metric and safety_violation_rate over windows:
	•	If performance degrades and PoX yield is non-positive, suspend patch application.
	•	If safety_violation_rate exceeds threshold, suspend patch application and optionally rollback to a previous snapshot.

17.7 SNAPSHOT and RESUME

SNAPSHOT(label):
	•	Freeze patch application.
	•	Serialize C and selected H state.
	•	Store snapshot metadata.
	•	Log snapshot entry.
	•	Unfreeze patch application.

RESUME(snapshot_id):
	•	Load snapshot configuration C_snapshot.
	•	Replace current C with C_snapshot.
	•	Restore relevant H state.
	•	Reset drift metrics and resume.

End of BEM v0.0.1 integrated spec.
