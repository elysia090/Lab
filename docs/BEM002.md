BEM v0.0.1 – Boolean Expert Machine, Hardware-Oriented Core Specification (Optimized, Tightened Draft)
	0.	Scope and Goals

0.1 Purpose

This document defines the Boolean Expert Machine (BEM) v0.0.1 as a hardware-oriented, finite-state abstract machine with:
	1.	A single integer control core plus a fixed set of co-processors.
	2.	Fast path using only integer arithmetic and bitwise operations with bounded, sequence-length-independent cost per step.
	3.	A family of Boolean “experts” acting as local state transformers over bit-sliced state.
	4.	Online learning via bandit-style expert selection and log-domain weight updates.
	5.	Structural updates (expert split/merge, macro extraction, circuit rewrites) subject to formal verification.
	6.	Interfaces for self-play, synthetic experiments, and CEGIS-style counterexample-driven refinement.

The v0.0.1 variant incorporates optimizations for:

– Fast-path routing and expert evaluation.
– Sample efficiency of learning (per-task statistics, adaptive learning rates).
– Structural-update efficiency (priority-guided search, template extraction).
– Verification efficiency (incremental CNF, unsat-core-based invariant improvement).

0.2 Non-goals

This specification does not define:

– Concrete instruction encodings or micro-architectures.
– Concrete performance targets or power envelopes.
– Any host programming language, ABI, or OS integration.
– Neural network structures or floating-point primitives on the fast path.

Neural or floating-point components MAY exist as external proposal generators (e.g. for candidate experts or invariants). Such proposals MUST be validated through the verification kernel before they affect the trusted fast path.

0.3 Notation and Complexity

– Bits are elements of {0,1}.
– Bitvectors of length n are elements of {0,1}^n.
– Integers are elements of Z with fixed-width representations where needed.
– Per-step complexity refers to control-core cycles and co-processor invocations triggered by one logical step (event/token), and MUST be bounded by a constant independent of episode length and total number of past steps.

Parameters:

– N: number of global state bits.
– K: number of shared memory bits (K ≥ N).
– P: number of fixed-point parameters.
– W: SIMD width (number of lanes).
– S: maximum number of experts (slots in EXPERT table).
– d: dimension of feature bits for routing (e.g. 64–256).
– k_large: ANN candidate size (e.g. 16–64).
– k_small: final routing candidate size (e.g. 1–4).
– D_max: maximum graph search depth inside ANN.
– M_max: maximum per-node neighbor degree in ANN.

All these are fixed at design or configuration time.
	1.	Machine State and Identifiers

1.1 Logical State

The logical state at time t is:

X_t = (s_t, M_t, Θ_t)

where:

– s_t ∈ {0,1}^N: global state bits (bit-sliced over W lanes in physical representation).
– M_t ∈ {0,1}^K: shared memory bits.
– Θ_t ∈ Z^P: fixed-point parameters.

The fast path reads and writes s_t and M_t and may read Θ_t. Structural update and verification may modify Θ_t and structural tables.

1.2 Identifier Space

Domain U = {0,1,…,2^32 − 1}. Each u ∈ U is structured as:

u = [class(6) | ecc(6) | shard(6) | local(14)]

where:

– class ∈ {0,…,63}: object class (e.g. expert, cfg_node, variable, template, hypothesis).
– ecc ∈ {0,…,63}: ECC parity bits for shard/local.
– shard ∈ {0,…,63}: logical shard index.
– local ∈ {0,…,16383}: shard-local index.

Gray encoding:

g(u) = u xor (u >> 1)

Hamming distance d_H(a,b) is the number of differing bits. Similarity:

sim(u,v) = 32 − d_H(g(u), g(v))

1.3 Slot Mapping

Each object type with tabular storage (e.g. experts) uses a slot function:

slot: U → {0,…,S−1} ∪ {⊥}

For an allocated expert identifier u:

– i = slot(u) ∈ {0,…,S−1}
– EXPERT[i] is the descriptor for u.

Required properties:

– slot(u) ≠ ⊥ for allocated expert u.
– If u ≠ v and both allocated as experts, then slot(u) ≠ slot(v).
– slot(u) and its inverse mapping are stored and updated in SHARED memory.
– Rebalancing MAY change slot(u) but MUST preserve:
– the content of objects,
– the semantics of references that use identifiers u (not slot indices).

1.4 Task and Context Identifiers

BEM maintains per-step task/context metadata:

– task_id_t ∈ Z_small: integer distinguishing task families or benchmark classes.
– context_hash_t ∈ Z_32 or Z_64: rolling hash summarizing a bounded window of recent observations, rewards, and actions.
– These are stored in SHARED or STATE.

They are computed by deterministic functions:

task_id_t = T_id(s_t, M_t, external_task_config)
context_hash_t = H_ctx(previous context_hash, obs_{t−1}, r_{t−1}, etc.)
	2.	Memory Segments

2.1 Segment Layout

Logical segments:
	1.	STATE:
– holds bit-sliced representation of W lanes of s_t.
– STATE[k] ∈ {0,1}^W for k ∈ {0,…,N−1}.
	2.	SHARED:
– holds scalar data M, Θ, configuration, routing metadata, counters.
	3.	EXPERT:
– EXPERT[0..S−1] entries.
	4.	CFG/CODE:
– instruction array C[0..L−1], CFG node metadata, macro descriptors.
	5.	TRACE/LOG:
– step-level traces, episode summaries, structural patch metadata, PoX entries.
	6.	PROOF:
– CNF formulas, solver state identifiers, proof objects, unsat cores.
	7.	WORK (optional PoX):
– PoX configuration, difficulty, moving averages, saturation and priority metrics.

Segments are logically disjoint. Physical mapping (pages, cache lines) is implementation-specific, but no aliasing between segments is allowed in semantics.

2.2 STATE Segment Representation

STATE segment holds:

– For each bit index k in [0,N):
– S_pl[k] ∈ {0,1}^W, representing the bit for each lane l.

Lane l’s view of s_t is recovered as:

s_t^(l)[k] = bit l of S_pl[k]

Shared memory M_t and parameters Θ_t are not bit-sliced.

2.3 EXPERT Segment Entry Format

For each slot i:

EXPERT[i] = (id_i, R_spec_i, C_rep_i, W_spec_i, stats_i, params_i, routing_meta_i)

– id_i ∈ U: expert identifier associated with this slot.
– R_spec_i: input selection specification.
– C_rep_i: Boolean circuit representation (Section 5.2).
– W_spec_i: write-back specification.
– stats_i:
– wins_total_i ∈ Z_nonneg,
– visits_total_i ∈ Z_nonneg,
– per-task arrays or maps:
– wins_i,τ,
– visits_i,τ,
– last_update_step_i ∈ Z.
– params_i:
– z_i: log-weight (fixed-point),
– L_i,τ, S_i,τ: cumulative loss and squared loss per-task for adaptive η.
– routing_meta_i:
– priority tags, macro tags, version information.

2.4 CFG/CODE Segment

– C[pc] is an abstract instruction executed by BEM-CORE.
– CFG nodes v ∈ U (class cfg_node) have:
– pc_start[v], pc_end[v],
– Succ(v) ⊆ U (successor node ids),
– optional local invariants P_v (CNF stored in PROOF).

Macro descriptors:

– macros may represent:
– common expert sequences,
– hot CFG fragments.
– macro nodes refer to:
– a subprogram or sequence of experts and control decisions.
	3.	Hardware Modules

3.1 BEM-CORE

BEM-CORE:

– executes the BEM ISA, including:
– integer arithmetic, bitwise operations,
– control flow,
– scalar loads/stores,
– co-processor commands.
– is responsible for:
– fast-path loop control,
– mid-path learning updates,
– scheduling slow-path tasks (verification, structural updates).

3.2 BIT-ALU

BIT-ALU supports:

– bitwise operations:
– AND, OR, XOR, NOT on {0,1}^W.
– shifts and rotates:
– SHIFT_LEFT, SHIFT_RIGHT, ROTATE.
– POPCOUNT:
– popcount: {0,1}^W → Z_nonneg.
– parity: popcount mod 2.
– mask-based blends:
– blend(mask, a, b): lane-wise selection.

Latencies of BIT-ALU instructions MUST be bounded by a small constant (architectural parameter).

3.3 ANN Unit

Interface:

ANN_QUERY(q, f, k, config) → candidate_list

Inputs:

– q: query key (e.g. 32-bit).
– f ∈ {0,1}^d: feature bitvector.
– k: desired number of candidates (k ≤ k_large).
– config: optional routing configuration (task_id, search-level flags).

Outputs:

– candidate_list: sequence of at most k slot indices or identifiers.

Internal constraints:

– search depth ≤ D_max,
– degree per node ≤ M_max,
– worst-case complexity per query bounded by a constant (given D_max, M_max).

The ANN Unit may maintain:

– multi-level buckets keyed by:
– shard_id = high bits or Gray-coded prefix of q,
– bucket_id = remaining bits,
– per-bucket:
– a small list of representative experts,
– a small list of recently high-performing experts (using stats_i).

3.4 SAT/Hoare Unit

Interface:

SAT_CHECK(cnf_id) → SAT / UNSAT / UNKNOWN
PROOF_CHECK(cnf_id, proof_id) → ACCEPT / REJECT
HOARE_CHECK(cfg_id, annotations_id) → ACCEPT / REJECT
CEGIS(φ_id, hyp_class_id) → (candidate_id or NONE, cex_id or NONE)

Requirements:

– supports incremental CNF:
– baseCNF_id: persistent solver context,
– delta clauses added per patch.
– supports unsat core extraction:
– UNSAT → unsat_core_id referencing subset of clauses.

3.5 HASH/ECC Unit

Responsibilities:

– ECC encode/decode for identifiers and memory blocks.
– Hash computation:
– Hash: {0,1}^* → {0,1}^h (e.g. h=256).
– Merkle tree updates:
– given child hashes, compute parent hash.
– Hash chains:
– H_{k+1} = Hash(H_k || entry_k).

3.6 LOG Unit

Responsibilities:

– append structured entries to LOG.
– maintain hash chain H_k in protected state.
– optionally maintain simple counters and moving averages for PoX metrics.
	4.	Observation and Routing Inputs

4.1 Observation Function

Observation is a deterministic function:

obs_t = O(s_t, M_t) = (task_id_t, context_hash_t, local_bits_t, feature_bits_t)

Components:

– task_id_t:
– must be stable for the duration of a benchmark task or environment family;
– may be stored in SHARED configuration per environment.
– context_hash_t:
– 32- or 64-bit rolling hash:
– context_hash_t = H_ctx(context_hash_{t−1}, small summary of obs_{t−1}, r_{t−1}, a_{t−1})
– H_ctx is integer-only (e.g. multiply-add and xor).
– local_bits_t:
– small fixed subset of bits from s_t and/or M_t:
– indices are determined by configuration for the current task.
– feature_bits_t ∈ {0,1}^d:
– derived by a deterministic mapping F_feat(s_t, M_t, context_hash_t):
– e.g. random projections plus thresholds, sketches, or simple integer transforms.

4.2 Query Key and Feature

From obs_t:

q_t = F_id(task_id_t, context_hash_t)
f_t = feature_bits_t

Example F_id:

q_t = Hash32(task_id_t || context_hash_t)

F_id MUST be collision-resistant enough to distribute contexts across shards, but only integer and bit operations are allowed.

4.3 Shard and Bucket

ANN Unit derives:

– shard_id = high bits of q_t (or its Gray code),
– bucket_id = selected bits of q_t (middle or low bits).

The index is logically:

index[shard_id][bucket_id] = small set of candidate experts plus access to a local graph or cache.
	5.	Expert Semantics and Circuits

5.1 Expert as Local Transformer

Given global state (s, M), expert i defines:

x = R_i(s, M) ∈ {0,1}^{n_i}
y = C_i(x) ∈ {0,1}^{m_i}
(s′, M′) = W_i(s, M, y)

where:

– R_i is determined by R_spec_i:
– bit indices into s and M,
– simple address expressions (e.g. fixed offsets).
– C_i is given by C_rep_i.
– W_i is determined by W_spec_i:
– writes back to specific bits or contiguous regions,
– may use masks derived from y.

5.2 Circuit Representation Requirements

ANF form:

– each output y_j is:

y_j = xor over monomials of input bits
monomial = AND of subset of inputs

Implementation uses:

– BIT-ALU for AND/XOR,
– popcount+parity to compress multiple XORs.

ROBDD form:

– DAG with nodes representing tests on specific input bits,
– canonical per-variable ordering,
– reduced (no duplicate subgraphs, no redundant nodes).

Common requirements:

– circuits must support bit-sliced evaluation across all W lanes:
– inputs x for all lanes are packed as W-bit words per input bit,
– intermediate values are W-bit words,
– all operations use BIT-ALU.

5.3 Fast-Path Evaluation Invariants

For all experts i, design-time constants n_i, m_i are bounded:

n_i ≤ N_in_max
m_i ≤ N_out_max

The total cost per expert evaluation (per BEM_EXPERT_BATCH) is bounded by:

Cost_expert ≤ C_expert_max

where C_expert_max depends on N_in_max, N_out_max, and chosen circuit form, but is independent of episode length.
	6.	Fast-Path Control and Routing

6.1 Two-Stage Routing Algorithm

At each step t, routing is:
	1.	Observation:

obs_t = O(s_t, M_t)
	2.	Query:

(q_t, f_t) = (F_id(task_id_t, context_hash_t), feature_bits_t)
	3.	ANN candidate retrieval:

C_large = ANN_QUERY(q_t, f_t, k_large, config(task_id_t))
	4.	Bandit-based filtering:

For current task τ = task_id_t, and each i ∈ C_large:

– visits_i,τ ≥ 0, wins_i,τ ≥ 0.
– mean_i,τ = wins_i,τ / max(1, visits_i,τ).
– exploration bonus:

bonus_i,τ = c_explore * sqrt( log(max(1, N_τ)) / max(1, visits_i,τ) )

N_τ = total visits for task τ.

Routing score:

score_i,τ = mean_i,τ + bonus_i,τ

BEM-CORE selects:

– a subset C_t (|C_t| = k_small) with highest score_i,τ,
– or samples a single i_t from C_large with probability proportional to exp(z_i) or another function of (score_i,τ, z_i).

The exact choice MUST be deterministic given a random seed, state, and configuration, but may be either:

– deterministic argmax or top-k,
– randomized sampling using pseudo-random bits from SHARED or a PRNG.

6.2 Lane-Level Assignment

Lane assignment schemes:

– Single expert for all lanes:
– choose i_t once and apply step_i_t to each lane independently.
– Grouped lanes:
– partition lanes into groups and assign one expert per group.
– Per-lane expert:
– rare, but allowed, with bit-masked updates.

In all cases, BEM_EXPERT_BATCH executes:

– R_spec_i for all lanes (reading STATE and SHARED),
– C_rep_i bit-sliced,
– W_spec_i with lane masks.

6.3 Complexity Bound

Per step t, fast path MUST satisfy:

Cost_step ≤ C_obs + C_ANN + C_route + C_expert_batch + C_stats

where all C_* are configuration-dependent constants:

– C_obs: cost of O, F_id, F_feat.
– C_ANN: cost of ANN_QUERY with D_max, M_max.
– C_route: cost of bandit scoring over ≤ k_large candidates.
– C_expert_batch: cost of evaluating ≤ k_small experts over W lanes.
– C_stats: cost of updating visits, wins, and small log-domain updates.
	7.	Learning and Bandits

7.1 Loss and Reward Aggregation

Per step t:

– reward r_t ∈ R (bounded, e.g. r_t ∈ [R_min, R_max]).
– per-expert loss at t:

loss_t(i) = −r_t if i = i_t, and 0 otherwise

Per-task loss:

– accumulate:
– L_i,τ += loss_t(i) for task τ,
– S_i,τ += loss_t(i)^2

7.2 Log-Domain Weight Update

For expert i and task τ, at update time (mid-path), define:

hat_l_i,τ = L_i,τ / max(1, visits_i,τ)

Clipped loss:

hat_l_i,τ_clipped = clamp(hat_l_i,τ, −L_max, L_max)

Adaptive learning rate:

η_i,τ = c_eta / sqrt(S_i,τ + ε_eta)

Fixed-point representation:

– z_i, L_i,τ, S_i,τ, η_i,τ are stored as fixed-point integers with scale factors determined at configuration.

Update rule:

z_i′ = z_i − η_i,τ * hat_l_i,τ_clipped

Trust region constraint:

– if |z_i′ − z_i| > Δ_z_max, then z_i′ is clipped to z_i ± Δ_z_max.

Optionally normalize z_i across experts periodically to prevent overflow or collapse.

7.3 Bandit Statistics Update

Whenever expert i is used at step t for task τ:

– visits_i,τ ← visits_i,τ + 1
– visits_total_i ← visits_total_i + 1
– wins_i,τ ← wins_i,τ + r_t or other reward proxy
– wins_total_i ← wins_total_i + r_t
– N_τ ← N_τ + 1

These updates are counted in mid-path or immediately after fast path, but are algebraically simple integer increments/additions.
	8.	Structural Updates and Templates

8.1 Logging

TRACE/LOG stores:

– per-step entries (optional for every step, mandatory for selected steps):
– (task_id_t, context_hash_t, i_t, r_t, minimal obs_t components).
– per-episode summaries:
– task_id, total reward, lengths, maybe regret estimates.
– candidate patches:
– Δ descriptors, pre-verification metrics.
– accepted patches:
– Δ descriptors, VC identifiers, PoX scores (if used).

Each entry is hashed into the LOG chain.

8.2 Error Localization

Given an episode τ or a batch of episodes with low return or high regret, G(τ) selects indices:

G(τ) ⊆ {0,…,T−1}

Typical choices:

– G(τ) = {T−L,…,T−1} for some L (e.g. last L steps).
– G(τ) = {t | |TD_error_t| ≥ threshold}.
– Or a union of several heuristics.

These indices identify candidate regions where structural updates may be beneficial.

8.3 Expert Split

For t* ∈ G(τ) and expert i* used at t*:
	1.	Select gating bit index b:
– either one of the input bits in R_spec_{i*}, or a designated “context” bit in s or M.
	2.	Allocate new identifiers u0, u1 ∈ U (class=expert) and slots i0, i1.
	3.	Define new experts i0 and i1:
– R_spec_i0 = R_spec_i1 = R_spec_i*.
– W_spec_i0 = W_spec_i1 = W_spec_i*.
– C_rep_i0, C_rep_i1 initially copies of C_rep_i*.
– gating criteria:
– i0 applies only when b=0,
– i1 applies only when b=1.
– optionally perturb C_rep_i0 and C_rep_i1 to differentiate behavior.
	4.	Routing update:
– reduce z_i* or mark i* as deprecated,
– initialize z_i0, z_i1 close to z_i*,
– insert i0, i1 into ANN index near i* and into routing_meta.
	5.	Generate a patch Δ_split describing:
– new experts, gating logic, routing changes.

8.4 Expert Merge

For a cluster C_merge = {i1,…,ik}:
	1.	Evaluate similarity based on:
– overlap of input selections,
– correlation of outputs on sampled inputs,
– similarity of per-task stats.
	2.	If similarity above threshold, construct a merged expert m:
– R_spec_m = intersection or union of R_spec_ij (must be decidable).
– W_spec_m = common subset of W_spec_ij, with optional per-case adjustments.
– C_rep_m approximates aggregated behavior, possibly learned via CEGIS or local search.
	3.	Routing update:
– create identifier u_m and slot i_m,
– route most traffic to i_m,
– keep residual experts for rare behaviors or temporarily preserve them until verification.
	4.	Generate patch Δ_merge.

8.5 Macro and Template Extraction

From logs L, T_extract(L) produces templates {T_k}:

– Each T_k represents a CFG fragment or expert sequence that appears frequently.
– T_k is characterized by:
– a fixed sequence of CFG nodes and/or experts,
– parameter slots (e.g. bits of s or M that vary),
– optional reward pattern.

Formalization:

T_k: Param_k × Noise_k → τ_k

Param_k encodes discrete degrees of freedom (e.g. key/value choices). Noise_k encodes stochasticity or synthetic variation.

Templates may be:

– compiled into macro nodes in CFG,
– used as sources for synthetic episodes in self-play,
– targeted for superoptimization.

8.6 Superoptimization

For selected experts/macros with high usage:
	1.	Derive an intermediate representation IR (e.g. SSA, bit-level expressions) from C_rep and logs.
	2.	Define an equivalence domain D (subset of possible inputs x).
	3.	Search for an equivalent circuit C_rep′:
– using bounded-depth enumeration, local rewrite rules, or search guided by cost metrics.
	4.	Construct VC_equiv(Δ) expressing:
– ∀x ∈ D: C_rep(x) = C_rep′(x)
	5.	Submit VC_equiv(Δ) to SAT/Hoare Unit:
– if proven (UNSAT of negation or equivalent), accept replacement.
	6.	Emit patch Δ_superopt replacing C_rep with C_rep′.
	7.	Verification Kernel

9.1 CNF and Clause Representation

Variables var_j indexed by integers or U-subset.

Clause c represented as:

(pos, neg)

pos, neg ∈ {0,1}^n where:

– pos_j = 1 indicates var_j appears positively.
– neg_j = 1 indicates var_j appears negatively.

CNF formula:

Φ = {c_1, …, c_M}

9.2 Hoare Logic Annotations

For each CFG node v:

– P_v is a CNF formula representing an invariant at entry of v.

For an edge (u, v) with instruction sequence instr(u→v):

– WP_instr(u→v): CNF → CNF maps postcondition P_v to precondition P_u.

Hoare consistency condition:

P_u = WP_instr(u→v)(P_v)

for all edges (u, v) in CFG.

9.3 VC Construction and Incremental Solving

For a patch Δ:

– build VC(Δ) as a CNF formula capturing:
– required safety properties (e.g. BAD state unreachable),
– equivalence properties (old vs new behavior identical on domain D),
– updated Hoare consistency conditions.

The solver uses:

– baseCNF_id: an id for an existing CNF representing the unpatched system and baseline invariants.
– deltaCNF_id: clauses added or modified for Δ.

SAT_CHECK(baseCNF_id + deltaCNF_id) returns:

– SAT: violation or counterexample exists (patch invalid).
– UNSAT: VC holds under assumptions.
– UNKNOWN: resource limits reached.

UNSAT may produce unsat_core_id that identifies a small subset of clauses sufficient for UNSAT.

9.4 CEGIS Integration

CEGIS(φ_id, hyp_class_id):

– tries to find:
– candidate (e.g. expert circuit or CFG fragment) in hyp_class satisfying φ,
– or counterexample assignment α violating φ.

If counterexample α found:

– map α → (s_0, M_0, e_0),
– generate episode or short trajectory for training or analysis.

If candidate found:

– feed candidate into structural update pipeline as a proposed expert or invariant.

CEGIS loop is used for:

– synthesizing experts from specifications,
– synthesizing invariants,
– constructing merged experts consistent with observed behavior.
	10.	PoX Objectives and Scheduling (Optional)

10.1 PoX Components

For a verified patch Δ, measure:

– ΔR: estimated regret reduction on a set of benchmark tasks (difference in cumulative regret between old and new configurations over evaluation episodes).
– ΔS: safety improvement score, e.g. weighted count of new verified properties or tightened invariants.
– ΔC: cost reduction (e.g. change in fast-path cycles per step, or gate count).
– ΔI: information gain (approximate reduction in entropy of hypothesis distribution π_H or uncertainty measure).

All these can be estimated via evaluation runs and analytical metrics.

Define PoX score:

score(Δ) = w_R ΔR + w_S ΔS + w_C ΔC + w_I ΔI

for configurable weights w_* ≥ 0.

10.2 Work Segment and Difficulty

WORK segment stores:

– weights w_R, w_S, w_C, w_I,
– difficulty D: threshold for PoX acceptance,
– moving averages:
– E_score: mean(score(Δ)) over last K_pox patches,
– Var_score: variance.
– saturation metrics:
– last_high_score_step,
– count of patches with score ≥ D over a window.

10.3 Scheduler Policy

Scheduler chooses job classes:

– acting: real environment interaction,
– synthetic: self-play, adversarial tasks,
– verification/optimization: VC checks, superopt, structural proposals.

Let:

– α_act + α_synth + α_verify = 1

Heuristics:

– increase α_synth when uncertainty of π_H high or when PoX yield from synthetic tasks is high.
– increase α_verify when many pending patches exist or when PoX backlog is large.
– decrease α_verify when verification throughput is ahead and PoX saturation is high.
– α_act may be constrained by external task requirements.

At finer granularity, jobs in Q_pox (PoX-targeted work) are prioritized according to:

– estimated E[score(Δ) / compute_cost] (bandit-like objective),
– exploration bonus for underexplored patch families.

Scheduler MUST maintain worst-case bounds on interference with fast path (e.g. by running slow-path jobs on idle cycles or separate cores).
	11.	Execution Model and Time Scales

11.1 Fast Path

Fast path is the per-step loop:
	1.	obs_t = O(s_t, M_t)
	2.	(q_t, f_t) = (F_id(task_id_t, context_hash_t), feature_bits_t)
	3.	C_large = ANN_QUERY(q_t, f_t, k_large, config(task_id_t))
	4.	C_t and/or i_t = routing(C_large, stats, z)
	5.	BEM_EXPERT_BATCH(i_t or C_t, STATE, SHARED)
	6.	Minimal stats updates (visit counts, reward increments).

The entire sequence must have bounded cost per step. No SAT, CEGIS, or heavy structural updates are permitted on the fast path.

11.2 Mid Path

Executed periodically:

– weight updates (log-domain z_i, η_i,τ),
– aggregation of stats for bandits,
– logging episodes and selected steps,
– light template extraction.

Mid-path operations MAY be amortized over steps or executed at episode boundaries.

11.3 Slow Path

Executed asynchronously or during idle periods:

– structural update proposals (split, merge, macro creation),
– superoptimization calls,
– SAT/Hoare verification and CEGIS,
– ANN index maintenance and rebalancing,
– PoX score evaluation and difficulty adjustment.

Slow-path jobs may be preemptible and must not violate fast-path timing guarantees.
	12.	Integrity and Audit

12.1 Log Chain Integrity

LOG contains entries e_k. Hash chain:

H_0 = fixed constant
H_{k+1} = Hash(H_k || e_k)

H_k is stored in protected storage or periodically exported. Any modification to entries changes the chain and can be detected.

12.2 Merkle Trees

Merkle trees MAY cover:

– EXPERT segment,
– CFG/CODE,
– WORK configuration.

Each leaf stores hash(block), internal nodes hash of children. On updates:

– HASH/ECC recomputes affected nodes upward,
– root hashes stored in protected locations or exported.

12.3 Patch Acceptance Policy

A patch Δ is applied only if:
	1.	VC(Δ) is verified (UNSAT of violation CNF) by SAT/Hoare Unit:
– SAT_CHECK(VC(Δ)) returns UNSAT.
	2.	Optional PoX condition (if enabled):
– score(Δ) ≥ D.

Accepted patches are logged with:

– patch descriptor (including structural changes),
– VC identifier and proof references (if any),
– PoX score components (ΔR, ΔS, ΔC, ΔI) and overall score,
– parent hash in LOG chain.

This yields an auditable sequence of structural changes.

	13.	Game-Theoretic Interpretation (Informative)

This section gives a game-theoretic view of BEM v0.0.1. It does not change the normative semantics in Sections 0–12, but clarifies:

– how fast-path expert selection can be understood as a regret-minimizing strategy in a repeated game,
– how structural patches correspond to meta-actions in a slower meta-game,
– how safety (BAD bit and verification) restricts admissible strategies.

13.1 Players, Stage Game, and Payoff

We model BEM’s interaction as a two-player repeated game.

Players:

– Player 1: the BEM controller (BEM-CORE plus co-processors as a joint agent).
– Player 2: the environment, which may be stochastic or adversarial.

At time t, the stage game proceeds as:
	1.	State and observation:
– Internal state:
– X_t = (s_t, M_t, Θ_t)
– External observation:
– obs_t = O(s_t, M_t)
– Task label:
– τ_t = task_id_t
	2.	Action selection (BEM):
– Available actions at time t:
– A_t = { i | i is an expert slot with a valid descriptor and not deprecated }.
– BEM selects an expert index:
– i_t ∈ A_t
using the routing-plus-bandit procedure of Sections 4, 5, 6, and 7.
	3.	State transition:
– x_t = R_{i_t}(s_t, M_t)
– y_t = C_{i_t}(x_t)
– (s_{t+1}, M_{t+1}) = W_{i_t}(s_t, M_t, y_t)
	4.	Environment response:
– Environment updates its own hidden state (not modeled explicitly here).
– Returns reward:
– r_t ∈ [R_min, R_max] (bounded).
– May indirectly influence future obs_{t+1}, τ_{t+1}.

Define BAD_t ∈ {0,1} as a designated safety indicator bit (or a Boolean function of (s_t, M_t)).

Define a fast-path cost proxy:

– cost_t ≥ 0: an integer or fixed-point value approximating cycles consumed on the fast path at step t.

The instantaneous payoff for BEM is:

u_t = r_t − λ_bad * BAD_t − λ_cost * cost_t

with:

– λ_bad ≫ 0,
– λ_cost ≥ 0.

13.2 Policies and Regret on the Fast Path

For a fixed task τ, define:

– A_τ ⊆ A_t: set of experts that are available and meaningful when task_id_t = τ.
– A_τ is treated as fixed on the fast-path time scale (structural changes affect it only slowly).

Let a fast-path policy for task τ be any mapping:

π: (obs_t, τ) ↦ Dist(A_τ)

that chooses a distribution over experts given the current observation and task label.

Let Π_τ be the set of such policies, and Π_ref ⊆ Π_τ be a reference class, such as:

– fixed single expert per task,
– or fixed small mixture over a subset of experts,
– or a class parameterized by log-weights z_i only (no structural changes).

For a policy π and horizon T, define cumulative payoff:

R_T(π) = Σ_{t=0}^{T−1} E[u_t | policy π]

where the expectation is over any randomness in:

– the environment,
– the routing procedure (ANN_QUERY, sampling),
– the bandit exploration mechanism,
– any pseudo-randomness used on the fast path.

For the online policy implemented by BEM’s routing and log-domain bandit update (Sections 4, 6, 7), denote it π_online. Define regret against Π_ref:

Regret_T = max_{π∗ ∈ Π_ref} R_T(π∗) − R_T(π_online)

Design intent:

– Under standard assumptions (bounded rewards, bounded BAD_t and cost_t, non-anticipating environment):
– E[Regret_T] = o(T) as T → ∞.

This is the intended behavior of Section 7’s multiplicative-weights-style update:

– for each task τ, the expert weights z_i and bandit statistics (visits_i,τ, wins_i,τ, L_i,τ, S_i,τ) are updated so that the realized policy π_online asymptotically performs as well as the best fixed policy in Π_ref, subject to constraints introduced below.

13.3 Safety as a Strategy Constraint

Safety is represented by:

– BAD_t: safety indicator (bit or Boolean function),
– VC(Δ): verification conditions for structural patches,
– BAD-related invariants in Hoare annotations P_v and VC(Δ).

We interpret safety as a hard strategy constraint:

limsup_{T→∞} (1/T) Σ_{t=0}^{T−1} P[BAD_t = 1] ≤ δ_safe

where:

– δ_safe is small (ideally δ_safe = 0).

Any policy π that would violate this safety constraint is considered inadmissible.

The verification kernel (Section 9) and patch acceptance policy (Section 12) enforce that:

– structural patches Δ that may increase reachable BAD states are rejected,
– only patches whose VC(Δ) is proven (SAT_CHECK returns UNSAT) can change the system.

Thus, the strategy space is:

– S_safe = { configurations (experts, CFG, invariants, weights) that satisfy encoded safety properties }
– fast-path policies π_online are always induced by configurations in S_safe.

Regret is therefore measured over:

– Π_ref ∩ S_safe, not over all unconstrained Π_ref.

13.4 Structural Patches as Meta-Actions

Let C denote a configuration of BEM’s structural elements:

C = (EXPERT table, CFG/CODE, ANN index, invariants, Θ, WORK parameters, etc.)

At a given slow-path decision point t_meta, a structural patch Δ transforms C into:

C′ = C ⊕ Δ

Subject to:

– feasibility:
– VC(Δ) constructed from C and Δ is UNSAT (no violation of required safety or equivalence properties).
– optional PoX threshold (Section 10):
– score(Δ) ≥ D.

We define:

– meta-action set A_meta(C): set of patches Δ that:
– are syntactically valid candidates under C,
– pass VC(Δ) and PoX threshold (if enabled).

Each meta-action Δ has:

– meta-cost C_meta(Δ): estimate of compute/time spent on:
– generating Δ (trace analysis, template extraction, CEGIS, etc.),
– verifying Δ (SAT/Hoare, proof checking),
– updating indices (ANN, Merkle trees, etc.).
– meta-effect on long-run fast-path payoff and safety, estimated via:
– ΔR: change in expected regret or cumulative reward on benchmark tasks,
– ΔS: change in safety margin (e.g. number or strength of verified invariants),
– ΔC: change in fast-path cost per step,
– ΔI: information gain or uncertainty reduction over hypotheses.

These quantities define the PoX score:

score(Δ) = w_R ΔR + w_S ΔS + w_C ΔC + w_I ΔI

Meta-game:

– At each slow-path decision epoch, BEM conceptually plays a meta-game:
– state: current configuration C_t_meta,
– actions: Δ ∈ A_meta(C_t_meta) ∪ {NOOP},
– payoff: score(Δ) − λ_meta * C_meta(Δ), with λ_meta ≥ 0,
– constraints: Δ must be verified and safe.

The meta-objective is to choose a sequence of patches {Δ_k} that maximizes:

Σ_k E[score(Δ_k) − λ_meta * C_meta(Δ_k)]

over long horizons, subject to compute budgets and safety preservation.

13.5 Two-Time-Scale Learning and Scheduling

BEM v0.0.1 naturally decomposes into two time scales.

Fast time scale (per step t):

– Observations, routing, expert execution, minimal stats update:
– Sections 4, 5, 6, 7, 11.1.
– Goal:
– minimize regret on the fast path against Π_ref ∩ S_safe,
– keep BAD_t rare or unreachable,
– keep cost_t bounded per step.

Slow time scale (per patch / batch):

– Operations in Sections 8, 9, 10, 11.3:
– expert split/merge, template extraction, superoptimization, ANN maintenance,
– construction and solving of VC(Δ),
– evaluation and scheduling based on PoX.
– Goal:
– improve long-run fast-path performance by changing C,
– under constraints:
– safety (VC(Δ) UNSAT),
– compute budget for structural work.

Scheduler (Section 10) chooses allocations:

– α_act, α_synth, α_verify ∈ [0,1], with α_act + α_synth + α_verify = 1,

interpreted as average fractions of compute time spent on:

– α_act: acting on real tasks (fast-path loop),
– α_synth: synthetic experiments, self-play, adversarial tasks,
– α_verify: verification and optimization jobs (meta-actions and evaluation).

Heuristics in Section 10 can be understood game-theoretically as:

– choosing, at each slow time scale, a mixed meta-policy over job classes and candidate patches that trades off:
– short-term improvements in fast-path payoff,
– long-term information gain and structural simplification,
– cost of verification and optimization.

13.6 Synthetic Experiments as Adversarial or Cooperative Play

Although synthetic experiments and self-play are not fully axiomatized in v0.0.1, they are implicitly supported through:

– TRACE/LOG (Section 8),
– CEGIS (Section 9.4),
– PoX scheduling (Section 10).

Game-theoretically, synthetic jobs can be seen as creating auxiliary games in which:

– Player 2 is not an external environment, but a task generator that may:
– be adversarial (e.g. CEGIS counterexample generation),
– be cooperative (e.g. curriculum design for exploration of under-tested behaviors).

For such synthetic games:

– payoff is measured more directly in terms of ΔI (information gain), ΔS (safety strengthening), or ΔC (cost reduction),
– PoX score reflects these objectives explicitly.

Thus, the meta-game can include synthetic experiments as actions that trade immediate compute for improved structural knowledge and stronger invariants.

13.7 Relation to Implementation Choices

The game-theoretic view does not impose additional implementation constraints beyond Sections 0–12, but clarifies design intent:
	1.	Fast-path routing and bandit updates:
– intended to approximate no-regret strategies in a contextual bandit with safety-constrained action sets.
	2.	Structural patch mechanisms:
– intended to act as meta-actions that adapt the policy class (experts, macros, invariants) under explicit cost and safety accounting.
	3.	Verification kernel:
– intended to restrict both fast-path and meta-level strategies to configurations in S_safe, by acting as a conservative oracle that rejects unsafe or unproven patches.
	4.	PoX and WORK:
– intended to provide a scalar objective and lightweight state to drive meta-level scheduling, so that long-running BEM instances use their compute budget to:
– reduce regret,
– improve safety guarantees,
– reduce fast-path cost,
– and reduce epistemic uncertainty.

This interpretation is compatible with alternative viewpoints (e.g. purely algorithmic, purely logical). It exists to make explicit that BEM v0.0.1 is not only a static accelerator for Boolean circuits, but a two-time-scale learning system that:

– plays an online game on the fast path,
– and a slower meta-game in which it selects and verifies changes to itself.
