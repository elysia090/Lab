BEM v0.0.1 – Boolean Expert Machine
Mixture-of-Experts VM with Fast-Path Bandit RL, Task Grammar, and PoX-Gated Structural Learning
(Integrated English ASCII Draft, no optionals)
	0.	Scope and Goals

0.1 Purpose

This document defines BEM v0.0.1 as a self-reinforcing mixture-of-experts virtual machine with:
	1.	A fixed integer/bitwise ISA and bit-sliced SIMD execution core.
	2.	A fixed-size MoE table organized into routing buckets and expert slots, with constant-time fast-path bandit routing.
	3.	A task grammar (TEACH) that generates bounded-complexity finite environments and assigns task families.
	4.	A structural learning subsystem expressed as patches, with the following mandatory patch kinds:
4.1 Expert retire.
4.2 Expert reset.
4.3 Expert split.
4.4 Expert merge.
4.5 Expert superoptimization.
4.6 Task-grammar edits.
	5.	A verification kernel that expresses patch verification conditions as CNF and checks them with SAT/CEGIS.
	6.	A PoX (proof-of-improvement) scoring mechanism that gates all patch application based on empirical regret, cost, safety, and novelty.
	7.	A logging and snapshot pipeline for auditability and reproducibility.

The fast path is strictly bounded per logical step by a constant C_step_max that is independent of episode length, total training time, and number of applied patches.

0.2 Non-goals

BEM v0.0.1 does not define:
	1.	Hardware micro-architecture, cache hierarchy, or binary instruction encoding.
	2.	Any floating-point primitives in the trusted core.
	3.	External human-facing APIs (natural language, GUI, RPC).
	4.	Concrete datasets, domains, or reward functions beyond the abstract environment interface.

0.3 Global configuration

All configuration parameters are fixed before the system is started and never changed in place. They include:
	1.	N_state_bits: number of global STATE bits.
	2.	W: SIMD lane width (number of lanes).
	3.	B: number of routing buckets.
	4.	K_exp: number of expert slots per bucket.
	5.	P_params: number of global integer/fixed-point parameters in SHARED.
	6.	T_tasks_max: maximum number of task families.
	7.	S_templates_max: maximum number of task templates in TEACH.
	8.	L_cfg_max: maximum number of CFG instructions.
	9.	M_mono_max: maximum monomial count per expert output (ANF representation bound).
	10.	G_gate_max: maximum gate count for DAG-based circuit representation.
	11.	C_expert_max: upper bound on cycle cost of one expert execution.
	12.	C_step_max: upper bound on total fast-path cost per step.
	13.	K_patch_queue_max: maximum number of patches in the patch queue.
	14.	Bandit hyperparameters:
14.1 alpha_bandit: fixed-point exploration weight.
14.2 beta_bandit: fixed-point prior weight.
14.3 eta_z: learning rate for expert prior z.
14.4 l_ref: reference loss.
14.5 z_min, z_max: bounds for z.
	15.	TEACH hyperparameters:
15.1 Parameters for difficulty_est.
15.2 Parameters for meta_reward.
15.3 Mutation rate p_mut.
	16.	PoX and scheduler hyperparameters:
16.1 w_R, w_C, w_S, w_N: weights for regret, cost, safety, novelty.
16.2 D_threshold: PoX acceptance threshold.
16.3 Scheduler exploration constants.
	17.	Reward range:
17.1 R_min < R_max: fixed reward bounds.

All hyperparameters are stored in dedicated locations in SHARED and are treated as read-only during execution.
	1.	State, Memory, and Identifiers

1.1 Runtime state

At logical step t the full VM state is:

X_t = (STATE_t, SHARED_t)
	1.	STATE_t is a bit-sliced array:
1.1 For each bit index k in [0, N_state_bits),
STATE[k] ∈ {0,1}^W holds bit k for all lanes.
1.2 For each lane index l in [0, W), the lane-local view is:

state_lane(l)[k] = bit l of STATE[k]


	2.	SHARED_t is a flat integer/fixed-point memory, conceptually segmented:
2.1 CONFIG: read-only configuration and hyperparameters.
2.2 BANDIT: expert bandit statistics.
2.3 TEACH: task template table and statistics.
2.4 WORK: PoX and scheduler statistics.
2.5 ROUTE_META: routing descriptors per task family.
2.6 PATCH_QUEUE: patch descriptors and statuses.
2.7 ENV: environment descriptors and per-task persistent parameters.

The exact physical layout of SHARED is an implementation detail; logical segments are disjoint in address space.

1.2 Identifier layout

Identifiers are 32-bit integers u ∈ {0,…,2^32−1} with the following bit layout:

u = [class(6) | ecc(6) | bucket(10) | local(10)]
	1.	class: object kind.
Examples:
1.1 0: expert.
1.2 1: task_family.
1.3 2: template.
1.4 3: patch.
1.5 4: cfg_node.
1.6 5: env_instance.
1.7 Others reserved.
	2.	ecc: parity/ECC bits for corruption detection.
	3.	bucket: routing bucket index or a reserved value when not applicable.
	4.	local: sub-index within class+bucket subspace.

An allocator in SHARED ensures uniqueness of (class,bucket,local) at allocation time and maintains ecc bits.

1.3 Buckets and expert slots

Routing buckets are numbered b in {0,…,B−1}. For each bucket b there is a fixed array of K_exp expert slots:

BUCKET[b].expert_slots[0..K_exp−1]

Each slot k in bucket b stores:
	1.	expert_id ∈ U with class=expert and bucket=b.
	2.	R_spec: read specification.
	3.	W_spec: write specification.
	4.	C_rep: circuit representation.
	5.	profile: static cost estimate and counters.

1.4 Task families and task_id

A task family index tau ∈ {0,…,T_tasks_max−1} is represented as a small integer. At each logical step t:
	1.	SHARED stores a current task_id_t = tau_t for each environment instance.
	2.	STATE may duplicate tau_t into fixed bits to allow routing and experts to depend on task.

Bandit statistics are indexed by (bucket b, slot k, task tau).
	2.	Experts and Local Semantics

2.1 Expert descriptor format

For each (b,k) pair:

EXPERT[b][k] = (
expert_id,
R_spec,
W_spec,
C_rep,
profile
)
	1.	expert_id: as in 1.3.
	2.	R_spec: fixed read specification:
2.1 A fixed-length array of STATE bit indices:
R_spec.state_bits[0..R_state_max−1] ⊆ [0, N_state_bits)
2.2 A fixed-length array of SHARED word indices:
R_spec.shared_words[0..R_shared_max−1]
All indices are within configuration bounds.
	3.	W_spec: fixed write specification:
3.1 A fixed-length array of STATE bit indices for writing.
3.2 A fixed-length array of SHARED word indices for integer/fixed-point writes.
3.3 A fixed mapping from circuit outputs to these indices.
3.4 A fixed mapping from selected bits of outputs to lane masks.
	4.	C_rep: circuit representation for the expert:
4.1 Inputs x ∈ {0,1}^{n_in} are derived from:

4.1.1 STATE bits referenced by R_spec.state_bits.  
4.1.2 SHARED words via bit extraction and fixed bit-packing.

4.2 Outputs y ∈ {0,1}^{n_out} and a fixed number of integer accumulators z_int:

4.2.1 y is defined by a Boolean circuit over x.  
4.2.2 z_int is defined by fixed integer MAC-like formulas over small subsets of x.

4.3 Representation constraints:

4.3.1 n_in ≤ N_in_max.  
4.3.2 n_out ≤ N_out_max.  
4.3.3 Total number of Boolean primitives (AND, OR, XOR, NOT, etc.) ≤ G_gate_max.  
4.3.4 If ANF is used, each output has at most M_mono_max monomials.


	5.	profile:
5.1 cost_expert[b][k]: static upper bound on cycles consumed by the expert.
5.2 usage counters for profiling (not used for correctness).

2.2 Expert execution semantics

Given current (STATE_t, SHARED_t), bucket b_t, slot k_t:
	1.	Input extraction:
1.1 For each index in R_spec.state_bits:
load STATE bit-vectors into bit registers (bit-sliced across W lanes).
1.2 For each index in R_spec.shared_words:
load SHARED words into scalar registers.
1.3 Construct x as a bit-sliced vector from these inputs via fixed bit-packing.
	2.	Circuit evaluation:
2.1 Use BIT-ALU and integer ALU instructions to evaluate C_rep deterministically.
2.2 Compute Boolean outputs y and integer outputs z_int.
	3.	Lane masking:
3.1 Compute lane mask(s) mask_lane ∈ {0,1}^W from fixed bits of y.
3.2 mask_lane[l] = 1 means “lane l is active for this write”.
	4.	Write-back:
4.1 For each STATE write target:

4.1.1 Combine current STATE[k] with outputs using mask_lane:  
       STATE[k] := (STATE[k] & ~mask_lane) | (y_bits & mask_lane)

4.2 For each SHARED write target:

4.2.1 Update SHARED word with integer outputs and constants.


	5.	Cost:
5.1 The implementation of C_rep and R_spec/W_spec must guarantee that the total cycle count for this expert call is ≤ C_expert_max.

2.3 Structural invariants
	1.	R_spec, W_spec, C_rep, and profile for a given (b,k) remain constant as long as expert_id at (b,k) is unchanged.
	2.	Structural learning only modifies experts by installing new EXPERT[b][k] descriptors atomically via patches.
	3.	Routing and Bandit RL

3.1 Routing signature

For each task family tau there is a routing descriptor:

ROUTE_DESC[tau] = (
state_bit_indices[],
shared_word_indices[],
hash_params
)

A deterministic function SIG_t is defined as:
	1.	Read a fixed set of STATE bits and SHARED words from ROUTE_DESC[tau].
	2.	Combine them into a 64-bit key k_t using fixed integer/bitwise operations (e.g. xor, rotations, multiplications).
	3.	Return k_t.

The bucket index b_t is defined as:

b_t = k_t mod B

For each environment instance and step t, fast path computes:
	1.	tau_t = task_id_t from SHARED.
	2.	k_t = SIG_t(STATE_t, SHARED_t, tau_t).
	3.	b_t = k_t mod B.

3.2 Bandit state layout

For each triple (bucket b, slot k, task tau) the bandit statistics are:
	1.	n[b][k][tau] ∈ Z_32: visit count (≥0).
	2.	L[b][k][tau] ∈ fixed-point: sum of losses.
	3.	Q[b][k][tau] ∈ fixed-point: sum of squared losses.
	4.	z[b][k][tau] ∈ fixed-point: prior log-weight.

For each tau:
	1.	N_tau[tau] ∈ Z_64: total selections for task tau.

All are stored in BANDIT segment of SHARED.

3.3 Loss normalization

For each step t, environment writes reward r_t ∈ [R_min, R_max]. The loss is:

loss_t = (R_max − r_t) / (R_max − R_min) ∈ [0,1]

Only the chosen (b_t,k_t,tau_t) receives a non-zero loss update in BANDIT_UPDATE.

3.4 Index computation (UCB-V + prior)

For a fixed tau and bucket b, for each slot k:
	1.	n = max(1, n[b][k][tau]).
	2.	L = L[b][k][tau].
	3.	Q = Q[b][k][tau].
	4.	hat_l = L / n.
	5.	var = max(0, Q/n − hat_l * hat_l).
	6.	n_tot = max(1, N_tau[tau]).
	7.	bonus = alpha_bandit * sqrt( (2 * var * log(1 + n_tot)) / n )
+ alpha_bandit * (3 * log(1 + n_tot)) / n.
	8.	prior_term = −beta_bandit * z[b][k][tau].
	9.	index[b][k][tau] = hat_l − prior_term + bonus.

All operations use fixed-point arithmetic with sufficient precision, chosen in CONFIG.

3.5 Expert choice

At step t:
	1.	Read tau_t and compute b_t as in 3.1.
	2.	Candidate set C_t = {0,…,K_exp−1}.
	3.	For each k in C_t compute index[b_t][k][tau_t].
	4.	Choose k_t as:
k_t = argmin_k index[b_t][k][tau_t].
	5.	If multiple k share the same minimal index (within numeric equality), choose the smallest k.

This defines a deterministic greedy UCB-V selection.

3.6 Bandit update

When reward r_t is available for step t, with chosen (b_t, k_t, tau_t):
	1.	Compute loss_t as in 3.3.
	2.	Load:
n_old = n[b_t][k_t][tau_t]
L_old = L[b_t][k_t][tau_t]
Q_old = Q[b_t][k_t][tau_t]
z_old = z[b_t][k_t][tau_t]
	3.	Update:
n_new = n_old + 1
N_tau[tau_t] = N_tau[tau_t] + 1
L_new = L_old + loss_t
Q_new = Q_old + loss_t * loss_t
	4.	Store:
n[b_t][k_t][tau_t] = n_new
L[b_t][k_t][tau_t] = L_new
Q[b_t][k_t][tau_t] = Q_new
	5.	Prior update:
avg_l = L_new / max(1, n_new)
delta_z = −eta_z * (avg_l − l_ref)
z_temp = z_old + delta_z
z_clipped = min(max(z_temp, z_min), z_max)
z[b_t][k_t][tau_t] = z_clipped

This update is implemented as a small loop over fixed-size integers and fixed-point multiplications; its per-step cost is bounded by a constant independent of t and training duration.

3.7 Regret guarantee (informal requirement)

For each pair (b,tau):
	1.	Losses are bounded in [0,1].
	2.	The selection rule uses index[b][k][tau] as in 3.4.
	3.	z updates are bounded in magnitude by configuration constants.

Under these conditions, the expected regret of the bandit selection on (b,tau) grows as O(√(K_exp T log T)) in T, up to constant factors that depend only on configuration parameters and not on t.
	4.	Task Grammar and Templates

4.1 BaseProblem families

TEACH stores a fixed set of primitive environment families (“BaseProblems”). Each BaseProblem B_j has:

B_j = (
base_id,
env_class_id,
param_schema,
horizon_bound,
complexity_est
)
	1.	base_id: template-independent identifier.
	2.	env_class_id: an integer labeling the environment implementation.
	3.	param_schema: ranges and integer distributions for BaseProblem parameters.
	4.	horizon_bound: fixed upper bound on episode length.
	5.	complexity_est: static estimate used in difficulty_est.

BaseProblem families include, at minimum:
	1.	Bitwise aggregation primitives (parity, majority, threshold).
	2.	Stack and simple context-free structure with bounded depth.
	3.	Key-value retrieval with bounded table size.
	4.	K-armed bandits and contextual bandits with bounded arms.
	5.	Small matrix games and simple signaling games.
	6.	Bounded safety and SAT-like predicates over STATE.

4.2 CFG fragment tasks

TEACH also stores CFG fragment task specifications referencing subgraphs of CFG. Each fragment F_k has:

F_k = (
cfg_fragment_id,
entry_pc,
exit_condition_spec,
local_reward_spec,
fragment_horizon_bound,
fragment_complexity_est
)

These define environment instances that run BEM’s own CFG on synthetic or recorded input patterns.

4.3 Template representation

Each task template t is stored in TEACH[T_id] as:

TEMPLATE[t_id] = (
domain_id,
op_tree,
param_schema,
difficulty_est,
stats
)
	1.	domain_id: integer label for grouping templates into domains.
	2.	op_tree: composition tree with node types:
2.1 LEAF_BASE(base_id)
2.2 LEAF_CFG(cfg_fragment_id)
2.3 SEQ(node_a, node_b)
2.4 PAR(node_a, node_b)
2.5 MASK(node_a, mask_descriptor)
2.6 INTERLEAVE(node_a, node_b, pattern_descriptor)
2.7 LOOP(node_a, max_iter)
	3.	param_schema: ranges of integer/fixed-point parameters used to instantiate the template.
	4.	difficulty_est: fixed-point scalar.
	5.	stats:
5.1 usage_count_t
5.2 pass_rate_t
5.3 regret_proxy_t
5.4 novelty_t
5.5 last_update_step_t

4.4 Template instantiation

To instantiate a template t_id into a concrete task instance:
	1.	Sample parameters from param_schema using a PRNG seeded from SHARED.
	2.	Traverse op_tree and construct an environment skeleton:
2.1 LEAF_BASE(base_id): instantiate a BaseProblem with sampled parameters.
2.2 LEAF_CFG(cfg_fragment_id): instantiate CFG fragment environment.
2.3 SEQ(a,b): connect termination of a to initialization of b via fixed mapping.
2.4 PAR(a,b): maintain separate states and combine observations/rewards by concat and fixed linear combination.
2.5 MASK(a,mask_desc): apply masking rules to observations/rewards from a.
2.6 INTERLEAVE(a,b,pattern_desc): construct a step schedule that chooses at each step which sub-environment to advance, then merges observations according to pattern_desc.
2.7 LOOP(a,max_iter): run a repeatedly until stop condition or max_iter, summing or aggregating rewards.
	3.	Assign:
3.1 A task family tau for the instantiated environment.
3.2 env_config pointer specifying env_class and parameters.
3.3 horizon bound as a function of child horizon bounds and operator type.

The instantiation procedure is fully deterministic given sampled parameters and uses a fixed bounded amount of compute per instantiation.

4.5 Template bandit

For each domain d and difficulty band k, TEACH maintains a bandit over templates in that domain and band:
	1.	For each template t:
1.1 meta_n[d][k][t], meta_L[d][k][t], meta_Q[d][k][t], meta_z[d][k][t].
	2.	meta_loss is defined from meta_reward:
meta_loss_t = (R_meta_max − meta_reward_t) / (R_meta_max − R_meta_min).
	3.	meta_reward_t is computed from:
3.1 pass_rate_t
3.2 regret_proxy_t
3.3 novelty_t
3.4 safety statistics

with a fixed function defined in CONFIG.

Template selection TEACH_CHOOSE uses the same UCB-V + prior index as in section 3, replacing loss with meta_loss and step counts with template-level counts.
	5.	Patches and Structural Learning

5.1 Patch descriptor

Each patch has a descriptor stored in PATCH_QUEUE:

PATCH[patch_id] = (
kind,
target,
payload,
estimated_effects,
status
)
	1.	kind ∈ { RETIRE, RESET, SPLIT, MERGE, SUPEROPT, TEACH_EDIT }.
	2.	target: an identifier or tuple pointing to the affected object:
2.1 (b,k) for expert-related patches.
2.2 t_id for TEACH_EDIT.
2.3 Other identifiers for CFG-related edits if configured.
	3.	payload: kind-specific data encoding all changes.
	4.	estimated_effects: fields storing:
4.1 Δ_regret_est
4.2 Δ_cost_est
4.3 Δ_safety_est
4.4 Δ_novelty_est
	5.	status ∈ { PENDING, VERIFIED, REJECTED, APPLIED }.

PATCH_QUEUE is a circular array of size K_patch_queue_max; new patches overwrite least-priority REJECTED or low-score PENDING entries when full.

5.2 RETIRE patch

RETIRE replaces an expert with a deterministic NOOP expert.
	1.	Input:
1.1 target = (b,k) with poor long-term performance.
	2.	payload:
2.1 Descriptor for NOOP expert:
2.1.1 R_spec reading no bits or a minimal safe set.
2.1.2 W_spec that writes nothing or leaves state unchanged.
2.1.3 C_rep implementing identity or constant output.
	3.	Effect if APPLIED:
3.1 EXPERT[b][k] is overwritten with NOOP descriptor.
3.2 Bandit stats n,L,Q,z for all tau at (b,k) are reset to neutral values.

5.3 RESET patch

RESET resets bandit stats for an expert without changing its program.
	1.	Input: target = (b,k).
	2.	payload: none beyond target.
	3.	Effect if APPLIED:
3.1 n[b][k][tau] = n_init for all tau.
3.2 L[b][k][tau] = L_init.
3.3 Q[b][k][tau] = Q_init.
3.4 z[b][k][tau] = z_init.

Initial values are fixed in CONFIG.

5.4 SPLIT patch

SPLIT specializes one expert into two experts within the same bucket by introducing a gating predicate.
	1.	Input: target = (b,k).
	2.	Construction:
2.1 Collect a finite set S of trace entries where (b,k) was chosen and loss was high.
2.2 For each candidate gating bit g from a fixed set of indices into STATE and SHARED:
2.2.1 Partition S into S0 (g=0) and S1 (g=1).
2.2.2 Compute loss0, loss1, |S0|, |S1|.
2.2.3 Compute score(g) = var_reduction(g) + balance_term(g) with fixed formulas.
2.3 Choose g* with maximal score(g) over allowed candidates.
2.4 Find a free or RETIREd slot k_new within bucket b.
2.5 Copy EXPERT[b][k] descriptor into EXPERT[b][k_new].
	3.	payload:
3.1 gating_bit_index = g*.
3.2 original slot k and new slot k_new.
3.3 initial bandit stats for (b,k_new,tau) derived from (b,k,tau).
	4.	Effect if APPLIED:
4.1 EXPERT[b][k_new] is installed.
4.2 ROUTE_DESC[tau] for all relevant tau is updated to include a gating predicate P_g* that determines whether (b,k) or (b,k_new) participate in candidate set C_t.
4.3 Specifically, for bucket b:
4.3.1 If P_g*(STATE,SHARED,tau)=0, candidate includes k and excludes k_new.
4.3.2 If P_g*(STATE,SHARED,tau)=1, candidate includes k_new and excludes k.

5.5 MERGE patch

MERGE fuses multiple similar experts into one.
	1.	Input: target cluster C_merge = {(b,k_1),…,(b,k_m)}.
	2.	Construction:
2.1 Check that all experts in C_merge share compatible R_spec and W_spec.
2.2 Collect input/output samples:
2.2.1 For each (b,k_i) gather a set of (x_j,y_j) pairs from TRACE where k_i was chosen, x_j are input bits, y_j outputs.
2.3 Form a combined dataset D_merge of size ≤ D_merge_max.
2.4 Use PROVER’s CEGIS to synthesize C_rep_m that satisfies all (x_j → y_j) in D_merge, with gate/monomial bounds.
2.5 Compute aggregated bandit stats as weighted averages or sums from C_merge.
	3.	payload:
3.1 indices k_1,…,k_m and new slot k_mrg.
3.2 synthesized C_rep_m.
3.3 merged R_spec and W_spec.
3.4 aggregated bandit stats.
	4.	Effect if APPLIED:
4.1 EXPERT[b][k_mrg] is installed.
4.2 Selected experts in C_merge are RETIREd or repurposed.
4.3 Bandit stats for (b,k_mrg,tau) are set from payload.

5.6 SUPEROPT patch

SUPEROPT locally rewrites the circuit of an expert to reduce its cost.
	1.	Input: target = (b,k).
	2.	Construction:
2.1 Extract C_rep and R_spec/W_spec.
2.2 Use a fixed search procedure over a finite set of rewrite rules to generate candidate circuits C_rep’ with lower estimated cost.
2.3 For each candidate C_rep’, build a finite test set D_sup of (x_j,y_j) using recorded inputs and random inputs.
2.4 Construct VC_equiv asserting that C_rep and C_rep’ produce identical outputs on D_sup.
2.5 Select the best C_rep’ that passes VC_equiv and yields maximal estimated cost reduction.
	3.	payload:
3.1 New C_rep’.
3.2 Estimated cost_reduction.
	4.	Effect if APPLIED:
4.1 EXPERT[b][k].C_rep is replaced by C_rep’.
4.2 profile.cost_expert[b][k] is updated.

5.7 TEACH_EDIT patch

TEACH_EDIT adds or modifies task templates.
	1.	Input: target = t_id (existing) or reserved id for new template.
	2.	Construction:
2.1 Propose new op_tree via:
2.1.1 Mutation of an existing template (e.g. insert MASK, add SEQ node).
2.1.2 Extraction from TRACE and CFG fragments (T_extract).
2.2 Compute new param_schema constrained to bounded ranges.
2.3 Estimate difficulty_est from horizon, op_tree size, BaseProblem composition, and historical pass_rate.
	3.	payload:
3.1 Complete new TEMPLATE descriptor.
	4.	Effect if APPLIED:
4.1 TEMPLATE[t_id] is created or replaced.
4.2 TEACH bandit stats for this template are initialized from parent or neutral priors.
	5.	Verification Kernel and PoX

6.1 Verification kernel

PROVER exposes:
	1.	SAT_CHECK(cnf_id, options) → {SAT, UNSAT, UNKNOWN}.
	2.	CEGIS(spec_id, hyp_class_id, options) → candidate_circuit or NONE.
	3.	CNF management calls to register base formulas and patch-specific formulas.

Each patch Δ defines a verification condition VC(Δ) converted to CNF:
	1.	RETIRE / RESET:
1.1 VC_RETIRE/RESET ensures indices are in range and NOOP expert representation respects cost and type bounds.
	2.	SPLIT:
2.1 VC_SPLIT ensures:
2.1.1 gating_bit_index is allowable.
2.1.2 R_spec and W_spec equality between original and new expert.
2.1.3 Routing descriptor updates maintain candidate set size bounds.
	3.	MERGE:
3.1 VC_MERGE ensures:
3.1.1 R_spec/W_spec compatibility across cluster.
3.1.2 C_rep_m satisfies given (x_j,y_j) pairs.
3.1.3 Gate/monomial bounds are not violated.
	4.	SUPEROPT:
4.1 VC_SUPEROPT ensures:
4.1.1 C_rep’ respects cost and complexity bounds.
4.1.2 C_rep and C_rep’ agree on D_sup.
	5.	TEACH_EDIT:
5.1 VC_TEACH ensures:
5.1.1 op_tree depth ≤ configured max.
5.1.2 horizon bound ≤ configured max.
5.1.3 type consistency of observation and action spaces with env_class.
5.1.4 Safety tags and constraints are preserved or strengthened.

SAT_CHECK is run with a fixed timeout. If result is UNKNOWN or timeout, the patch is set to status=REJECTED.

6.2 PoX scoring

For each VERIFIED patch Δ, PoX computes:

score(Δ) = w_R * Δ_regret
+ w_C * Δ_cost
+ w_S * Δ_safety
+ w_N * Δ_novelty
	1.	Δ_regret is estimated from sliding-window regret proxies on affected buckets/tasks before and after an experimental application or from off-policy evaluation.
	2.	Δ_cost is estimated from changes in cost_expert and observed cycle counts.
	3.	Δ_safety is estimated from changes in BAD flags or safety violation counters.
	4.	Δ_novelty is estimated from coverage metrics (e.g. distribution of routing signatures and template usage).

PoX acceptance rule:
	1.	If VC(Δ) is UNSAT and score(Δ) ≥ D_threshold, then Δ is eligible for application.
	2.	Otherwise status is set to REJECTED.

6.3 Patch application

Application of an APPLIED patch Δ is atomic with respect to:
	1.	EXPERT table entries or TEACH template entries it modifies.
	2.	Associated bandit state changes in SHARED.
	3.	Associated ROUTE_DESC or CFG changes.
	4.	Merkle root updates and TRACE log of the patch.

Fast path continues to operate with a consistent view of EXPERT and TEACH.
	7.	Execution Model

7.1 Fast-path step

For each environment instance, a logical step STEP_FAST executes:
	1.	Read task_id_t = tau_t from SHARED.
	2.	Compute routing signature:
2.1 k_t = SIG_t(STATE_t, SHARED_t, tau_t) using ROUTE_DESC[tau_t].
2.2 b_t = k_t mod B.
	3.	Run BANDIT_CHOOSE for (b_t, tau_t) to obtain k_t.
	4.	Execute EXPERT[b_t][k_t] on (STATE_t, SHARED_t) to obtain (STATE_t’, SHARED_t’).
	5.	Environment driver:
5.1 Reads action-relevant bits/words from STATE_t’ and SHARED_t’.
5.2 Updates its internal state.
5.3 Writes reward r_t and termination flag for this step/episode into SHARED.
	6.	LOG:
6.1 Append a minimal trace entry e_t = (task_id_t, b_t, k_t, r_t, cost_proxy) to TRACE.
6.2 Update hash chain H.
	7.	BANDIT_UPDATE:
7.1 When a reward is fully determined for step t (immediate or after delay), call BANDIT_UPDATE for (b_t, k_t, tau_t, r_t).

The implementation must ensure the total work in items 1–6 (excluding BANDIT_UPDATE) is ≤ C_step_max.

7.2 Mid-path and slow-path

Separate scheduler cycles perform:
	1.	Aggregation of per-task and per-template statistics from TRACE into BANDIT and TEACH segments.
	2.	TEACH_CHOOSE to select templates for future episodes based on domain and difficulty bands.
	3.	Patch generation:
3.1 Analyze TRACE, BANDIT, and WORK to propose RETIRE, RESET, SPLIT, MERGE, SUPEROPT, TEACH_EDIT patches.
3.2 Insert patches into PATCH_QUEUE as PENDING.
	4.	Patch verification and PoX scoring:
4.1 Run VC(Δ) via PROVER for selected PENDING patches.
4.2 Compute PoX score(Δ).
4.3 If accepted, apply Δ and mark APPLIED.
	5.	Snapshot decisions based on WORK metrics and PoX yield.

7.3 Scheduler for ACT / SYNTH / VERIFY

A contextual bandit schedules three meta-actions:
	1.	ACT: run STEP_FAST and BANDIT_UPDATE episodes.
	2.	SYNTH: generate patches.
	3.	VERIFY: verify and score patches.

A fixed-length context vector x_meta is built from:
	1.	Lengths of patch queue and their statuses.
	2.	Recent PoX scores and yields.
	3.	Safety violation counters.
	4.	Training progress counters.

The scheduler computes scores for each meta-action via a UCB-style index over past meta-rewards and chooses one action at each meta-step. Meta-rewards are derived from improvements in PoX yield, regret reduction rates, and safety metrics.
	8.	Logging, Integrity, and Snapshot

8.1 TRACE and hash chain

TRACE is an append-only array of entries:
	1.	Step entries: (time_or_step_counter, task_id, bucket, slot, reward, cost_proxy).
	2.	Episode summaries: (task_id, return, length, regret_estimate).

A hash chain H is maintained:
	1.	H_0 = fixed constant.
	2.	H_{i+1} = Hash(H_i || encode(e_i)).

The current H is stored in WORK and periodically exported.

8.2 Merkle trees

Merkle trees are maintained for:
	1.	EXPERT table (buckets × slots).
	2.	TEACH templates.
	3.	WORK configuration and hyperparameters.

On each APPLIED patch, affected leaves are updated, and corresponding Merkle roots are recomputed. Roots are logged into TRACE.

8.3 Snapshot model

A snapshot captures:
	1.	STATE and SHARED for all environment instances.
	2.	EXPERT table and ROUTE_DESC.
	3.	TEACH templates.
	4.	WORK metrics and scheduler state.
	5.	PATCH_QUEUE state.
	6.	TRACE up to current hash chain head.
	7.	Merkle roots.

Snapshots are serialized into container images or equivalent, identified by:
	1.	A timestamp.
	2.	Hash chain head H_current.
	3.	Merkle roots.

Restoring a snapshot reconstructs a BEM instance with the same configuration, EXPERT/TEACH structure, and logs up to that point.
	9.	Initial Conditions

9.1 Initial experts

At boot, the EXPERT table is initialized to a small fixed library of seed experts:
	1.	Identity-like transformers on subsets of STATE.
	2.	Simple bit-flips and permutations.
	3.	Simple counters in SHARED.
	4.	Safe NOOP experts.

Bandit stats are initialized to neutral priors for all (b,k,tau).

9.2 Initial task templates

TEACH is initialized with:
	1.	A small set of BaseProblem-based templates with short horizons.
	2.	A small set of CFG fragment templates with simple goals.

These ensure that:
	1.	Reward signals are available from the start.
	2.	Routing and experts can be trained immediately.
	3.	Patch generation has meaningful data to work with.

9.3 Determinism

Given:
	1.	Fixed configuration constants.
	2.	Fixed seeds for PRNG(s).
	3.	Fixed stream of external environment randomness (or deterministic simulators).

BEM v0.0.1 produces a deterministic sequence of:
	1.	Routing choices.
	2.	Expert executions.
	3.	Patch proposals, verification outcomes, and applied patches.
	4.	TEACH template selections.
	5.	Snapshots and logs.

End of BEM v0.0.1 core specification.
